<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="William Goette, Ph.D.">
<meta name="dcterms.date" content="2025-05-10">

<title>Interactive Statistics for Clinical Psychology</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="Interactive Statistics for Clinical Psychology_files/libs/clipboard/clipboard.min.js"></script>
<script src="Interactive Statistics for Clinical Psychology_files/libs/quarto-html/quarto.js"></script>
<script src="Interactive Statistics for Clinical Psychology_files/libs/quarto-html/popper.min.js"></script>
<script src="Interactive Statistics for Clinical Psychology_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Interactive Statistics for Clinical Psychology_files/libs/quarto-html/anchor.min.js"></script>
<link href="Interactive Statistics for Clinical Psychology_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Interactive Statistics for Clinical Psychology_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Interactive Statistics for Clinical Psychology_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Interactive Statistics for Clinical Psychology_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Interactive Statistics for Clinical Psychology_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<meta name="shinylive:serviceworker_dir" content=".">
<script src="Interactive Statistics for Clinical Psychology_files/libs/quarto-contrib/shinylive-0.9.1/shinylive/load-shinylive-sw.js" type="module"></script>
<script src="Interactive Statistics for Clinical Psychology_files/libs/quarto-contrib/shinylive-0.9.1/shinylive/run-python-blocks.js" type="module"></script>
<link href="Interactive Statistics for Clinical Psychology_files/libs/quarto-contrib/shinylive-0.9.1/shinylive/shinylive.css" rel="stylesheet">
<link href="Interactive Statistics for Clinical Psychology_files/libs/quarto-contrib/shinylive-quarto-css/shinylive-quarto.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="custom.css">
</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#interactive-statistics-for-clinical-psychology" id="toc-interactive-statistics-for-clinical-psychology" class="nav-link active" data-scroll-target="#interactive-statistics-for-clinical-psychology">Interactive Statistics for Clinical Psychology</a>
  <ul class="collapse">
  <li><a href="#preface" id="toc-preface" class="nav-link" data-scroll-target="#preface">Preface</a></li>
  <li><a href="#how-to-use-this-guide" id="toc-how-to-use-this-guide" class="nav-link" data-scroll-target="#how-to-use-this-guide">How to Use This Guide</a></li>
  </ul></li>
  <li><a href="#introduction-to-statistical-thinking" id="toc-introduction-to-statistical-thinking" class="nav-link" data-scroll-target="#introduction-to-statistical-thinking">1. Introduction to Statistical Thinking</a>
  <ul class="collapse">
  <li><a href="#populations-and-samples" id="toc-populations-and-samples" class="nav-link" data-scroll-target="#populations-and-samples">1.1 Populations and Samples</a></li>
  <li><a href="#probability-distributions" id="toc-probability-distributions" class="nav-link" data-scroll-target="#probability-distributions">1.2 Probability Distributions</a>
  <ul class="collapse">
  <li><a href="#the-normal-distribution" id="toc-the-normal-distribution" class="nav-link" data-scroll-target="#the-normal-distribution">1.2.1 The Normal Distribution</a></li>
  <li><a href="#the-standard-normal-distribution" id="toc-the-standard-normal-distribution" class="nav-link" data-scroll-target="#the-standard-normal-distribution">1.2.2 The Standard Normal Distribution</a></li>
  <li><a href="#other-important-distributions" id="toc-other-important-distributions" class="nav-link" data-scroll-target="#other-important-distributions">1.2.3 Other Important Distributions</a></li>
  </ul></li>
  <li><a href="#the-central-limit-theorem" id="toc-the-central-limit-theorem" class="nav-link" data-scroll-target="#the-central-limit-theorem">1.3 The Central Limit Theorem</a>
  <ul class="collapse">
  <li><a href="#mathematical-formulation" id="toc-mathematical-formulation" class="nav-link" data-scroll-target="#mathematical-formulation">1.3.1 Mathematical Formulation</a></li>
  <li><a href="#implications-for-clinical-research" id="toc-implications-for-clinical-research" class="nav-link" data-scroll-target="#implications-for-clinical-research">1.3.2 Implications for Clinical Research</a></li>
  <li><a href="#why-the-central-limit-theorem-matters-in-clinical-psychology" id="toc-why-the-central-limit-theorem-matters-in-clinical-psychology" class="nav-link" data-scroll-target="#why-the-central-limit-theorem-matters-in-clinical-psychology">1.3.3 Why the Central Limit Theorem Matters in Clinical Psychology</a></li>
  </ul></li>
  <li><a href="#hypothesis-testing" id="toc-hypothesis-testing" class="nav-link" data-scroll-target="#hypothesis-testing">1.4 Hypothesis Testing</a>
  <ul class="collapse">
  <li><a href="#the-logic-of-hypothesis-testing" id="toc-the-logic-of-hypothesis-testing" class="nav-link" data-scroll-target="#the-logic-of-hypothesis-testing">1.4.1 The Logic of Hypothesis Testing</a></li>
  <li><a href="#steps-in-hypothesis-testing" id="toc-steps-in-hypothesis-testing" class="nav-link" data-scroll-target="#steps-in-hypothesis-testing">1.4.2 Steps in Hypothesis Testing</a></li>
  <li><a href="#types-of-hypothesis-tests" id="toc-types-of-hypothesis-tests" class="nav-link" data-scroll-target="#types-of-hypothesis-tests">1.4.3 Types of Hypothesis Tests</a></li>
  <li><a href="#a-worked-example" id="toc-a-worked-example" class="nav-link" data-scroll-target="#a-worked-example">1.4.4 A Worked Example</a></li>
  </ul></li>
  <li><a href="#statistical-significance-and-effect-sizes" id="toc-statistical-significance-and-effect-sizes" class="nav-link" data-scroll-target="#statistical-significance-and-effect-sizes">1.5 Statistical Significance and Effect Sizes</a>
  <ul class="collapse">
  <li><a href="#statistical-significance" id="toc-statistical-significance" class="nav-link" data-scroll-target="#statistical-significance">1.5.1 Statistical Significance</a></li>
  <li><a href="#effect-sizes" id="toc-effect-sizes" class="nav-link" data-scroll-target="#effect-sizes">1.5.2 Effect Sizes</a></li>
  <li><a href="#interpreting-effect-sizes" id="toc-interpreting-effect-sizes" class="nav-link" data-scroll-target="#interpreting-effect-sizes">1.5.3 Interpreting Effect Sizes</a></li>
  <li><a href="#clinical-vs.-statistical-significance" id="toc-clinical-vs.-statistical-significance" class="nav-link" data-scroll-target="#clinical-vs.-statistical-significance">1.5.4 Clinical vs.&nbsp;Statistical Significance</a></li>
  </ul></li>
  <li><a href="#type-i-and-type-ii-errors" id="toc-type-i-and-type-ii-errors" class="nav-link" data-scroll-target="#type-i-and-type-ii-errors">1.6 Type I and Type II Errors</a>
  <ul class="collapse">
  <li><a href="#error-types-in-hypothesis-testing" id="toc-error-types-in-hypothesis-testing" class="nav-link" data-scroll-target="#error-types-in-hypothesis-testing">1.6.1 Error Types in Hypothesis Testing</a></li>
  <li><a href="#the-relationship-between-error-types" id="toc-the-relationship-between-error-types" class="nav-link" data-scroll-target="#the-relationship-between-error-types">1.6.2 The Relationship Between Error Types</a></li>
  <li><a href="#statistical-power" id="toc-statistical-power" class="nav-link" data-scroll-target="#statistical-power">1.6.3 Statistical Power</a></li>
  <li><a href="#balancing-errors-in-clinical-research" id="toc-balancing-errors-in-clinical-research" class="nav-link" data-scroll-target="#balancing-errors-in-clinical-research">1.6.4 Balancing Errors in Clinical Research</a></li>
  <li><a href="#beyond-the-dichotomy" id="toc-beyond-the-dichotomy" class="nav-link" data-scroll-target="#beyond-the-dichotomy">1.6.5 Beyond the Dichotomy</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">1.7 Summary</a></li>
  </ul></li>
  <li><a href="#comparing-two-groups-t-tests" id="toc-comparing-two-groups-t-tests" class="nav-link" data-scroll-target="#comparing-two-groups-t-tests">2. Comparing Two Groups: t-tests</a>
  <ul class="collapse">
  <li><a href="#introduction-to-t-tests" id="toc-introduction-to-t-tests" class="nav-link" data-scroll-target="#introduction-to-t-tests">2.1 Introduction to t-tests</a></li>
  <li><a href="#independent-samples-t-test" id="toc-independent-samples-t-test" class="nav-link" data-scroll-target="#independent-samples-t-test">2.2 Independent Samples t-test</a>
  <ul class="collapse">
  <li><a href="#when-to-use-the-independent-samples-t-test" id="toc-when-to-use-the-independent-samples-t-test" class="nav-link" data-scroll-target="#when-to-use-the-independent-samples-t-test">2.2.1 When to Use the Independent Samples t-test</a></li>
  <li><a href="#the-logic-of-the-independent-samples-t-test" id="toc-the-logic-of-the-independent-samples-t-test" class="nav-link" data-scroll-target="#the-logic-of-the-independent-samples-t-test">2.2.2 The Logic of the Independent Samples t-test</a></li>
  <li><a href="#key-assumptions" id="toc-key-assumptions" class="nav-link" data-scroll-target="#key-assumptions">2.2.3 Key Assumptions</a></li>
  <li><a href="#effect-size-for-independent-samples-t-test" id="toc-effect-size-for-independent-samples-t-test" class="nav-link" data-scroll-target="#effect-size-for-independent-samples-t-test">2.2.4 Effect Size for Independent Samples t-test</a></li>
  </ul></li>
  <li><a href="#paired-samples-t-test" id="toc-paired-samples-t-test" class="nav-link" data-scroll-target="#paired-samples-t-test">2.3 Paired Samples t-test</a>
  <ul class="collapse">
  <li><a href="#when-to-use-the-paired-samples-t-test" id="toc-when-to-use-the-paired-samples-t-test" class="nav-link" data-scroll-target="#when-to-use-the-paired-samples-t-test">2.3.1 When to Use the Paired Samples t-test</a></li>
  <li><a href="#the-logic-of-the-paired-samples-t-test" id="toc-the-logic-of-the-paired-samples-t-test" class="nav-link" data-scroll-target="#the-logic-of-the-paired-samples-t-test">2.3.2 The Logic of the Paired Samples t-test</a></li>
  <li><a href="#key-assumptions-1" id="toc-key-assumptions-1" class="nav-link" data-scroll-target="#key-assumptions-1">2.3.3 Key Assumptions</a></li>
  <li><a href="#statistical-power-and-advantages-of-paired-designs" id="toc-statistical-power-and-advantages-of-paired-designs" class="nav-link" data-scroll-target="#statistical-power-and-advantages-of-paired-designs">2.3.4 Statistical Power and Advantages of Paired Designs</a></li>
  <li><a href="#effect-size-for-paired-samples-t-test" id="toc-effect-size-for-paired-samples-t-test" class="nav-link" data-scroll-target="#effect-size-for-paired-samples-t-test">2.3.5 Effect Size for Paired Samples t-test</a></li>
  </ul></li>
  <li><a href="#choosing-between-independent-and-paired-t-tests" id="toc-choosing-between-independent-and-paired-t-tests" class="nav-link" data-scroll-target="#choosing-between-independent-and-paired-t-tests">2.4 Choosing Between Independent and Paired t-tests</a></li>
  <li><a href="#interpretation-and-reporting" id="toc-interpretation-and-reporting" class="nav-link" data-scroll-target="#interpretation-and-reporting">2.5 Interpretation and Reporting</a>
  <ul class="collapse">
  <li><a href="#clinical-vs.-statistical-significance-1" id="toc-clinical-vs.-statistical-significance-1" class="nav-link" data-scroll-target="#clinical-vs.-statistical-significance-1">2.5.1 Clinical vs.&nbsp;Statistical Significance</a></li>
  </ul></li>
  <li><a href="#common-misinterpretations" id="toc-common-misinterpretations" class="nav-link" data-scroll-target="#common-misinterpretations">2.6 Common Misinterpretations</a></li>
  <li><a href="#summary-1" id="toc-summary-1" class="nav-link" data-scroll-target="#summary-1">2.7 Summary</a></li>
  </ul></li>
  <li><a href="#comparing-multiple-groups-anova" id="toc-comparing-multiple-groups-anova" class="nav-link" data-scroll-target="#comparing-multiple-groups-anova">3. Comparing Multiple Groups: ANOVA</a>
  <ul class="collapse">
  <li><a href="#one-way-anova" id="toc-one-way-anova" class="nav-link" data-scroll-target="#one-way-anova">3.2 One-way ANOVA</a></li>
  <li><a href="#two-way-anova" id="toc-two-way-anova" class="nav-link" data-scroll-target="#two-way-anova">3.3 Two-way ANOVA</a></li>
  <li><a href="#between-subjects-within-subjects-and-mixed-designs" id="toc-between-subjects-within-subjects-and-mixed-designs" class="nav-link" data-scroll-target="#between-subjects-within-subjects-and-mixed-designs">3.4 Between-subjects, Within-subjects, and Mixed Designs</a>
  <ul class="collapse">
  <li><a href="#within-subjects-anova-repeated-measures" id="toc-within-subjects-anova-repeated-measures" class="nav-link" data-scroll-target="#within-subjects-anova-repeated-measures">3.4.2 Within-subjects ANOVA (Repeated Measures)</a></li>
  </ul></li>
  <li><a href="#interpretation-and-reporting-1" id="toc-interpretation-and-reporting-1" class="nav-link" data-scroll-target="#interpretation-and-reporting-1">3.5 Interpretation and Reporting</a></li>
  </ul></li>
  <li><a href="#relationships-between-variables-regression" id="toc-relationships-between-variables-regression" class="nav-link" data-scroll-target="#relationships-between-variables-regression">4. Relationships Between Variables: Regression</a>
  <ul class="collapse">
  <li><a href="#introduction-to-regression" id="toc-introduction-to-regression" class="nav-link" data-scroll-target="#introduction-to-regression">4.1 Introduction to Regression</a></li>
  <li><a href="#simple-linear-regression" id="toc-simple-linear-regression" class="nav-link" data-scroll-target="#simple-linear-regression">4.2 Simple Linear Regression</a>
  <ul class="collapse">
  <li><a href="#the-linear-regression-model" id="toc-the-linear-regression-model" class="nav-link" data-scroll-target="#the-linear-regression-model">4.2.1 The Linear Regression Model</a></li>
  <li><a href="#when-to-use-simple-linear-regression" id="toc-when-to-use-simple-linear-regression" class="nav-link" data-scroll-target="#when-to-use-simple-linear-regression">4.2.2 When to Use Simple Linear Regression</a></li>
  <li><a href="#correlation-vs.-regression" id="toc-correlation-vs.-regression" class="nav-link" data-scroll-target="#correlation-vs.-regression">4.2.3 Correlation vs.&nbsp;Regression</a></li>
  <li><a href="#key-assumptions-of-simple-linear-regression" id="toc-key-assumptions-of-simple-linear-regression" class="nav-link" data-scroll-target="#key-assumptions-of-simple-linear-regression">4.2.4 Key Assumptions of Simple Linear Regression</a></li>
  <li><a href="#interpretation-of-regression-results" id="toc-interpretation-of-regression-results" class="nav-link" data-scroll-target="#interpretation-of-regression-results">4.2.5 Interpretation of Regression Results</a></li>
  </ul></li>
  <li><a href="#multiple-linear-regression" id="toc-multiple-linear-regression" class="nav-link" data-scroll-target="#multiple-linear-regression">4.3 Multiple Linear Regression</a>
  <ul class="collapse">
  <li><a href="#the-multiple-regression-model" id="toc-the-multiple-regression-model" class="nav-link" data-scroll-target="#the-multiple-regression-model">4.3.1 The Multiple Regression Model</a></li>
  <li><a href="#when-to-use-multiple-regression" id="toc-when-to-use-multiple-regression" class="nav-link" data-scroll-target="#when-to-use-multiple-regression">4.3.2 When to Use Multiple Regression</a></li>
  <li><a href="#unique-and-shared-variance" id="toc-unique-and-shared-variance" class="nav-link" data-scroll-target="#unique-and-shared-variance">4.3.3 Unique and Shared Variance</a></li>
  <li><a href="#multicollinearity" id="toc-multicollinearity" class="nav-link" data-scroll-target="#multicollinearity">4.3.4 Multicollinearity</a></li>
  <li><a href="#categorical-predictors" id="toc-categorical-predictors" class="nav-link" data-scroll-target="#categorical-predictors">4.3.5 Categorical Predictors</a></li>
  <li><a href="#model-selection-and-evaluation" id="toc-model-selection-and-evaluation" class="nav-link" data-scroll-target="#model-selection-and-evaluation">4.3.6 Model Selection and Evaluation</a></li>
  <li><a href="#interpretation-of-multiple-regression-results" id="toc-interpretation-of-multiple-regression-results" class="nav-link" data-scroll-target="#interpretation-of-multiple-regression-results">4.3.7 Interpretation of Multiple Regression Results</a></li>
  </ul></li>
  <li><a href="#logistic-regression" id="toc-logistic-regression" class="nav-link" data-scroll-target="#logistic-regression">4.4 Logistic Regression</a>
  <ul class="collapse">
  <li><a href="#the-logistic-regression-model" id="toc-the-logistic-regression-model" class="nav-link" data-scroll-target="#the-logistic-regression-model">4.4.1 The Logistic Regression Model</a></li>
  <li><a href="#when-to-use-logistic-regression" id="toc-when-to-use-logistic-regression" class="nav-link" data-scroll-target="#when-to-use-logistic-regression">4.4.2 When to Use Logistic Regression</a></li>
  <li><a href="#interpretation-of-logistic-regression-results" id="toc-interpretation-of-logistic-regression-results" class="nav-link" data-scroll-target="#interpretation-of-logistic-regression-results">4.4.3 Interpretation of Logistic Regression Results</a></li>
  <li><a href="#model-evaluation-in-logistic-regression" id="toc-model-evaluation-in-logistic-regression" class="nav-link" data-scroll-target="#model-evaluation-in-logistic-regression">4.4.4 Model Evaluation in Logistic Regression</a></li>
  </ul></li>
  <li><a href="#summary-2" id="toc-summary-2" class="nav-link" data-scroll-target="#summary-2">4.5 Summary</a></li>
  </ul></li>
  <li><a href="#mediation-and-moderation-analysis" id="toc-mediation-and-moderation-analysis" class="nav-link" data-scroll-target="#mediation-and-moderation-analysis">5. Mediation and Moderation Analysis</a>
  <ul class="collapse">
  <li><a href="#introduction-to-mediation-and-moderation" id="toc-introduction-to-mediation-and-moderation" class="nav-link" data-scroll-target="#introduction-to-mediation-and-moderation">5.1 Introduction to Mediation and Moderation</a></li>
  <li><a href="#mediation-analysis" id="toc-mediation-analysis" class="nav-link" data-scroll-target="#mediation-analysis">5.2 Mediation Analysis</a>
  <ul class="collapse">
  <li><a href="#the-mediation-model" id="toc-the-mediation-model" class="nav-link" data-scroll-target="#the-mediation-model">5.2.1 The Mediation Model</a></li>
  <li><a href="#testing-mediation" id="toc-testing-mediation" class="nav-link" data-scroll-target="#testing-mediation">5.2.2 Testing Mediation</a></li>
  <li><a href="#types-of-mediation" id="toc-types-of-mediation" class="nav-link" data-scroll-target="#types-of-mediation">5.2.3 Types of Mediation</a></li>
  <li><a href="#statistical-power-and-sample-size" id="toc-statistical-power-and-sample-size" class="nav-link" data-scroll-target="#statistical-power-and-sample-size">5.2.4 Statistical Power and Sample Size</a></li>
  <li><a href="#causal-inference-in-mediation" id="toc-causal-inference-in-mediation" class="nav-link" data-scroll-target="#causal-inference-in-mediation">5.2.5 Causal Inference in Mediation</a></li>
  </ul></li>
  <li><a href="#moderation-analysis" id="toc-moderation-analysis" class="nav-link" data-scroll-target="#moderation-analysis">5.3 Moderation Analysis</a>
  <ul class="collapse">
  <li><a href="#the-moderation-model" id="toc-the-moderation-model" class="nav-link" data-scroll-target="#the-moderation-model">5.3.1 The Moderation Model</a></li>
  <li><a href="#testing-moderation" id="toc-testing-moderation" class="nav-link" data-scroll-target="#testing-moderation">5.3.2 Testing Moderation</a></li>
  <li><a href="#probing-and-interpreting-interactions" id="toc-probing-and-interpreting-interactions" class="nav-link" data-scroll-target="#probing-and-interpreting-interactions">5.3.3 Probing and Interpreting Interactions</a></li>
  <li><a href="#types-of-moderators" id="toc-types-of-moderators" class="nav-link" data-scroll-target="#types-of-moderators">5.3.4 Types of Moderators</a></li>
  </ul></li>
  <li><a href="#conditional-process-models" id="toc-conditional-process-models" class="nav-link" data-scroll-target="#conditional-process-models">5.4 Conditional Process Models</a>
  <ul class="collapse">
  <li><a href="#examples-of-conditional-process-models" id="toc-examples-of-conditional-process-models" class="nav-link" data-scroll-target="#examples-of-conditional-process-models">5.4.1 Examples of Conditional Process Models</a></li>
  <li><a href="#testing-conditional-process-models" id="toc-testing-conditional-process-models" class="nav-link" data-scroll-target="#testing-conditional-process-models">5.4.2 Testing Conditional Process Models</a></li>
  <li><a href="#index-of-moderated-mediation" id="toc-index-of-moderated-mediation" class="nav-link" data-scroll-target="#index-of-moderated-mediation">5.4.3 Index of Moderated Mediation</a></li>
  </ul></li>
  <li><a href="#practical-considerations" id="toc-practical-considerations" class="nav-link" data-scroll-target="#practical-considerations">5.5 Practical Considerations</a>
  <ul class="collapse">
  <li><a href="#sample-size-and-power" id="toc-sample-size-and-power" class="nav-link" data-scroll-target="#sample-size-and-power">5.5.1 Sample Size and Power</a></li>
  <li><a href="#measurement-quality" id="toc-measurement-quality" class="nav-link" data-scroll-target="#measurement-quality">5.5.2 Measurement Quality</a></li>
  <li><a href="#theory-driven-vs.-exploratory-analysis" id="toc-theory-driven-vs.-exploratory-analysis" class="nav-link" data-scroll-target="#theory-driven-vs.-exploratory-analysis">5.5.3 Theory-Driven vs.&nbsp;Exploratory Analysis</a></li>
  <li><a href="#reporting-results" id="toc-reporting-results" class="nav-link" data-scroll-target="#reporting-results">5.5.4 Reporting Results</a></li>
  </ul></li>
  <li><a href="#summary-3" id="toc-summary-3" class="nav-link" data-scroll-target="#summary-3">5.6 Summary</a></li>
  </ul></li>
  <li><a href="#practical-considerations-1" id="toc-practical-considerations-1" class="nav-link" data-scroll-target="#practical-considerations-1">6. Practical Considerations</a>
  <ul class="collapse">
  <li><a href="#statistical-power-and-sample-size-planning" id="toc-statistical-power-and-sample-size-planning" class="nav-link" data-scroll-target="#statistical-power-and-sample-size-planning">6.1 Statistical Power and Sample Size Planning</a>
  <ul class="collapse">
  <li><a href="#factors-affecting-statistical-power" id="toc-factors-affecting-statistical-power" class="nav-link" data-scroll-target="#factors-affecting-statistical-power">6.1.1 Factors Affecting Statistical Power</a></li>
  <li><a href="#a-priori-power-analysis" id="toc-a-priori-power-analysis" class="nav-link" data-scroll-target="#a-priori-power-analysis">6.1.2 A Priori Power Analysis</a></li>
  <li><a href="#effect-size-conventions-and-considerations" id="toc-effect-size-conventions-and-considerations" class="nav-link" data-scroll-target="#effect-size-conventions-and-considerations">6.1.3 Effect Size Conventions and Considerations</a></li>
  </ul></li>
  <li><a href="#missing-data" id="toc-missing-data" class="nav-link" data-scroll-target="#missing-data">6.2 Missing Data</a>
  <ul class="collapse">
  <li><a href="#missing-data-mechanisms" id="toc-missing-data-mechanisms" class="nav-link" data-scroll-target="#missing-data-mechanisms">6.2.1 Missing Data Mechanisms</a></li>
  <li><a href="#missing-data-handling-strategies" id="toc-missing-data-handling-strategies" class="nav-link" data-scroll-target="#missing-data-handling-strategies">6.2.2 Missing Data Handling Strategies</a></li>
  <li><a href="#recommendations-for-handling-missing-data" id="toc-recommendations-for-handling-missing-data" class="nav-link" data-scroll-target="#recommendations-for-handling-missing-data">6.2.3 Recommendations for Handling Missing Data</a></li>
  </ul></li>
  <li><a href="#effect-size-interpretation-in-clinical-contexts" id="toc-effect-size-interpretation-in-clinical-contexts" class="nav-link" data-scroll-target="#effect-size-interpretation-in-clinical-contexts">6.3 Effect Size Interpretation in Clinical Contexts</a>
  <ul class="collapse">
  <li><a href="#beyond-cohens-conventions" id="toc-beyond-cohens-conventions" class="nav-link" data-scroll-target="#beyond-cohens-conventions">6.3.1 Beyond Cohen’s Conventions</a></li>
  <li><a href="#clinical-significance" id="toc-clinical-significance" class="nav-link" data-scroll-target="#clinical-significance">6.3.2 Clinical Significance</a></li>
  </ul></li>
  <li><a href="#reporting-results-in-apa-format" id="toc-reporting-results-in-apa-format" class="nav-link" data-scroll-target="#reporting-results-in-apa-format">6.4 Reporting Results in APA Format</a>
  <ul class="collapse">
  <li><a href="#general-reporting-guidelines" id="toc-general-reporting-guidelines" class="nav-link" data-scroll-target="#general-reporting-guidelines">6.4.1 General Reporting Guidelines</a></li>
  <li><a href="#apa-formatting-for-common-tests" id="toc-apa-formatting-for-common-tests" class="nav-link" data-scroll-target="#apa-formatting-for-common-tests">6.4.2 APA Formatting for Common Tests</a></li>
  <li><a href="#tables-and-figures" id="toc-tables-and-figures" class="nav-link" data-scroll-target="#tables-and-figures">6.4.3 Tables and Figures</a></li>
  </ul></li>
  <li><a href="#common-misinterpretations-and-pitfalls" id="toc-common-misinterpretations-and-pitfalls" class="nav-link" data-scroll-target="#common-misinterpretations-and-pitfalls">6.5 Common Misinterpretations and Pitfalls</a>
  <ul class="collapse">
  <li><a href="#misinterpreting-p-values" id="toc-misinterpreting-p-values" class="nav-link" data-scroll-target="#misinterpreting-p-values">6.5.1 Misinterpreting p-values</a></li>
  <li><a href="#multiple-comparisons-problem" id="toc-multiple-comparisons-problem" class="nav-link" data-scroll-target="#multiple-comparisons-problem">6.5.2 Multiple Comparisons Problem</a></li>
  <li><a href="#confusing-correlation-with-causation" id="toc-confusing-correlation-with-causation" class="nav-link" data-scroll-target="#confusing-correlation-with-causation">6.5.3 Confusing Correlation with Causation</a></li>
  <li><a href="#overreliance-on-significance-testing" id="toc-overreliance-on-significance-testing" class="nav-link" data-scroll-target="#overreliance-on-significance-testing">6.5.4 Overreliance on Significance Testing</a></li>
  <li><a href="#recommendations-for-avoiding-pitfalls" id="toc-recommendations-for-avoiding-pitfalls" class="nav-link" data-scroll-target="#recommendations-for-avoiding-pitfalls">6.5.5 Recommendations for Avoiding Pitfalls</a></li>
  </ul></li>
  <li><a href="#summary-4" id="toc-summary-4" class="nav-link" data-scroll-target="#summary-4">6.6 Summary</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Interactive Statistics for Clinical Psychology</h1>
<p class="subtitle lead">A Conceptual Guide for Doctoral Students</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>William Goette, Ph.D. </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 10, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="interactive-statistics-for-clinical-psychology" class="level1">
<h1>Interactive Statistics for Clinical Psychology</h1>
<section id="preface" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="preface">Preface</h2>
<p>This interactive guide is designed to support clinical psychology doctoral students who need to develop a solid foundation in statistics. The material focuses on conceptual understanding rather than mathematical derivations, with interactive elements that allow you to manipulate parameters and see how results change. This approach helps build intuition about statistical concepts that is crucial for interpreting and designing research in clinical psychology.</p>
<p>Each section includes:</p>
<ul>
<li>Clear explanations using psychology-relevant examples</li>
<li>Interactive applications to visualize key concepts</li>
<li>Discussions of when to use each test and how to check assumptions</li>
<li>Guidance on interpreting and reporting results</li>
</ul>
</section>
<section id="how-to-use-this-guide" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="how-to-use-this-guide">How to Use This Guide</h2>
<p>Throughout this document, you’ll find interactive applications created with R and Shiny. These applications run directly in your web browser - no server or installation is needed. Experiment with different parameters to see how statistical outcomes change. This hands-on exploration is a powerful way to develop statistical intuition.</p>
<p>Special formatting is used to highlight important concepts:</p>
<div class="key-concepts">
<p><strong>Key Concepts</strong> boxes appear at the beginning of each chapter, summarizing the most important ideas.</p>
</div>
<div class="margin-note">
<p><strong>Margin notes</strong> provide definitions and additional information.</p>
</div>
<div class="definition">
<p><strong>Definition</strong> boxes provide formal definitions of important terms.</p>
</div>
<div class="example">
<p><strong>Examples</strong> illustrate concepts with clinical psychology applications.</p>
</div>
<div class="practice">
<p><strong>Practice</strong> sections offer opportunities to test your understanding.</p>
</div>
<hr>
</section>
</section>
<section id="introduction-to-statistical-thinking" class="level1 unnumbered">
<h1 class="unnumbered">1. Introduction to Statistical Thinking</h1>
<div class="key-concepts">
<p><strong>Key Concepts:</strong></p>
<ul>
<li>The distinction between populations and samples</li>
<li>Probability distributions and their characteristics</li>
<li>The Central Limit Theorem and its importance</li>
<li>The foundation of hypothesis testing</li>
<li>Statistical significance vs.&nbsp;clinical significance</li>
<li>Type I and Type II errors</li>
</ul>
</div>
<p>Statistics forms the backbone of evidence-based practice in clinical psychology. By understanding statistical concepts, clinical psychologists can rigorously evaluate treatments, interpret research findings, and make informed decisions about patient care. This chapter introduces fundamental statistical concepts that will serve as the foundation for the more advanced methods covered in later chapters.</p>
<section id="populations-and-samples" class="level2">
<h2 class="anchored" data-anchor-id="populations-and-samples">1.1 Populations and Samples</h2>
<p>At the heart of statistical thinking is the recognition that we rarely have access to data from an entire population. Instead, we work with samples—smaller subsets that we hope represent the broader population of interest.</p>
<div class="margin-note">
<p><strong>Population:</strong> The entire group of individuals or observations about which we want to draw conclusions.</p>
</div>
<div class="margin-note">
<p><strong>Sample:</strong> A subset of the population selected for study.</p>
</div>
<p>In clinical psychology, populations may include all individuals with a particular diagnosis (e.g., all people with Major Depressive Disorder), all clients receiving a specific treatment (e.g., everyone undergoing Cognitive Processing Therapy for PTSD), or all therapists practicing a certain therapeutic approach. The population could be conceptual (all possible clients with a condition) or defined (all patients at a particular clinic).</p>
<p>When conducting research, practical constraints like time, resources, and accessibility mean we can only include a limited number of participants—our sample. We then use statistical methods to make inferences about the broader population from which the sample was drawn.</p>
<div class="definition">
<p><strong>Sampling:</strong> The process of selecting a subset of individuals from a population to estimate characteristics of the whole population.</p>
</div>
<p>The relationship between samples and populations is fundamental to statistical inference. We use information from our sample to make educated guesses about the population. The accuracy of these guesses depends on:</p>
<ol type="1">
<li><p><strong>Sample size:</strong> Larger samples generally provide more accurate estimates because they capture more of the population’s variability. For instance, a treatment study with 200 participants will usually yield more reliable conclusions than one with 20 participants.</p></li>
<li><p><strong>Representativeness:</strong> How well the sample reflects the characteristics of the population. A clinical trial conducted only with college students may not generalize well to older adults or individuals with comorbid conditions.</p></li>
<li><p><strong>Sampling method:</strong> How participants were selected for inclusion. Probability sampling methods (like random sampling) generally produce more representative samples than convenience sampling.</p></li>
<li><p><strong>Sampling variability:</strong> The natural variation that occurs between different samples from the same population. This variation underlies many statistical concepts, including confidence intervals and p-values.</p></li>
</ol>
<div class="example">
<p><strong>Clinical Example:</strong> A researcher wants to study the effectiveness of cognitive-behavioral therapy (CBT) for social anxiety disorder. The population of interest is all individuals with social anxiety disorder worldwide—millions of people with diverse backgrounds and characteristics.</p>
<p>The researcher recruits 40 participants from a university counseling center. This sample has several limitations:</p>
<ul>
<li>It consists primarily of young adults in higher education</li>
<li>It represents only those seeking treatment at this particular center</li>
<li>It may exclude those with severe symptoms who couldn’t attend university</li>
<li>It likely lacks socioeconomic and cultural diversity</li>
</ul>
<p>When analyzing results, the researcher must consider how these sampling limitations might affect the generalizability of findings. Perhaps the treatment shows excellent results in this sample, but would it work as well for middle-aged adults with longstanding social anxiety who never attended college? The researcher should acknowledge these constraints when discussing the study’s implications.</p>
</div>
<p>In clinical practice, we constantly make inferences from samples to populations. When reading a clinical trial of a new therapy that found positive outcomes in a sample of 100 patients, we’re using statistical inference when we consider applying that treatment to our own patients who weren’t in the original study.</p>
</section>
<section id="probability-distributions" class="level2">
<h2 class="anchored" data-anchor-id="probability-distributions">1.2 Probability Distributions</h2>
<p>Statistics relies heavily on probability distributions, which describe the likelihood of different outcomes occurring. Understanding these distributions is crucial for making sense of statistical tests and interpreting research findings in clinical psychology.</p>
<div class="margin-note">
<p><strong>Probability distribution:</strong> A mathematical function that gives the probabilities of different possible outcomes for an experiment or random variable.</p>
</div>
<section id="the-normal-distribution" class="level3">
<h3 class="anchored" data-anchor-id="the-normal-distribution">1.2.1 The Normal Distribution</h3>
<p>The normal distribution (also known as the Gaussian distribution or “bell curve”) is perhaps the most important distribution in statistics. Many psychological variables approximately follow a normal distribution, including IQ scores, personality traits, and many symptom measures.</p>
<div class="definition">
<p><strong>Normal Distribution:</strong> A symmetric, bell-shaped distribution defined by its mean (<span class="math inline">\(\mu\)</span>) and standard deviation (<span class="math inline">\(\sigma\)</span>). About 68% of the data falls within one standard deviation of the mean, 95% within two standard deviations, and 99.7% within three standard deviations (known as the 68-95-99.7 rule or the empirical rule).</p>
</div>
<p>The probability density function for the normal distribution is:</p>
<p><span class="math display">\[f(x) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\mu\)</span> is the mean (determining the center of the distribution)</li>
<li><span class="math inline">\(\sigma\)</span> is the standard deviation (determining the spread or width of the distribution)</li>
<li><span class="math inline">\(e\)</span> is the mathematical constant approximately equal to 2.71828</li>
<li><span class="math inline">\(\pi\)</span> is the mathematical constant approximately equal to 3.14159</li>
</ul>
<p>The normal distribution has several important properties:</p>
<ul>
<li>It is symmetric around its mean (the left side is a mirror image of the right)</li>
<li>The mean, median, and mode are all equal</li>
<li>Its shape is completely determined by two parameters: the mean and standard deviation</li>
<li>The total area under the curve equals 1 (representing 100% of possible values)</li>
</ul>
<p>In clinical psychology, we often assume that many variables follow a normal distribution. For example:</p>
<ol type="1">
<li><p><strong>Assessment scores:</strong> Most standardized psychological tests (like the Beck Depression Inventory, WAIS-IV, or MMPI-2) are constructed so that scores in the normative population follow approximately normal distributions.</p></li>
<li><p><strong>Symptom severity:</strong> Within diagnostic categories, symptom severity often follows a roughly normal distribution, with most people experiencing moderate symptom levels and fewer experiencing very mild or very severe symptoms.</p></li>
<li><p><strong>Treatment responses:</strong> Individual differences in response to psychological interventions often follow normal distributions, with most people showing moderate improvement and fewer showing either minimal response or dramatic improvement.</p></li>
</ol>
<p>Understanding the normal distribution allows clinicians to contextualize individual scores. For instance, if a client scores 1.5 standard deviations above the mean on an anxiety measure, the clinician can quickly recognize this places them at approximately the 93rd percentile of the reference population—providing useful context for interpreting symptom severity.</p>
</section>
<section id="the-standard-normal-distribution" class="level3">
<h3 class="anchored" data-anchor-id="the-standard-normal-distribution">1.2.2 The Standard Normal Distribution</h3>
<p>The standard normal distribution is a special case of the normal distribution with a mean of 0 and a standard deviation of 1. We denote values from the standard normal distribution as <span class="math inline">\(z\)</span>-scores.</p>
<p>Converting a value <span class="math inline">\(x\)</span> from a normal distribution to a <span class="math inline">\(z\)</span>-score enables us to determine its relative position within any normal distribution:</p>
<p><span class="math display">\[z = \frac{x - \mu}{\sigma}\]</span></p>
<div class="example">
<p><strong>Clinical Example:</strong> A client takes the Beck Depression Inventory-II, scoring 29 points. The BDI-II has a mean of 13.5 and standard deviation of 9.3 in an adult outpatient population.</p>
<p>To determine how this client’s score compares to the reference population:</p>
<p><span class="math display">\[z = \frac{29 - 13.5}{9.3} = \frac{15.5}{9.3} = 1.67\]</span></p>
<p>This <span class="math inline">\(z\)</span>-score of 1.67 indicates the client’s depression score is 1.67 standard deviations above the mean. Consulting a <span class="math inline">\(z\)</span>-table or calculator, we find this corresponds to approximately the 95th percentile, meaning about 95% of outpatients score lower and 5% score higher. This suggests relatively severe depression symptoms compared to the reference population.</p>
</div>
<p>The ability to convert to standard scores is fundamental in clinical assessment, allowing clinicians to meaningfully compare scores across different measures and interpret them relative to appropriate reference groups.</p>
</section>
<section id="other-important-distributions" class="level3">
<h3 class="anchored" data-anchor-id="other-important-distributions">1.2.3 Other Important Distributions</h3>
<p>While the normal distribution is central to many statistical tests, other distributions are also important in statistical analysis for clinical psychology:</p>
<ul>
<li><p><strong><span class="math inline">\(t\)</span>-distribution:</strong> Similar to the normal distribution but with heavier tails (more values in the extremes). It’s used when sample sizes are small and the population standard deviation is unknown. The <span class="math inline">\(t\)</span>-distribution approaches the normal distribution as sample size increases.</p>
<p>The <span class="math inline">\(t\)</span>-distribution has a single parameter called degrees of freedom (df), which affects its shape. With smaller df, the tails are heavier; as df increases, it approaches the normal distribution.</p>
<p>In clinical research, the <span class="math inline">\(t\)</span>-distribution is used for:</p>
<ul>
<li>Comparing treatment outcomes between groups (<span class="math inline">\(t\)</span>-tests)</li>
<li>Testing whether regression coefficients differ from zero</li>
<li>Constructing confidence intervals with small samples</li>
</ul></li>
<li><p><strong><span class="math inline">\(F\)</span>-distribution:</strong> Used in analysis of variance (ANOVA) and regression analysis to compare variances. It’s always positive and right-skewed.</p>
<p>The <span class="math inline">\(F\)</span>-distribution is essential for:</p>
<ul>
<li>Comparing treatment effects across multiple groups (ANOVA)</li>
<li>Testing overall significance of regression models</li>
<li>Comparing nested statistical models</li>
</ul></li>
<li><p><strong>Chi-square (<span class="math inline">\(\chi^2\)</span>) distribution:</strong> Used for categorical data analysis and testing goodness-of-fit. Like the <span class="math inline">\(F\)</span>-distribution, it’s always positive and generally right-skewed.</p>
<p>Clinical researchers use the chi-square distribution for:</p>
<ul>
<li>Analyzing contingency tables (e.g., testing if treatment response differs by diagnostic category)</li>
<li>Testing whether observed frequencies match expected frequencies</li>
<li>Assessing model fit in structural equation modeling</li>
</ul></li>
<li><p><strong>Binomial distribution:</strong> Models the number of successes in a fixed number of independent trials with the same probability of success.</p>
<p>In clinical contexts, the binomial distribution applies to:</p>
<ul>
<li>Modeling the number of patients who respond to treatment</li>
<li>Analyzing dichotomous outcomes (improved/not improved)</li>
<li>Calculating confidence intervals for proportions</li>
</ul></li>
</ul>
<p>Understanding which distribution applies to a particular statistical test helps clinical researchers correctly interpret results and determine appropriate analysis strategies.</p>
<p>The following interactive application lets you visualize these different probability distributions and their relevance to clinical psychology:</p>
<div style="width:175%; margin-left:-75%; position:relative; overflow:visible;">
<pre class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 700

library(shiny)
library(ggplot2)

ui &lt;- fluidPage(
  titlePanel("Probability Distributions in Statistics"),
  
  sidebarLayout(
    sidebarPanel(
      width = 3,
      
      # Distribution selection
      selectInput("dist_type", "Distribution Type:",
                choices = c("Normal" = "normal",
                           "t" = "t",
                           "F" = "f",
                           "Chi-square" = "chi_sq",
                           "Binomial" = "binom"),
                selected = "normal"),
      
      # Parameters for Normal distribution
      conditionalPanel(
        condition = "input.dist_type == 'normal'",
        sliderInput("normal_mean", "Mean (μ):", min = -5, max = 5, value = 0, step = 0.5),
        sliderInput("normal_sd", "Standard Deviation (σ):", min = 0.1, max = 3, value = 1, step = 0.1)
      ),
      
      # Parameters for t distribution
      conditionalPanel(
        condition = "input.dist_type == 't'",
        sliderInput("t_df", "Degrees of Freedom:", min = 1, max = 30, value = 5, step = 1)
      ),
      
      # Parameters for F distribution
      conditionalPanel(
        condition = "input.dist_type == 'f'",
        sliderInput("f_df1", "df₁ (numerator):", min = 1, max = 20, value = 3, step = 1),
        sliderInput("f_df2", "df₂ (denominator):", min = 2, max = 50, value = 20, step = 1)
      ),
      
      # Parameters for Chi-square distribution
      conditionalPanel(
        condition = "input.dist_type == 'chi_sq'",
        sliderInput("chi_df", "Degrees of Freedom:", min = 1, max = 20, value = 3, step = 1)
      ),
      
      # Parameters for Binomial distribution
      conditionalPanel(
        condition = "input.dist_type == 'binom'",
        sliderInput("binom_n", "Number of Trials (n):", min = 1, max = 50, value = 20, step = 1),
        sliderInput("binom_p", "Probability of Success (p):", min = 0.01, max = 0.99, value = 0.5, step = 0.01)
      )
    ),
    
    mainPanel(
      width = 9,
      
      # Distribution plot
      plotOutput("distPlot", height = "350px"),
      
      # Formula and explanation
      div(class = "well well-sm",
          uiOutput("formula")
      ),
      
      # Distribution properties
      div(class = "panel panel-default",
        div(class = "panel-heading", h4("Distribution Properties")),
        div(class = "panel-body", uiOutput("distribution_info"))
      )
    )
  )
)

server &lt;- function(input, output, session) {
  
  # Generate distribution plot
  output$distPlot &lt;- renderPlot({
    
    # Normal distribution
    if (input$dist_type == "normal") {
      mu &lt;- input$normal_mean
      sigma &lt;- input$normal_sd
      
      # Create x range for normal distribution
      x &lt;- seq(mu - 4*sigma, mu + 4*sigma, length.out = 1000)
      y &lt;- dnorm(x, mean = mu, sd = sigma)
      
      # Create data frame for plotting
      plot_data &lt;- data.frame(x = x, y = y)
      
      # Create the plot
      p &lt;- ggplot(plot_data, aes(x = x, y = y)) +
        geom_line(size = 1.2, color = "steelblue") +
        labs(title = "Normal Distribution",
             subtitle = paste0("μ = ", mu, ", σ = ", sigma),
             x = "Value",
             y = "Probability Density") +
        theme_minimal() +
        theme(plot.title = element_text(face = "bold", size = 16),
              plot.subtitle = element_text(size = 12))
      
      # Add critical values
      crit_lo &lt;- qnorm(0.025, mean = mu, sd = sigma)
      crit_hi &lt;- qnorm(0.975, mean = mu, sd = sigma)
      
      p &lt;- p + 
        geom_vline(xintercept = c(crit_lo, crit_hi), linetype = "dashed", color = "purple") +
        annotate("text", x = crit_lo, y = max(y)*0.6, label = "2.5%", color = "purple", angle = 90) +
        annotate("text", x = crit_hi, y = max(y)*0.6, label = "97.5%", color = "purple", angle = 90)
      
      p
      
    } 
    # t distribution
    else if (input$dist_type == "t") {
      df &lt;- input$t_df
      
      # Create x range for t distribution
      x &lt;- seq(-6, 6, length.out = 1000)
      y &lt;- dt(x, df = df)
      
      # For comparison, add standard normal density
      y_norm &lt;- dnorm(x)
      
      # Create data frame for plotting
      plot_data &lt;- data.frame(x = x, y = y, y_norm = y_norm)
      
      # Create the plot
      p &lt;- ggplot(plot_data) +
        geom_line(aes(x = x, y = y, color = "t-distribution"), size = 1.2) +
        geom_line(aes(x = x, y = y_norm, color = "Normal distribution"), 
                 size = 1.2, linetype = "dashed") +
        labs(title = "t-Distribution",
             subtitle = paste0("df = ", df),
             x = "Value",
             y = "Probability Density") +
        scale_color_manual(values = c("t-distribution" = "firebrick", 
                                    "Normal distribution" = "steelblue"),
                          name = "") +
        theme_minimal() +
        theme(plot.title = element_text(face = "bold", size = 16),
              plot.subtitle = element_text(size = 12),
              legend.position = "top")
      
      # Add critical values
      crit_lo &lt;- qt(0.025, df = df)
      crit_hi &lt;- qt(0.975, df = df)
      
      p &lt;- p + 
        geom_vline(xintercept = c(crit_lo, crit_hi), linetype = "dashed", color = "purple") +
        annotate("text", x = crit_lo, y = max(y)*0.6, label = "2.5%", color = "purple", angle = 90) +
        annotate("text", x = crit_hi, y = max(y)*0.6, label = "97.5%", color = "purple", angle = 90)
      
      p
    } 
    # F distribution
    else if (input$dist_type == "f") {
      df1 &lt;- input$f_df1
      df2 &lt;- input$f_df2
      
      # Create x range for F distribution
      x_max &lt;- qf(0.999, df1 = df1, df2 = df2)
      x &lt;- seq(0, x_max, length.out = 1000)
      y &lt;- df(x, df1 = df1, df2 = df2)
      
      # Create data frame for plotting
      plot_data &lt;- data.frame(x = x, y = y)
      
      # Create the plot
      p &lt;- ggplot(plot_data, aes(x = x, y = y)) +
        geom_line(size = 1.2, color = "darkgreen") +
        labs(title = "F-Distribution",
             subtitle = paste0("df₁ = ", df1, ", df₂ = ", df2),
             x = "Value",
             y = "Probability Density") +
        theme_minimal() +
        theme(plot.title = element_text(face = "bold", size = 16),
              plot.subtitle = element_text(size = 12))
      
      # Add critical value
      crit &lt;- qf(0.95, df1 = df1, df2 = df2)
      
      p &lt;- p + 
        geom_vline(xintercept = crit, linetype = "dashed", color = "purple") +
        annotate("text", x = crit, y = max(y)*0.6, label = "5%", color = "purple", angle = 90)
      
      p
    } 
    # Chi-square distribution
    else if (input$dist_type == "chi_sq") {
      df &lt;- input$chi_df
      
      # Create x range for chi-square distribution
      x_max &lt;- qchisq(0.999, df = df)
      x &lt;- seq(0, x_max, length.out = 1000)
      y &lt;- dchisq(x, df = df)
      
      # Create data frame for plotting
      plot_data &lt;- data.frame(x = x, y = y)
      
      # Create the plot
      p &lt;- ggplot(plot_data, aes(x = x, y = y)) +
        geom_line(size = 1.2, color = "darkorange") +
        labs(title = "Chi-square Distribution",
             subtitle = paste0("df = ", df),
             x = "Value",
             y = "Probability Density") +
        theme_minimal() +
        theme(plot.title = element_text(face = "bold", size = 16),
              plot.subtitle = element_text(size = 12))
      
      # Add critical value
      crit &lt;- qchisq(0.95, df = df)
      
      p &lt;- p + 
        geom_vline(xintercept = crit, linetype = "dashed", color = "purple") +
        annotate("text", x = crit, y = max(y)*0.6, label = "5%", color = "purple", angle = 90)
      
      p
    } 
    # Binomial distribution
    else if (input$dist_type == "binom") {
      n &lt;- input$binom_n
      p &lt;- input$binom_p
      
      # Create x range for binomial distribution (0 to n)
      x &lt;- 0:n
      y &lt;- dbinom(x, size = n, prob = p)
      
      # Create data frame for plotting
      plot_data &lt;- data.frame(x = factor(x), y = y)
      
      # Create the plot
      ggplot(plot_data, aes(x = x, y = y)) +
        geom_col(fill = "purple", alpha = 0.7) +
        labs(title = "Binomial Distribution",
             subtitle = paste0("n = ", n, ", p = ", p),
             x = "Number of Successes",
             y = "Probability Mass") +
        theme_minimal() +
        theme(plot.title = element_text(face = "bold", size = 16),
              plot.subtitle = element_text(size = 12),
              axis.text.x = element_text(angle = 45, hjust = 1))
    }
  })
  
  # Generate formula and mathematical representation with improved rendering
  output$formula &lt;- renderUI({
    if (input$dist_type == "normal") {
      tagList(
        h4("Mathematical Formula:"),
        # Render equation with withMathJax as standalone
        withMathJax("$$f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}$$"),
        
        p("Where:"),
        tags$ul(
          # Separate the math and text components - note the use of Unicode characters
          tags$li(HTML("&lt;i&gt;μ&lt;/i&gt; (mu) = ", input$normal_mean, " is the mean")),
          tags$li(HTML("&lt;i&gt;σ&lt;/i&gt; (sigma) = ", input$normal_sd, " is the standard deviation"))
        )
      )
    } else if (input$dist_type == "t") {
      tagList(
        h4("Mathematical Formula:"),
        withMathJax("$$f(t) = \\frac{\\Gamma\\left(\\frac{\\nu+1}{2}\\right)}{\\sqrt{\\nu\\pi}\\,\\Gamma\\left(\\frac{\\nu}{2}\\right)}\\left(1+\\frac{t^2}{\\nu}\\right)^{-\\frac{\\nu+1}{2}}$$"),
        
        p("Where:"),
        tags$ul(
          tags$li(HTML("&lt;i&gt;ν&lt;/i&gt; (nu) = ", input$t_df, " is the degrees of freedom")),
          tags$li(HTML("&lt;i&gt;Γ&lt;/i&gt; is the gamma function"))
        ),
        p("The t-distribution approaches the normal distribution as degrees of freedom increase.")
      )
    } else if (input$dist_type == "f") {
      tagList(
        h4("Mathematical Formula:"),
        withMathJax("$$f(x) = \\frac{\\sqrt{\\frac{(d_1 x)^{d_1} d_2^{d_2}}{(d_1 x + d_2)^{d_1+d_2}}}}{x \\beta\\left(\\frac{d_1}{2}, \\frac{d_2}{2}\\right)}$$"),
        
        p("Where:"),
        tags$ul(
          tags$li(HTML("&lt;i&gt;d&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt; = ", input$f_df1, " is the numerator degrees of freedom")),
          tags$li(HTML("&lt;i&gt;d&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt; = ", input$f_df2, " is the denominator degrees of freedom")),
          tags$li(HTML("&lt;i&gt;β&lt;/i&gt; is the beta function"))
        )
      )
    } else if (input$dist_type == "chi_sq") {
      tagList(
        h4("Mathematical Formula:"),
        withMathJax("$$f(x) = \\frac{x^{k/2-1}e^{-x/2}}{2^{k/2}\\Gamma(k/2)}$$"),
        
        p("Where:"),
        tags$ul(
          tags$li(HTML("&lt;i&gt;k&lt;/i&gt; = ", input$chi_df, " is the degrees of freedom")),
          tags$li(HTML("&lt;i&gt;Γ&lt;/i&gt; is the gamma function"))
        )
      )
    } else if (input$dist_type == "binom") {
      tagList(
        h4("Mathematical Formula:"),
        withMathJax("$$P(X = k) = {n \\choose k}p^k(1-p)^{n-k}$$"),
        
        p("Where:"),
        tags$ul(
          tags$li(HTML("&lt;i&gt;n&lt;/i&gt; = ", input$binom_n, " is the number of trials")),
          tags$li(HTML("&lt;i&gt;p&lt;/i&gt; = ", input$binom_p, " is the probability of success")),
          tags$li(HTML("&lt;i&gt;k&lt;/i&gt; is the number of successes")),
          tags$li(HTML("&lt;i&gt;n choose k&lt;/i&gt; is the binomial coefficient"))
        )
      )
    }
  })
  
  # Generate distribution information with proper Unicode characters
  output$distribution_info &lt;- renderUI({
    if (input$dist_type == "normal") {
      tagList(
        h4("Normal Distribution Properties"),
        tags$ul(
          tags$li(strong("Shape:"), " Symmetric bell curve"),
          tags$li(strong("Parameters:"), HTML(" Mean (μ) = ", input$normal_mean, ", Standard Deviation (σ) = ", input$normal_sd)),
          tags$li(strong("Range:"), HTML(" -∞ to +∞")),
          tags$li(strong("Mean = Median = Mode:"), paste0(" ", input$normal_mean)),
          tags$li(strong("Variance:"), HTML(" σ² = ", input$normal_sd^2)),
          tags$li(
            strong("Empirical Rule:"),
            tags$ul(
              tags$li(HTML("68% of values fall within ±1σ (", round(input$normal_mean - input$normal_sd, 2), 
                       " to ", round(input$normal_mean + input$normal_sd, 2), ")")),
              tags$li(HTML("95% of values fall within ±2σ (", round(input$normal_mean - 2*input$normal_sd, 2), 
                       " to ", round(input$normal_mean + 2*input$normal_sd, 2), ")")),
              tags$li(HTML("99.7% of values fall within ±3σ (", round(input$normal_mean - 3*input$normal_sd, 2), 
                       " to ", round(input$normal_mean + 3*input$normal_sd, 2), ")"))
            )
          )
        ),
        
        h4("Use in Statistical Tests"),
        tags$ul(
          tags$li("Z-tests (when population parameters are known)"),
          tags$li("Large-sample t-tests and confidence intervals"),
          tags$li("Basis for many statistical methods due to the Central Limit Theorem")
        )
      )
    } else if (input$dist_type == "t") {
      tagList(
        h4("t-Distribution Properties"),
        tags$ul(
          tags$li(strong("Shape:"), " Symmetric, bell-shaped but with heavier tails than normal distribution"),
          tags$li(strong("Parameter:"), HTML(" Degrees of freedom (df) = ", input$t_df)),
          tags$li(strong("Range:"), HTML(" -∞ to +∞")),
          tags$li(strong("Mean (if df &gt; 1):"), " 0"),
          tags$li(strong("Variance (if df &gt; 2):"), HTML(" df/(df-2) = ", ifelse(input$t_df &gt; 2, round(input$t_df/(input$t_df-2), 3), "Undefined"))),
          tags$li(strong("As df increases:"), " The t-distribution approaches the standard normal distribution")
        ),
        
        h4("Use in Statistical Tests"),
        tags$ul(
          tags$li("One-sample, independent samples, and paired samples t-tests"),
          tags$li("Confidence intervals for means with unknown population standard deviation"),
          tags$li("Significance tests for regression coefficients")
        )
      )
    } else if (input$dist_type == "f") {
      tagList(
        h4("F-Distribution Properties"),
        tags$ul(
          tags$li(strong("Shape:"), " Right-skewed, always positive"),
          tags$li(strong("Parameters:"), HTML(" Numerator df (df₁) = ", input$f_df1, ", Denominator df (df₂) = ", input$f_df2)),
          tags$li(strong("Range:"), " 0 to +∞"),
          tags$li(strong("Mean (if df₂ &gt; 2):"), HTML(" df₂/(df₂-2) = ", ifelse(input$f_df2 &gt; 2, round(input$f_df2/(input$f_df2-2), 3), "Undefined"))),
          tags$li(strong("Critical Value (α = 0.05):"), paste0(" ", round(qf(0.95, df1 = input$f_df1, df2 = input$f_df2), 3)))
        ),
        
        h4("Use in Statistical Tests"),
        tags$ul(
          tags$li("Analysis of Variance (ANOVA) for comparing multiple group means"),
          tags$li("Tests for equality of variances (e.g., Levene's test)"),
          tags$li("Overall significance tests in regression analysis"),
          tags$li("Comparing nested statistical models")
        )
      )
    } else if (input$dist_type == "chi_sq") {
      tagList(
        h4("Chi-square Distribution Properties"),
        tags$ul(
          tags$li(strong("Shape:"), " Right-skewed, always positive"),
          tags$li(strong("Parameter:"), HTML(" Degrees of freedom (df) = ", input$chi_df)),
          tags$li(strong("Range:"), " 0 to +∞"),
          tags$li(strong("Mean:"), HTML(" df = ", input$chi_df)),
          tags$li(strong("Variance:"), HTML(" 2×df = ", 2*input$chi_df)),
          tags$li(strong("Critical Value (α = 0.05):"), paste0(" ", round(qchisq(0.95, df = input$chi_df), 3)))
        ),
        
        h4("Use in Statistical Tests"),
        tags$ul(
          tags$li("Chi-square tests for independence in contingency tables"),
          tags$li("Goodness-of-fit tests for categorical data"),
          tags$li("Tests for normality (e.g., as part of Shapiro-Wilk test)"),
          tags$li("Confidence intervals for variances"),
          tags$li("Model fit assessment in structural equation modeling")
        )
      )
    } else if (input$dist_type == "binom") {
      # Calculate some properties
      n &lt;- input$binom_n
      p &lt;- input$binom_p
      mean_val &lt;- n * p
      var_val &lt;- n * p * (1-p)
      mode_val &lt;- floor((n+1)*p)
      
      tagList(
        h4("Binomial Distribution Properties"),
        tags$ul(
          tags$li(strong("Shape:"), " Discrete probability distribution (not continuous)"),
          tags$li(strong("Parameters:"), HTML(" Number of trials (n) = ", n, ", Probability of success (p) = ", p)),
          tags$li(strong("Range:"), paste0(" 0, 1, 2, ..., ", n)),
          tags$li(strong("Mean:"), HTML(" np = ", mean_val)),
          tags$li(strong("Variance:"), HTML(" np(1-p) = ", var_val)),
          tags$li(strong("Mode:"), HTML(" ⌊(n+1)p⌋ = ", mode_val))
        ),
        
        h4("Use in Clinical Psychology"),
        tags$ul(
          tags$li("Modeling treatment response rates (number of responders out of n patients)"),
          tags$li("Analyzing success/failure outcomes in clinical trials"),
          tags$li("Constructing confidence intervals for proportions"),
          tags$li("Power analysis for studies with binary outcomes"),
          tags$li("Sign test (non-parametric alternative to paired t-test)")
        )
      )
    }
  })
}

shinyApp(ui, server)</code></pre>
</div>
</section>
</section>
<section id="the-central-limit-theorem" class="level2">
<h2 class="anchored" data-anchor-id="the-central-limit-theorem">1.3 The Central Limit Theorem</h2>
<p>One of the most powerful concepts in statistics is the Central Limit Theorem (CLT), which explains why the normal distribution is so prevalent and important in statistical analysis, even when our original data isn’t normally distributed.</p>
<div class="definition">
<p><strong>Central Limit Theorem:</strong> When independent random samples are drawn from any population distribution with finite variance, the sampling distribution of the sample means will approach a normal distribution as the sample size increases, regardless of the shape of the original population distribution.</p>
</div>
<p>In simpler terms, if you:</p>
<ol type="1">
<li>Take many random samples from a population</li>
<li>Calculate the mean of each sample</li>
<li>Plot the distribution of all these sample means</li>
</ol>
<p>The resulting distribution will be approximately normal, regardless of the shape of the original population distribution. This holds true even if the original population has a completely different distribution (uniform, skewed, bimodal, etc.).</p>
<section id="mathematical-formulation" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-formulation">1.3.1 Mathematical Formulation</h3>
<p>If <span class="math inline">\(X_1, X_2, ..., X_n\)</span> is a random sample from a distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, and if <span class="math inline">\(\bar{X}\)</span> is the sample mean, then as <span class="math inline">\(n\)</span> increases:</p>
<p><span class="math display">\[\bar{X} \sim N\left(\mu, \frac{\sigma^2}{n}\right)\]</span></p>
<p>This means that the sample mean <span class="math inline">\(\bar{X}\)</span> follows approximately a normal distribution with:</p>
<ul>
<li>The same mean as the original population (<span class="math inline">\(\mu\)</span>)</li>
<li>A variance equal to the population variance divided by the sample size (<span class="math inline">\(\frac{\sigma^2}{n}\)</span>)</li>
<li>A standard error (the standard deviation of the sampling distribution) equal to <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span></li>
</ul>
</section>
<section id="implications-for-clinical-research" class="level3">
<h3 class="anchored" data-anchor-id="implications-for-clinical-research">1.3.2 Implications for Clinical Research</h3>
<p>The CLT has profound implications for statistical inference in clinical psychology:</p>
<ol type="1">
<li><p><strong>Robustness of parametric tests:</strong> It allows us to use normal-based tests (like t-tests) even when we’re not certain that our data perfectly follows a normal distribution, as long as our sample size is sufficiently large.</p></li>
<li><p><strong>Sample size planning:</strong> It helps us understand how sample size affects the precision of our estimates. The standard error of the mean decreases predictably as sample size increases (<span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span>), allowing us to determine how large a sample we need to achieve a desired level of precision.</p></li>
<li><p><strong>Confidence intervals:</strong> It provides the foundation for constructing confidence intervals around means, which are essential for interpreting treatment outcomes and effect sizes.</p></li>
<li><p><strong>Interpreting group differences:</strong> It helps us understand the expected variability in sample means, which is crucial for determining whether observed differences between groups are meaningful or could have occurred by chance.</p></li>
</ol>
<div class="margin-note">
<p>A rule of thumb is that the Central Limit Theorem begins to apply when sample sizes reach about 30, though this varies depending on how non-normal the original distribution is. For highly skewed distributions, larger samples may be needed.</p>
</div>
<div class="example">
<p><strong>Clinical Example:</strong> A researcher is studying the effectiveness of a new anxiety treatment. From previous research, they know that anxiety scores in the relevant population have a somewhat skewed distribution (not normal) with a mean of 65 and standard deviation of 12.</p>
<p>If they plan to recruit a sample of 40 participants, the CLT tells us that the sampling distribution of the mean will be approximately normal with:</p>
<ul>
<li>Mean = 65 (same as the population)</li>
<li>Standard error = <span class="math inline">\(\frac{12}{\sqrt{40}} = \frac{12}{6.32} = 1.90\)</span></li>
</ul>
<p>This means that if they were to repeat their study many times with different samples of 40 participants, about 95% of the sample means would fall within approximately 65 ± 3.80 (i.e., 61.20 to 68.80).</p>
<p>This knowledge helps them design their study, interpret their results, and understand the precision of their estimates.</p>
</div>
<p>The following interactive app below lets you explore the Central Limit Theorem by simulating samples from different distributions. Take time to observe how the sampling distribution of means becomes increasingly normal as you increase the sample size, regardless of the original population distribution.</p>
<pre class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 1200

library(shiny)
library(munsell)
library(ggplot2)

ui &lt;- fluidPage(
  titlePanel("Understanding Sampling Distributions"),
  
  sidebarLayout(
    # Left side: Controls
    sidebarPanel(
      width = 3,
      
      # Collapsible section 1: Sample Parameters
      div(class = "panel panel-default",
        div(class = "panel-heading", 
            style = "cursor: pointer;",
            "data-toggle" = "collapse",
            "data-target" = "#sample_params",
            h4(icon("sliders"), "Sample Parameters", 
               span(class = "pull-right", icon("chevron-down")))
        ),
        div(id = "sample_params", class = "panel-collapse collapse in",
          div(class = "panel-body",
            sliderInput("sampleSize", "Sample Size:", 
                      min = 5, max = 100, value = 30),
            sliderInput("numSamples", "Number of Samples:", 
                      min = 1, max = 1000, value = 100)
          )
        )
      ),
      
      # Collapsible section 2: Distribution Settings
      div(class = "panel panel-default",
        div(class = "panel-heading", 
            style = "cursor: pointer;",
            "data-toggle" = "collapse",
            "data-target" = "#dist_settings",
            h4(icon("chart-area"), "Distribution Settings", 
               span(class = "pull-right", icon("chevron-down")))
        ),
        div(id = "dist_settings", class = "panel-collapse collapse in",
          div(class = "panel-body",
            selectInput("popDist", "Population Distribution:",
                      choices = c("Normal", "Uniform", "Skewed", "Bimodal"),
                      selected = "Normal"),
            actionButton("resample", "Generate New Samples", 
                        class = "btn-primary btn-block")
          )
        )
      )
    ),
    
    # Right side: Content
    mainPanel(
      width = 9,
      tabsetPanel(
        tabPanel("Distributions", plotOutput("samplingPlot", height = "500px")),
        tabPanel("Explanation", verbatimTextOutput("explanation"))
      )
    )
  )
)

server &lt;- function(input, output, session) {
  
  # Reactive expression for the data
  samples &lt;- reactiveVal(NULL)
  
  observeEvent(c(input$sampleSize, input$numSamples, input$popDist, input$resample), {
    # Generate population based on selection
    population &lt;- switch(input$popDist,
                        "Normal" = rnorm(10000, mean = 50, sd = 10),
                        "Uniform" = runif(10000, min = 30, max = 70),
                        "Skewed" = rgamma(10000, shape = 2, scale = 5) + 40,
                        "Bimodal" = c(rnorm(5000, mean = 40, sd = 5), 
                                     rnorm(5000, mean = 60, sd = 5)))
    
    # Calculate population parameters
    pop_mean &lt;- mean(population)
    pop_sd &lt;- sd(population)
    
    # Take samples
    all_samples &lt;- replicate(input$numSamples, 
                            sample(population, input$sampleSize))
    
    # Calculate means of each sample
    sample_means &lt;- apply(all_samples, 2, mean)
    
    samples(list(
      population = population,
      pop_mean = pop_mean,
      pop_sd = pop_sd,
      sample_means = sample_means,
      se_theoretical = pop_sd/sqrt(input$sampleSize)
    ))
  }, ignoreInit = FALSE)
  
  output$samplingPlot &lt;- renderPlot({
    req(samples())
    
    # Create data frames for ggplot
    df_pop &lt;- data.frame(value = samples()$population)
    df_means &lt;- data.frame(mean = samples()$sample_means)
    
    # Plot population distribution
    p1 &lt;- ggplot(df_pop, aes(x = value)) +
      geom_histogram(bins = 30, fill = "lightblue", color = "white", alpha = 0.7) +
      geom_vline(xintercept = samples()$pop_mean, color = "blue", size = 1) +
      labs(title = "Population Distribution",
           subtitle = paste("Mean =", round(samples()$pop_mean, 2), 
                           ", SD =", round(samples()$pop_sd, 2)),
           x = "Value",
           y = "Frequency") +
      theme_minimal() +
      theme(plot.title = element_text(face = "bold"))
    
    # Plot sampling distribution
    p2 &lt;- ggplot(df_means, aes(x = mean)) +
      geom_histogram(bins = 30, fill = "steelblue", color = "white", alpha = 0.7) +
      geom_vline(xintercept = samples()$pop_mean, color = "red", linetype = "dashed", size = 1) +
      geom_vline(xintercept = mean(df_means$mean), color = "green", size = 1) +
      stat_function(
        fun = function(x) dnorm(x, mean = samples()$pop_mean, sd = samples()$se_theoretical) * 
          length(df_means$mean) * (max(df_means$mean) - min(df_means$mean))/30,
        color = "darkred", size = 1, alpha = 0.5
      ) +
      labs(title = "Sampling Distribution of the Mean",
           subtitle = paste("Mean =", round(mean(df_means$mean), 2), 
                           ", SE =", round(sd(df_means$mean), 2)),
           x = "Sample Mean",
           y = "Frequency") +
      theme_minimal() +
      theme(plot.title = element_text(face = "bold"))
    
    # Combine plots
    gridExtra::grid.arrange(p1, p2, ncol = 1)
  })
  
  output$explanation &lt;- renderText({
    req(samples())
    
    sample_means &lt;- samples()$sample_means
    se_observed &lt;- sd(sample_means)
    se_theoretical &lt;- samples()$se_theoretical
    
    paste0(
      "Observed characteristics:\n",
      "- Population mean: ", round(samples()$pop_mean, 2), "\n",
      "- Population standard deviation: ", round(samples()$pop_sd, 2), "\n",
      "- Mean of all sample means: ", round(mean(sample_means), 2), "\n",
      "- Standard deviation of sample means (SE): ", round(se_observed, 2), "\n",
      "- Theoretical SE (σ/√n): ", round(se_theoretical, 2), "\n\n",
      "This illustrates the Central Limit Theorem: regardless of the \n",
      "population distribution, the sampling distribution of the mean \n",
      "approaches a normal distribution as the sample size increases."
    )
  })
}

shinyApp(ui, server)</code></pre>
</section>
<section id="why-the-central-limit-theorem-matters-in-clinical-psychology" class="level3">
<h3 class="anchored" data-anchor-id="why-the-central-limit-theorem-matters-in-clinical-psychology">1.3.3 Why the Central Limit Theorem Matters in Clinical Psychology</h3>
<p>The CLT is particularly important in clinical psychology for several reasons:</p>
<ol type="1">
<li><p><strong>Dealing with non-normal data:</strong> Many psychological variables don’t perfectly follow normal distributions. Symptom measures often show some skewness (e.g., more people with mild symptoms than severe), and some measures have natural bounds (e.g., scores that can’t go below zero). The CLT allows us to use many parametric statistical techniques even when our raw data isn’t perfectly normal.</p></li>
<li><p><strong>Generalizing from samples:</strong> Clinical research typically involves relatively small samples drawn from larger populations of interest. The CLT helps us understand how sample statistics (like means) relate to population parameters, and how much uncertainty exists in our estimates.</p></li>
<li><p><strong>Meta-analysis:</strong> When combining results across multiple studies (meta-analysis), researchers often work with means and standard errors from different samples. The CLT provides the theoretical foundation for aggregating these results.</p></li>
<li><p><strong>Statistical power:</strong> Understanding the standard error formula (<span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span>) derived from the CLT helps researchers plan appropriately sized studies to detect meaningful effects.</p></li>
</ol>
<p>Take some time to explore the interactive demonstration above. Try different population distributions and observe how the sampling distribution becomes increasingly normal as you increase the sample size. Also notice how the standard deviation of the sampling distribution (called the standard error) decreases as the sample size increases, following the formula <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span>.</p>
</section>
</section>
<section id="hypothesis-testing" class="level2">
<h2 class="anchored" data-anchor-id="hypothesis-testing">1.4 Hypothesis Testing</h2>
<p>Hypothesis testing is the framework that underlies most statistical analyses in psychological research. It provides a systematic approach for making decisions about psychological phenomena based on sample data.</p>
<div class="definition">
<p><strong>Hypothesis Testing:</strong> A method for using sample data to evaluate a hypothesis about a population parameter.</p>
</div>
<section id="the-logic-of-hypothesis-testing" class="level3">
<h3 class="anchored" data-anchor-id="the-logic-of-hypothesis-testing">1.4.1 The Logic of Hypothesis Testing</h3>
<p>The fundamental logic of hypothesis testing involves several key concepts:</p>
<ol type="1">
<li><p><strong>Research question:</strong> We begin with a question about a population parameter (e.g., “Does this therapy reduce anxiety symptoms?”)</p></li>
<li><p><strong>Null and alternative hypotheses:</strong> We formulate two competing hypotheses:</p>
<ul>
<li><strong>Null hypothesis (H₀):</strong> A statement of “no effect” or “no difference” (e.g., “The therapy has no effect on anxiety symptoms”)</li>
<li><strong>Alternative hypothesis (H₁ or Hₐ):</strong> A statement of “effect” or “difference” (e.g., “The therapy reduces anxiety symptoms”)</li>
</ul></li>
<li><p><strong>Statistical model:</strong> We choose an appropriate statistical model and test statistic based on our research design and the type of data collected</p></li>
<li><p><strong>Sampling distribution:</strong> We determine the sampling distribution of the test statistic under the assumption that the null hypothesis is true</p></li>
<li><p><strong>Critical region:</strong> We identify the values of the test statistic that would be unlikely if the null hypothesis were true</p></li>
<li><p><strong>Decision rule:</strong> Based on our sample data, we either reject the null hypothesis (if the test statistic falls in the critical region) or fail to reject it (if it does not)</p></li>
</ol>
</section>
<section id="steps-in-hypothesis-testing" class="level3">
<h3 class="anchored" data-anchor-id="steps-in-hypothesis-testing">1.4.2 Steps in Hypothesis Testing</h3>
<p>The process typically involves several structured steps:</p>
<ol type="1">
<li><p><strong>State the hypotheses</strong></p>
<ul>
<li><p><strong>Null hypothesis (H₀):</strong> There is no effect or relationship</p>
<ul>
<li>e.g., “The mean difference in anxiety between treatment and control groups is zero” (μ₁ - μ₂ = 0)</li>
<li>e.g., “The correlation between therapeutic alliance and outcome is zero” (ρ = 0)</li>
</ul></li>
<li><p><strong>Alternative hypothesis (H₁ or Hₐ):</strong> There is an effect or relationship</p>
<ul>
<li>e.g., “The treatment group has lower anxiety than the control group” (μ₁ - μ₂ &lt; 0)</li>
<li>e.g., “There is a positive correlation between therapeutic alliance and outcome” (ρ &gt; 0)</li>
</ul></li>
</ul></li>
<li><p><strong>Choose a significance level (α)</strong></p>
<ul>
<li>This represents the probability of incorrectly rejecting the null hypothesis when it is actually true (Type I error)</li>
<li>Traditionally set at 0.05 in psychology, meaning we’re willing to accept a 5% chance of incorrectly rejecting the null hypothesis</li>
<li>The significance level determines the critical region for our test statistic</li>
</ul></li>
<li><p><strong>Collect data and compute test statistics</strong></p>
<ul>
<li>This involves calculating a statistic (e.g., t, F, χ²) from your sample data</li>
<li>The test statistic quantifies how far the observed data deviates from what would be expected under the null hypothesis</li>
<li>The formula for the test statistic depends on the specific statistical test being used</li>
</ul></li>
<li><p><strong>Determine the p-value or critical region</strong></p>
<ul>
<li>The p-value is the probability of obtaining results at least as extreme as those observed, assuming the null hypothesis is true</li>
<li>It can be interpreted as the strength of evidence against the null hypothesis</li>
<li>Smaller p-values indicate stronger evidence against the null hypothesis</li>
</ul></li>
<li><p><strong>Make a decision</strong></p>
<ul>
<li>If p &lt; α, reject the null hypothesis</li>
<li>If p ≥ α, fail to reject the null hypothesis</li>
<li>Note that “failing to reject” is not the same as “accepting” the null hypothesis</li>
</ul></li>
</ol>
<div class="margin-note">
<p><strong>p-value:</strong> The probability of obtaining results at least as extreme as those observed, assuming the null hypothesis is true. It is not the probability that the null hypothesis is true.</p>
</div>
</section>
<section id="types-of-hypothesis-tests" class="level3">
<h3 class="anchored" data-anchor-id="types-of-hypothesis-tests">1.4.3 Types of Hypothesis Tests</h3>
<p>Different types of hypothesis tests are appropriate for different research questions and data types:</p>
<ol type="1">
<li><p><strong>One-sided (directional) vs.&nbsp;Two-sided (non-directional) tests:</strong></p>
<ul>
<li><strong>One-sided test:</strong> The alternative hypothesis specifies a direction (e.g., “treatment is better than control”)</li>
<li><strong>Two-sided test:</strong> The alternative hypothesis doesn’t specify a direction (e.g., “treatment differs from control”)</li>
</ul></li>
<li><p><strong>Parametric vs.&nbsp;Non-parametric tests:</strong></p>
<ul>
<li><strong>Parametric tests:</strong> Assume data come from a specific distribution (usually normal) with certain parameters</li>
<li><strong>Non-parametric tests:</strong> Make fewer assumptions about the underlying distribution</li>
</ul></li>
<li><p><strong>Common tests in clinical psychology:</strong></p>
<ul>
<li><strong>t-tests:</strong> For comparing means between two groups or conditions</li>
<li><strong>ANOVA:</strong> For comparing means among three or more groups</li>
<li><strong>Chi-square:</strong> For analyzing categorical data</li>
<li><strong>Correlation:</strong> For examining relationships between continuous variables</li>
<li><strong>Regression:</strong> For predicting one variable from one or more other variables</li>
</ul></li>
</ol>
</section>
<section id="a-worked-example" class="level3">
<h3 class="anchored" data-anchor-id="a-worked-example">1.4.4 A Worked Example</h3>
<div class="example">
<p><strong>Clinical Example:</strong> A clinical psychologist wants to know if a new therapy reduces depression scores. They set up:</p>
<ul>
<li>H₀: The therapy has no effect on depression scores (mean difference = 0)</li>
<li>H₁: The therapy reduces depression scores (mean difference &lt; 0)</li>
</ul>
<p>They conduct a study with 25 patients, measuring depression scores before and after treatment using the Beck Depression Inventory (BDI), with these results:</p>
<ul>
<li>Mean pre-treatment score: 24.6</li>
<li>Mean post-treatment score: 18.2</li>
<li>Standard deviation of the differences: 9.3</li>
</ul>
<p>Step 1: Calculate the test statistic (paired t-test): <span class="math inline">\(t = \frac{\bar{d}}{s_d / \sqrt{n}}\)</span> <span class="math inline">\(t = \frac{24.6 - 18.2}{9.3 / \sqrt{25}}\)</span> <span class="math inline">\(t = \frac{6.4}{9.3 / 5}\)</span> <span class="math inline">\(t = \frac{6.4}{1.86}\)</span> <span class="math inline">\(t = 3.44\)</span></p>
<p>Step 2: Determine the p-value: For a one-sided test with df = 24, t = 3.44 corresponds to p = 0.001</p>
<p>Step 3: Make a decision: Since p = 0.001 &lt; α = 0.05, they reject the null hypothesis and conclude that the therapy appears to reduce depression scores.</p>
<p>Step 4: Calculate effect size (Cohen’s d): <span class="math inline">\(d = \frac{\bar{d}}{s_d} = \frac{6.4}{9.3} = 0.69\)</span></p>
<p>This represents a medium to large effect size, suggesting that the therapy not only produces statistically significant reductions in depression, but the magnitude of the effect is likely to be clinically meaningful.</p>
</div>
<p>This framework allows researchers to make decisions about population parameters based on sample data, with a quantifiable level of confidence. It’s important to remember that hypothesis testing does not prove or disprove hypotheses with certainty—it provides a systematic approach for making decisions based on available evidence, with known error rates.</p>
</section>
</section>
<section id="statistical-significance-and-effect-sizes" class="level2">
<h2 class="anchored" data-anchor-id="statistical-significance-and-effect-sizes">1.5 Statistical Significance and Effect Sizes</h2>
<p>A fundamental distinction in statistical analysis is between statistical significance and practical significance. Understanding both is crucial for meaningful interpretation of research findings in clinical psychology.</p>
<section id="statistical-significance" class="level3">
<h3 class="anchored" data-anchor-id="statistical-significance">1.5.1 Statistical Significance</h3>
<p>Statistical significance addresses the question: “Is the observed effect likely due to chance?”</p>
<div class="margin-note">
<p><strong>Statistical significance:</strong> Indicates that an observed effect is unlikely to have occurred by chance, but says nothing about the size or importance of the effect.</p>
</div>
<p>Key points about statistical significance:</p>
<ol type="1">
<li><p><strong>Definition:</strong> An effect is statistically significant if the p-value falls below the pre-determined significance level (typically α = .05)</p></li>
<li><p><strong>Interpretation:</strong> Statistical significance means that the observed result would be unlikely if the null hypothesis were true</p></li>
<li><p><strong>Limitations:</strong></p>
<ul>
<li>Statistical significance is influenced by sample size—with large enough samples, even tiny, clinically meaningless effects can be statistically significant</li>
<li>Statistical significance does not tell us about the magnitude of the effect</li>
<li>Statistical significance does not necessarily imply practical importance</li>
<li>Non-significant results don’t prove there is no effect—they may reflect insufficient power to detect an existing effect</li>
</ul></li>
<li><p><strong>Statistical vs.&nbsp;Clinical significance:</strong> A treatment might show a statistically significant effect (p &lt; .05) that is too small to be meaningful in clinical practice</p></li>
</ol>
</section>
<section id="effect-sizes" class="level3">
<h3 class="anchored" data-anchor-id="effect-sizes">1.5.2 Effect Sizes</h3>
<p>Effect sizes address the question: “How large or important is the observed effect?”</p>
<div class="definition">
<p><strong>Effect Size:</strong> A quantitative measure of the magnitude of a phenomenon. Effect sizes complement p-values by telling us not just whether an effect exists, but how large it is.</p>
</div>
<p>Common effect size measures in clinical psychology include:</p>
<ul>
<li><p><strong>Cohen’s d</strong>: Standardized mean difference (for t-tests)</p>
<p><span class="math display">\[d = \frac{\mu_1 - \mu_2}{\sigma}\]</span></p>
<p>Where:</p>
<ul>
<li>μ₁ and μ₂ are the group means</li>
<li>σ is the standard deviation (either pooled or from a control/reference group)</li>
</ul>
<p>In a paired design:</p>
<p><span class="math display">\[d = \frac{\bar{d}}{s_d}\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\bar{d}\)</span> is the mean difference</li>
<li><span class="math inline">\(s_d\)</span> is the standard deviation of the differences</li>
</ul></li>
<li><p><strong>Eta-squared (η²)</strong> and <strong>Partial eta-squared (partial η²)</strong>: Proportion of variance explained (for ANOVA)</p>
<p><span class="math display">\[\eta^2 = \frac{SS_{effect}}{SS_{total}}\]</span></p>
<p>Where:</p>
<ul>
<li>SS₁ is the sum of squares for the effect</li>
<li>SS₂ is the total sum of squares</li>
</ul>
<p>For partial eta-squared:</p>
<p><span class="math display">\[\text{partial } \eta^2 = \frac{SS_{effect}}{SS_{effect} + SS_{error}}\]</span></p></li>
<li><p><strong>Correlation coefficient (r)</strong>: Relationship between variables</p>
<p><span class="math display">\[r = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum(x_i - \bar{x})^2 \sum(y_i - \bar{y})^2}}\]</span></p>
<p>Where:</p>
<ul>
<li>x₁ and y₁ are paired observations</li>
<li><span class="math inline">\(\bar{x}\)</span> and <span class="math inline">\(\bar{y}\)</span> are the means of each variable</li>
</ul></li>
<li><p><strong>Odds Ratio (OR)</strong>: The ratio of the odds of an event occurring in one group to the odds of it occurring in another group</p>
<p><span class="math display">\[OR = \frac{a/b}{c/d}\]</span></p>
<p>Where:</p>
<ul>
<li>a, b, c, and d are the cells in a 2×2 contingency table</li>
</ul></li>
<li><p><strong>Number Needed to Treat (NNT)</strong>: The number of patients that need to be treated to prevent one additional negative outcome</p>
<p><span class="math display">\[NNT = \frac{1}{ARR} = \frac{1}{CER - EER}\]</span></p>
<p>Where:</p>
<ul>
<li>ARR is the absolute risk reduction</li>
<li>CER is the control event rate</li>
<li>EER is the experimental event rate</li>
</ul></li>
</ul>
</section>
<section id="interpreting-effect-sizes" class="level3">
<h3 class="anchored" data-anchor-id="interpreting-effect-sizes">1.5.3 Interpreting Effect Sizes</h3>
<p>While interpretation depends on context, Cohen’s conventional guidelines offer a starting point:</p>
<p>For Cohen’s d:</p>
<ul>
<li>d ≈ 0.2: Small effect</li>
<li>d ≈ 0.5: Medium effect</li>
<li>d ≈ 0.8: Large effect</li>
</ul>
<p>For correlation coefficient (r):</p>
<ul>
<li>r ≈ 0.1: Small effect</li>
<li>r ≈ 0.3: Medium effect</li>
<li>r ≈ 0.5: Large effect</li>
</ul>
<p>For eta-squared (η²):</p>
<ul>
<li>η² ≈ 0.01: Small effect</li>
<li>η² ≈ 0.06: Medium effect</li>
<li>η² ≈ 0.14: Large effect</li>
</ul>
<div class="margin-note">
<p>These guidelines are just rules of thumb. In clinical research, smaller effects may be meaningful for severe conditions or when interventions are low-cost and low-risk. Context matters tremendously in interpretation.</p>
</div>
<p>For example, a “small” effect size (d = 0.2) for a low-cost, minimal-risk intervention targeting a severe, treatment-resistant condition might be clinically important. Conversely, a “medium” effect size (d = 0.5) might not justify an expensive treatment with significant side effects for a mild condition with good existing treatments.</p>
</section>
<section id="clinical-vs.-statistical-significance" class="level3">
<h3 class="anchored" data-anchor-id="clinical-vs.-statistical-significance">1.5.4 Clinical vs.&nbsp;Statistical Significance</h3>
<p>In clinical psychology, it’s particularly important to distinguish between statistical significance and clinical significance.</p>
<div class="margin-note">
<p><strong>Clinical significance:</strong> Refers to whether an intervention produces a meaningful change that makes a real difference in a client’s life.</p>
</div>
<p>A treatment might produce statistically significant improvements on a symptom measure without actually creating meaningful improvements in patients’ quality of life or functioning. For example, a 2-point reduction on a depression scale might be statistically significant with a large enough sample, but if patients don’t feel better or function better in their daily lives, the clinical significance is questionable.</p>
<p>Some approaches to assessing clinical significance include:</p>
<ol type="1">
<li><p><strong>Comparing post-treatment scores to normative ranges</strong></p>
<ul>
<li>Does the client’s functioning return to normal levels after treatment?</li>
<li>E.g., Are post-treatment anxiety scores similar to those of non-anxious individuals?</li>
</ul></li>
<li><p><strong>Reliable Change Index (RCI)</strong></p>
<ul>
<li>Does the amount of change exceed what might be expected due to measurement error?</li>
</ul>
<p><span class="math display">\[RCI = \frac{X_{post} - X_{pre}}{S_{diff}}\]</span></p>
<p>Where <span class="math inline">\(S_{diff}\)</span> is the standard error of the difference</p>
<p><span class="math display">\[S_{diff} = \sqrt{2(S_E)^2}\]</span></p>
<p>And <span class="math inline">\(S_E\)</span> is the standard error of measurement</p>
<p><span class="math display">\[S_E = SD \sqrt{1-r_{xx}}\]</span></p>
<p>Where <span class="math inline">\(r_{xx}\)</span> is the reliability of the measure</p></li>
<li><p><strong>Minimum Clinically Important Difference (MCID)</strong></p>
<ul>
<li>Does the change exceed a threshold considered meaningful by patients or clinicians?</li>
<li>This might be determined by expert consensus, patient ratings, or anchoring to functional outcomes</li>
</ul></li>
<li><p><strong>Categorical approaches</strong></p>
<ul>
<li>Does the client no longer meet diagnostic criteria?</li>
<li>Has the client achieved recovery based on established cut-off scores?</li>
</ul></li>
</ol>
<div class="example">
<p><strong>Clinical Example:</strong> A large study (N = 500) comparing two therapies for anxiety finds a statistically significant difference (p = 0.02) but a small effect size (Cohen’s d = 0.2).</p>
<p><strong>Statistical significance:</strong> The p-value of 0.02 indicates that the observed difference between therapies is unlikely to be due to chance.</p>
<p><strong>Effect size:</strong> The Cohen’s d of 0.2 suggests that while the effect is real, it’s relatively small—the difference between therapies is only about 0.2 standard deviations.</p>
<p><strong>Clinical significance:</strong> To assess clinical significance, the researcher examines several indicators:</p>
<ul>
<li>Only 5% more patients in the superior therapy group achieve reliable improvement</li>
<li>The average difference in anxiety scores is 2.3 points on a 0-40 scale, below the MCID of 5 points</li>
<li>There’s no significant difference between groups in functional outcomes or quality of life</li>
</ul>
<p>Despite statistical significance, the difference between therapies may have limited clinical importance. Therapists should consider factors beyond this small statistical difference when choosing between these options, such as patient preferences, therapist expertise, cost, and availability.</p>
</div>
<p>When evaluating research findings or treatment outcomes, consider both statistical significance and effect sizes, and always interpret results in the context of clinical significance for the specific condition and treatment being studied.</p>
</section>
</section>
<section id="type-i-and-type-ii-errors" class="level2">
<h2 class="anchored" data-anchor-id="type-i-and-type-ii-errors">1.6 Type I and Type II Errors</h2>
<p>Whenever we make decisions based on statistical tests, there’s a possibility of error. Understanding these potential errors is crucial for interpreting research findings and planning studies.</p>
<section id="error-types-in-hypothesis-testing" class="level3">
<h3 class="anchored" data-anchor-id="error-types-in-hypothesis-testing">1.6.1 Error Types in Hypothesis Testing</h3>
<div class="definition">
<p><strong>Type I Error:</strong> Rejecting a null hypothesis that is actually true (a “false positive”).</p>
<p><strong>Type II Error:</strong> Failing to reject a null hypothesis that is actually false (a “false negative”).</p>
</div>
<div class="margin-note">
<p>The probability of a Type I error is α (our significance level, typically 0.05). The probability of a Type II error is β. Statistical power is 1-β.</p>
</div>
<p>These errors represent different kinds of mistakes with different consequences:</p>
<ul>
<li><strong>Type I error:</strong> Finding an effect that isn’t really there (e.g., concluding a treatment works when it doesn’t)</li>
<li><strong>Type II error:</strong> Missing an effect that is really there (e.g., concluding a treatment doesn’t work when it does)</li>
</ul>
<p>In the context of clinical psychology:</p>
<ul>
<li><strong>Type I error:</strong> Might lead to implementing ineffective treatments, wasting resources, or exposing patients to unnecessary risks</li>
<li><strong>Type II error:</strong> Might lead to abandoning potentially helpful treatments or missing important relationships between variables</li>
</ul>
</section>
<section id="the-relationship-between-error-types" class="level3">
<h3 class="anchored" data-anchor-id="the-relationship-between-error-types">1.6.2 The Relationship Between Error Types</h3>
<p>There’s an inherent trade-off between Type I and Type II errors. Attempts to reduce one type of error often increase the risk of the other:</p>
<ul>
<li>Decreasing α (e.g., from 0.05 to 0.01) reduces the risk of Type I errors but increases the risk of Type II errors</li>
<li>Increasing α (e.g., from 0.05 to 0.10) reduces the risk of Type II errors but increases the risk of Type I errors</li>
</ul>
<p>This relationship illustrates why simply making significance criteria more stringent (e.g., requiring p &lt; 0.001) isn’t always the best approach—it might prevent false positives but at the cost of missing genuine effects.</p>
</section>
<section id="statistical-power" class="level3">
<h3 class="anchored" data-anchor-id="statistical-power">1.6.3 Statistical Power</h3>
<p>Statistical power is the probability of correctly rejecting the null hypothesis when it is false—essentially, the probability of avoiding a Type II error.</p>
<div class="definition">
<p><strong>Statistical Power:</strong> The probability of detecting an effect when it truly exists. Power = 1 - β (where β is the probability of a Type II error).</p>
</div>
<p>Several factors affect statistical power:</p>
<ol type="1">
<li><strong>Sample size:</strong> Larger samples increase power</li>
<li><strong>Effect size:</strong> Larger effects are easier to detect</li>
<li><strong>Significance level (α):</strong> Less stringent significance levels increase power</li>
<li><strong>Variability:</strong> Less variability in measurements increases power</li>
<li><strong>Study design:</strong> More efficient designs (e.g., within-subjects vs.&nbsp;between-subjects) increase power</li>
</ol>
<p>Power analysis is used to determine the sample size needed to detect an effect of a given size with a specified level of power (typically 0.80, meaning an 80% chance of detecting the effect if it exists).</p>
<div class="example">
<p><strong>Clinical Example:</strong> A researcher tests a new therapy for PTSD.</p>
<p><strong>Type I error scenario:</strong> The study finds p = 0.04, leading to the conclusion that the therapy is effective. However, the effect was actually due to chance, and the therapy doesn’t truly work. This could lead to resources being wasted on an ineffective treatment, patients experiencing disappointment when the treatment fails in actual clinical practice, and potentially delaying the search for truly effective treatments.</p>
<p><strong>Type II error scenario:</strong> The study finds p = 0.08, failing to reach statistical significance. The researcher concludes there’s insufficient evidence that the therapy works. However, the therapy actually is effective, but the study had too few participants to detect the effect. This could result in abandoning a potentially helpful treatment, denying patients access to an effective intervention, and discouraging further research in a promising area.</p>
<p><strong>Power calculation:</strong> Before conducting the study, the researcher performs a power analysis. Assuming a medium effect size (d = 0.5) and aiming for 80% power with α = 0.05, the calculation indicates they need 64 participants per group (128 total) for a two-group comparison. If they can only recruit 30 participants per group, their power drops to about 48%—meaning they’d have less than a 50% chance of detecting a genuine medium-sized effect.</p>
</div>
<div style="width:175%; margin-left:-75%; position:relative; overflow:visible;">
<pre class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 500

install.packages(c("shiny", "ggplot2"))
library(shiny)
library(ggplot2)

ui &lt;- fluidPage(
  titlePanel("Understanding Type I and Type II Errors"),
  
  sidebarLayout(
    sidebarPanel(
      sliderInput("effectSize", "True Effect Size (Cohen's d):",
                  min = 0, max = 1.5, value = 0.5, step = 0.1),
      sliderInput("sampleSize", "Sample Size per Group:",
                  min = 10, max = 200, value = 30),
      sliderInput("alpha", "Significance Level (α):",
                  min = 0.01, max = 0.1, value = 0.05, step = 0.01),
      hr(),
      helpText("Move the sliders to see how effect size, sample size, and alpha level affect Type I and Type II errors.")
    ),
    
    mainPanel(
      plotOutput("powerPlot"),
      div(style = "margin-top: 20px;",
          h4("Current Values:"),
          textOutput("typeIError"),
          textOutput("typeIIError"),
          textOutput("power")
      ),
      div(style = "margin-top: 20px;",
          h4("Interpretation:"),
          uiOutput("interpretation")
      )
    )
  )
)

server &lt;- function(input, output, session) {
  
  # Calculate power and errors
  results &lt;- reactive({
    d &lt;- input$effectSize
    n &lt;- input$sampleSize
    alpha &lt;- input$alpha
    
    # Calculate non-centrality parameter
    ncp &lt;- d * sqrt(n / 2)
    
    # Critical value
    crit &lt;- qt(1 - alpha, df = 2*n - 2)
    
    # Power calculation
    power &lt;- 1 - pt(crit, df = 2*n - 2, ncp = ncp)
    
    # Type II error
    type_II &lt;- 1 - power
    
    # Type I error is just alpha
    type_I &lt;- alpha
    
    list(
      type_I = type_I,
      type_II = type_II,
      power = power,
      crit = crit,
      n = n,
      d = d
    )
  })
  
  # Create the visualization
  output$powerPlot &lt;- renderPlot({
    res &lt;- results()
    
    # Create data for null and alternative distributions
    x &lt;- seq(-4, 6, length.out = 1000)
    null_dist &lt;- dt(x, df = 2*res$n - 2)
    alt_dist &lt;- dt(x, df = 2*res$n - 2, ncp = res$d * sqrt(res$n / 2))
    
    # Create data frame for plotting
    df &lt;- data.frame(
      x = rep(x, 2),
      y = c(null_dist, alt_dist),
      Distribution = rep(c("Null (H₀)", "Alternative (H₁)"), each = length(x))
    )
    
    # Create critical region
    crit_x &lt;- res$crit
    
    # Create plot
    p &lt;- ggplot(df, aes(x = x, y = y, fill = Distribution)) +
      geom_line(aes(color = Distribution), size = 1) +
      geom_area(data = subset(df, Distribution == "Null (H₀)" &amp; x &gt;= crit_x),
                aes(x = x, y = y), fill = "red", alpha = 0.5) +
      geom_area(data = subset(df, Distribution == "Alternative (H₁)" &amp; x &lt;= crit_x),
                aes(x = x, y = y), fill = "blue", alpha = 0.5) +
      geom_vline(xintercept = crit_x, linetype = "dashed") +
      annotate("text", x = crit_x + 0.2, y = max(c(null_dist, alt_dist)) * 0.8,
               label = "Critical value", hjust = 0) +
      annotate("text", x = 3, y = max(c(null_dist, alt_dist)) * 0.6,
               label = "Type I Error\n(False Positive)", color = "red") +
      annotate("text", x = -1, y = max(c(null_dist, alt_dist)) * 0.5,
               label = "Type II Error\n(False Negative)", color = "blue") +
      labs(title = "Visualization of Type I and Type II Errors",
           subtitle = paste("Effect size =", res$d, ", Sample size =", res$n, ", α =", res$type_I),
           x = "t-statistic",
           y = "Density") +
      theme_minimal() +
      theme(legend.position = "top")
    
    print(p)
  })
  
  output$typeIError &lt;- renderText({
    res &lt;- results()
    paste("Type I Error (α) = ", round(res$type_I * 100, 2), "% (probability of rejecting H₀ when it's true)")
  })
  
  output$typeIIError &lt;- renderText({
    res &lt;- results()
    paste("Type II Error (β) = ", round(res$type_II * 100, 2), "% (probability of failing to reject H₀ when it's false)")
  })
  
  output$power &lt;- renderText({
    res &lt;- results()
    paste("Statistical Power (1-β) = ", round(res$power * 100, 2), "% (probability of rejecting H₀ when it's false)")
  })
  
  output$interpretation &lt;- renderUI({
    res &lt;- results()
    
    HTML(paste(
      "With your current settings:",
      "&lt;ul&gt;",
      paste0("&lt;li&gt;If there is &lt;strong&gt;no effect&lt;/strong&gt; (H₀ is true), you have a ", round(res$type_I * 100, 1), "% chance of incorrectly concluding there is an effect.&lt;/li&gt;"),
      paste0("&lt;li&gt;If there is a &lt;strong&gt;true effect&lt;/strong&gt; of size d = ", res$d, " (H₁ is true), you have a ", round(res$power * 100, 1), "% chance of correctly detecting it.&lt;/li&gt;"),
      paste0("&lt;li&gt;If there is a &lt;strong&gt;true effect&lt;/strong&gt; of size d = ", res$d, " (H₁ is true), you have a ", round(res$type_II * 100, 1), "% chance of incorrectly concluding there is no effect.&lt;/li&gt;"),
      "&lt;/ul&gt;",
      "&lt;p&gt;In a clinical context, these error rates translate to real consequences for patients:&lt;/p&gt;",
      "&lt;ul&gt;",
      "&lt;li&gt;&lt;strong&gt;Type I Error:&lt;/strong&gt; Implementing ineffective treatments, potentially exposing patients to unnecessary risks or side effects, and wasting limited healthcare resources.&lt;/li&gt;",
      "&lt;li&gt;&lt;strong&gt;Type II Error:&lt;/strong&gt; Failing to adopt effective treatments, denying patients access to interventions that could help them, and potentially allowing their conditions to worsen without proper treatment.&lt;/li&gt;",
      "&lt;/ul&gt;",
      "&lt;p&gt;Increasing sample size improves power and reduces Type II errors. Decreasing α reduces Type I errors but increases Type II errors.&lt;/p&gt;"
    ))
  })
}

shinyApp(ui, server)</code></pre>
</div>
<p>Experiment with this interactive application to see how sample size, effect size, and significance level (alpha) affect the probabilities of Type I and Type II errors.</p>
</section>
<section id="balancing-errors-in-clinical-research" class="level3">
<h3 class="anchored" data-anchor-id="balancing-errors-in-clinical-research">1.6.4 Balancing Errors in Clinical Research</h3>
<p>In clinical psychology, the relative costs of Type I and Type II errors often depend on the specific research question and context:</p>
<ul>
<li><p><strong>High-risk interventions:</strong> When testing treatments with significant potential side effects or costs, avoiding Type I errors might be prioritized to prevent implementing harmful or wasteful interventions.</p></li>
<li><p><strong>Novel treatments for severe conditions:</strong> When investigating new treatments for severe or treatment-resistant conditions with few existing options, avoiding Type II errors might be prioritized to avoid missing potentially beneficial interventions.</p></li>
<li><p><strong>Screening measures:</strong> When developing screening tools for serious conditions, sensitivity to Type I vs.&nbsp;Type II errors relates directly to the consequences of false positives vs.&nbsp;false negatives. For life-threatening conditions where early intervention is crucial, accepting more false positives (Type I errors) might be warranted.</p></li>
</ul>
<p>Researchers should consider these tradeoffs when designing studies and interpreting results, rather than rigidly adhering to conventional significance levels without context.</p>
</section>
<section id="beyond-the-dichotomy" class="level3">
<h3 class="anchored" data-anchor-id="beyond-the-dichotomy">1.6.5 Beyond the Dichotomy</h3>
<p>Modern statistical approaches increasingly emphasize moving beyond the simplistic “significant vs.&nbsp;non-significant” dichotomy:</p>
<ol type="1">
<li><p><strong>Confidence intervals:</strong> Provide a range of plausible values for the parameter of interest, rather than a simple yes/no decision about significance.</p></li>
<li><p><strong>Effect sizes with confidence intervals:</strong> Focus on the magnitude of effects and the precision of our estimates, not just whether an effect exists.</p></li>
<li><p><strong>Bayesian approaches:</strong> Directly estimate the probability that hypotheses are true given the data, rather than the probability of the data given the hypothesis.</p></li>
<li><p><strong>Open science practices:</strong> Pre-registration, transparent reporting, and replication help build cumulative evidence beyond single-study significance testing.</p></li>
</ol>
<p>These approaches acknowledge the limitations of simple hypothesis testing and provide richer information for making research and clinical decisions.</p>
</section>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">1.7 Summary</h2>
<p>This chapter has introduced fundamental concepts in statistical thinking that form the foundation for the specific statistical tests we’ll explore in later chapters. Key takeaways include:</p>
<ul>
<li><p><strong>Populations and samples:</strong> Statistics allows us to use sample data to make inferences about populations. The relationship between samples and populations is fundamental to statistical reasoning.</p></li>
<li><p><strong>Probability distributions:</strong> Different distributions describe the likelihood of various outcomes. The normal distribution is particularly important because many psychological variables approximately follow this pattern, and the Central Limit Theorem ensures that sampling distributions of means approach normality.</p></li>
<li><p><strong>The Central Limit Theorem:</strong> This remarkable theorem tells us that regardless of the original population distribution, the sampling distribution of means will be approximately normal for sufficiently large samples. This provides the foundation for many statistical tests.</p></li>
<li><p><strong>Hypothesis testing:</strong> This framework provides a systematic approach for making decisions based on data. By comparing observed results to what would be expected under the null hypothesis, we can quantify the evidence against the null.</p></li>
<li><p><strong>Statistical significance and effect sizes:</strong> Both statistical significance (p-values) and effect sizes are important for interpretation. Statistical significance tells us whether an effect is likely due to chance, while effect sizes tell us about the magnitude and practical importance of effects.</p></li>
<li><p><strong>Type I and Type II errors:</strong> All statistical decisions involve potential errors, which we manage but cannot eliminate. The balance between these error types depends on the specific context and the relative costs of different kinds of mistakes.</p></li>
</ul>
<p>In the next chapter, we’ll explore t-tests, our first specific statistical test for comparing groups.</p>
<p>Let’s now convert the practice questions at the end of the chapter into an interactive quiz:</p>
<pre class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 700

install.packages(c("shiny", "shinyjs"))
library(shiny)
library(shinyjs)

ui &lt;- fluidPage(
  useShinyjs(),
  tags$head(
    tags$style(HTML("
      .quiz-container {
        max-width: 800px;
        margin: 0 auto;
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 20px;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
      }
      .question {
        margin-bottom: 30px;
        padding-bottom: 20px;
        border-bottom: 1px solid #dee2e6;
      }
      .question-title {
        font-weight: bold;
        margin-bottom: 15px;
        color: #212529;
      }
      .feedback {
        margin-top: 15px;
        padding: 15px;
        border-radius: 5px;
      }
      .correct {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
      }
      .incorrect {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
      }
      .panel-heading {
        background-color: #6c757d;
        color: white;
        padding: 10px 15px;
        border-radius: 5px 5px 0 0;
      }
      .panel-body {
        background-color: white;
        padding: 15px;
        border: 1px solid #dee2e6;
        border-top: none;
        border-radius: 0 0 5px 5px;
      }
      .result-container {
        margin-top: 20px;
        text-align: center;
      }
      .btn-submit-answer {
        margin-top: 10px;
      }
      .explanation {
        font-style: italic;
        margin-top: 10px;
      }
    "))
  ),
  
  div(class = "container-fluid",
      div(class = "row",
          div(class = "col-md-12",
              div(class = "quiz-container",
                  
                  # Quiz header
                  div(class = "panel-heading",
                      h2("Chapter 1 Quiz: Introduction to Statistical Thinking", style = "margin-top: 0;")
                  ),
                  
                  div(class = "panel-body",
                      p("Test your understanding of the key concepts covered in this chapter. For each question, select the best answer and click 'Submit' to see feedback."),
                      
                      # Question 1
                      div(class = "question", id = "q1_container",
                          div(class = "question-title", "Question 1: Sampling in Clinical Research"),
                          p("A researcher conducts a study with 15 participants randomly sampled from a university counseling center. What concerns might you have about generalizing the results to all therapy clients?"),
                          
                          radioButtons("q1", NULL, 
                                     choices = c(
                                       "The study has too few participants to draw any statistically significant conclusions." = "incorrect1",
                                       "University counseling center clients may not be representative of the broader population of therapy clients, limiting generalizability." = "correct",
                                       "Random sampling ensures generalizability to all therapy clients, so there are no concerns." = "incorrect2",
                                       "The researcher should have used a paired samples design instead of random sampling." = "incorrect3"
                                     )),
                          actionButton("check1", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback1")
                      ),
                      
                      # Question 2
                      div(class = "question", id = "q2_container",
                          div(class = "question-title", "Question 2: The Central Limit Theorem"),
                          p("Explain why the Central Limit Theorem is important for statistical analysis in clinical psychology."),
                          
                          radioButtons("q2", NULL, 
                                     choices = c(
                                       "It allows researchers to use parametric tests even when the original data aren't perfectly normally distributed, as long as sample sizes are sufficient." = "correct",
                                       "It proves that all psychological variables are normally distributed." = "incorrect1",
                                       "It states that larger samples always produce statistically significant results." = "incorrect2",
                                       "It eliminates the need to check assumptions for statistical tests." = "incorrect3"
                                     )),
                          actionButton("check2", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback2")
                      ),
                      
                      # Question 3
                      div(class = "question", id = "q3_container",
                          div(class = "question-title", "Question 3: Statistical vs. Clinical Significance"),
                          p("A study reports p = 0.002 and Cohen's d = 0.15 for a new depression treatment. What can you conclude?"),
                          
                          radioButtons("q3", NULL, 
                                     choices = c(
                                       "The treatment has a large and clinically meaningful effect." = "incorrect1",
                                       "The treatment effect is statistically significant but small, suggesting limited clinical significance." = "correct",
                                       "The treatment has no real effect; the significant p-value is just due to chance." = "incorrect2", 
                                       "The p-value and effect size are contradictory, so the study must have methodological flaws." = "incorrect3"
                                     )),
                          actionButton("check3", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback3")
                      ),
                      
                      # Question 4
                      div(class = "question", id = "q4_container",
                          div(class = "question-title", "Question 4: Type I and Type II Errors"),
                          p("If you're testing a new therapy for depression, which would be more problematic: a Type I error or a Type II error? Explain your reasoning."),
                          
                          radioButtons("q4", NULL, 
                                     choices = c(
                                       "Type I error (concluding the therapy works when it doesn't) would be more problematic because it could lead to implementing an ineffective treatment, wasting resources, and potentially delaying effective care." = "option1",
                                       "Type II error (concluding the therapy doesn't work when it actually does) would be more problematic because it could mean abandoning a potentially helpful treatment and denying patients access to an effective intervention." = "option2",
                                       "Both error types are equally problematic in all clinical contexts." = "incorrect"
                                     )),
                          actionButton("check4", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback4")
                      ),
                      
                      # Score display
                      div(id = "score_section", class = "result-container",
                          actionButton("calculate_score", "Calculate My Score", class = "btn-success btn-lg"),
                          htmlOutput("final_score")
                      )
                  )
              )
          )
      )
  )
)

server &lt;- function(input, output, session) {
  
  # Initialize score tracking
  score &lt;- reactiveVal(0)
  answered &lt;- reactiveVal(rep(FALSE, 4))
  
  # Question 1 feedback
  observeEvent(input$check1, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[1] &lt;- TRUE
    answered(current_answered)
    
    # Check if correct and update score
    is_correct &lt;- input$q1 == "correct"
    if(is_correct) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback1 &lt;- renderUI({
      if(is_correct) {
        div(class = "feedback correct",
            h4("Correct!"),
            p(class = "explanation", "University counseling center clients typically differ from the broader population of therapy clients in important ways: they're usually younger, more educated, and may have different presenting concerns compared to community mental health clients or private practice clients. Random sampling from a non-representative source still produces a sample with limited generalizability.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "The main issue here is representativeness, not sample size or study design. Even with random sampling within the university counseling center, the sample may not represent the broader population of therapy clients. University students differ from the general population in age, education level, socioeconomic status, and potentially in the nature and severity of their psychological concerns.")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check1")
  })
  
  # Question 2 feedback
  observeEvent(input$check2, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[2] &lt;- TRUE
    answered(current_answered)
    
    # Check if correct and update score
    is_correct &lt;- input$q2 == "correct"
    if(is_correct) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback2 &lt;- renderUI({
      if(is_correct) {
        div(class = "feedback correct",
            h4("Correct!"),
            p(class = "explanation", "The Central Limit Theorem states that regardless of the original population distribution, the sampling distribution of the mean will be approximately normal for sufficiently large samples. This is crucial because it allows researchers to use parametric statistical tests (which often assume normality) even when working with data that isn't perfectly normally distributed. In clinical psychology, where many measures show some skewness or other departures from normality, this theorem provides theoretical justification for the statistical approaches we commonly use.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "The Central Limit Theorem doesn't claim that all psychological variables are normally distributed (many aren't), nor does it suggest that larger samples always produce significant results or eliminate the need to check assumptions. Instead, it tells us that the distribution of sample means will approximate a normal distribution as sample size increases, regardless of the original population distribution. This allows us to use parametric tests with reasonably large samples even when the original data isn't perfectly normal.")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check2")
  })
  
  # Question 3 feedback
  observeEvent(input$check3, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[3] &lt;- TRUE
    answered(current_answered)
    
    # Check if correct and update score
    is_correct &lt;- input$q3 == "correct"
    if(is_correct) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback3 &lt;- renderUI({
      if(is_correct) {
        div(class = "feedback correct",
            h4("Correct!"),
            p(class = "explanation", "This is a classic example of the distinction between statistical and clinical significance. The very small p-value (0.002) indicates strong statistical significance—the effect is very unlikely to be due to chance. However, the small effect size (d = 0.15) suggests that the magnitude of the effect is quite modest. In clinical contexts, such a small effect might not translate to meaningful improvements in patients' lives, especially if the treatment is costly, time-consuming, or has side effects. This highlights why we should always consider both statistical significance and effect size when interpreting research findings.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "The p-value (0.002) indicates that the result is statistically significant—highly unlikely to be due to chance. However, Cohen's d = 0.15 represents a small effect size, suggesting that while the effect is real, its magnitude is modest. The p-value and effect size aren't contradictory; they simply tell us different things. Statistical significance (p-value) tells us about the reliability of the effect, while effect size tells us about its magnitude. A treatment can have a statistically significant but small effect that may or may not be clinically meaningful, depending on the context.")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check3")
  })
  
  # Question 4 feedback
  observeEvent(input$check4, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[4] &lt;- TRUE
    answered(current_answered)
    
    # This question has two acceptable answers
    is_reasonable &lt;- input$q4 == "option1" || input$q4 == "option2"
    if(is_reasonable) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback4 &lt;- renderUI({
      if(input$q4 == "option1") {
        div(class = "feedback correct",
            h4("Good reasoning!"),
            p(class = "explanation", "A Type I error (false positive) in this context means concluding the therapy works when it doesn't. This could lead to implementing an ineffective treatment, which might waste resources, expose patients to unnecessary risks or side effects, and delay their access to truly effective treatments. This is a valid concern, especially if the new therapy is expensive, has potential side effects, or would replace existing effective treatments.")
        )
      } else if(input$q4 == "option2") {
        div(class = "feedback correct",
            h4("Good reasoning!"),
            p(class = "explanation", "A Type II error (false negative) in this context means failing to detect that the therapy works when it actually does. This could result in discarding a genuinely effective treatment and denying patients access to something that could help them. This is a reasonable concern, especially for conditions with limited existing treatment options or for treatments targeting treatment-resistant depression.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "The relative costs of Type I and Type II errors depend on the specific context. There's no universal rule that one type is always more problematic than the other. The consequences of each error type should be weighed based on factors like: the severity of the condition, availability of alternative treatments, cost and side effects of the new therapy, and the clinical setting. This nuanced approach is more appropriate than treating all error types as equally problematic in all situations.")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check4")
  })
  
  # Calculate and display final score
  observeEvent(input$calculate_score, {
    # Check if all questions have been answered
    if(!all(answered())) {
      output$final_score &lt;- renderUI({
        div(class = "alert alert-warning",
            h4("Please answer all questions first!"),
            p("Make sure you've submitted an answer for each question before calculating your score.")
        )
      })
      return()
    }
    
    # Calculate percentage
    total &lt;- 4
    current_score &lt;- score()
    percentage &lt;- round((current_score / total) * 100)
    
    # Generate feedback based on score
    feedback &lt;- if(percentage &gt;= 75) {
      "Excellent work! You have a strong understanding of the fundamental concepts in statistical thinking for clinical psychology."
    } else if(percentage &gt;= 50) {
      "Good job! You understand many of the key concepts, but you might want to review some areas to strengthen your understanding."
    } else {
      "You might benefit from reviewing this chapter again to strengthen your understanding of these fundamental statistical concepts."
    }
    
    # Display score and feedback
    output$final_score &lt;- renderUI({
      div(class = "well well-lg",
          h3(paste0("Your Score: ", current_score, "/", total, " (", percentage, "%)")),
          p(feedback),
          if(percentage &lt; 100) {
            p("Review the questions you missed and the explanations provided to deepen your understanding.")
          } else {
            p("Perfect score! You're well-prepared to move on to the next chapter on t-tests.")
          }
      )
    })
    
    # Disable the button after clicking
    disable("calculate_score")
  })
}

shinyApp(ui, server)</code></pre>
<hr>
</section>
</section>
<section id="comparing-two-groups-t-tests" class="level1 unnumbered">
<h1 class="unnumbered">2. Comparing Two Groups: t-tests</h1>
<div class="key-concepts">
<p><strong>Key Concepts:</strong></p>
<ul>
<li>Independent samples t-test: comparing means from two separate groups</li>
<li>Paired samples t-test: comparing means from related observations</li>
<li>Core assumptions of t-tests and how to check them</li>
<li>Effect size measures (Cohen’s d) and interpretation</li>
<li>Statistical power in t-tests</li>
<li>Clinical vs.&nbsp;statistical significance in treatment comparisons</li>
</ul>
</div>
<section id="introduction-to-t-tests" class="level2">
<h2 class="anchored" data-anchor-id="introduction-to-t-tests">2.1 Introduction to t-tests</h2>
<p>The t-test is one of the most common statistical procedures in psychological research. It addresses a fundamental question: Is there a significant difference between two means?</p>
<div class="margin-note">
<p><strong>t-test:</strong> A statistical test that compares the means of two groups and determines if they are statistically significantly different from each other.</p>
</div>
<p>In clinical psychology, t-tests are frequently used to:</p>
<ul>
<li>Compare a treatment group to a control group</li>
<li>Compare outcomes before and after an intervention</li>
<li>Compare two different therapeutic approaches</li>
<li>Compare clinical and non-clinical populations</li>
</ul>
<p>The t-test works by calculating the difference between two means and considering how large this difference is relative to the variability in the data. The result is a t-statistic, which we compare to a critical value from the t-distribution to determine statistical significance.</p>
<p>There are two main types of t-tests, and choosing the correct one depends on whether your groups are independent or paired:</p>
<ul>
<li><strong>Independent samples t-test:</strong> Used when comparing two separate groups</li>
<li><strong>Paired samples t-test:</strong> Used when comparing two related measurements</li>
</ul>
</section>
<section id="independent-samples-t-test" class="level2">
<h2 class="anchored" data-anchor-id="independent-samples-t-test">2.2 Independent Samples t-test</h2>
<p>The independent samples t-test (also called the two-sample t-test) is used when we have two separate groups of participants and want to compare their means on some measure.</p>
<div class="definition">
<p><strong>Independent Samples t-test:</strong> A statistical test that compares the means of two unrelated groups to determine if there is a statistically significant difference between them.</p>
</div>
<section id="when-to-use-the-independent-samples-t-test" class="level3">
<h3 class="anchored" data-anchor-id="when-to-use-the-independent-samples-t-test">2.2.1 When to Use the Independent Samples t-test</h3>
<p>Use the independent samples t-test when:</p>
<ul>
<li>You have two separate groups of participants</li>
<li>The groups are independent (different participants in each group)</li>
<li>You’re comparing the means of a continuous variable</li>
<li>You want to know if the difference between groups is statistically significant</li>
</ul>
<div class="example">
<p><strong>Clinical Example:</strong> A researcher wants to compare depression scores between clients receiving cognitive-behavioral therapy (CBT) and those receiving psychodynamic therapy. They randomly assign 30 clients to each treatment and measure depression after 12 weeks of therapy. Since these are two separate groups of clients, an independent samples t-test is appropriate.</p>
</div>
</section>
<section id="the-logic-of-the-independent-samples-t-test" class="level3">
<h3 class="anchored" data-anchor-id="the-logic-of-the-independent-samples-t-test">2.2.2 The Logic of the Independent Samples t-test</h3>
<p>The independent samples t-test compares two means while accounting for the variability within each group. The test is based on the t-statistic, which is calculated as:</p>
<p><span class="math display">\[t = \frac{\bar{X}_1 - \bar{X}_2}{SE}\]</span></p>
<p>Where <span class="math inline">\(SE\)</span> is the standard error of the difference between means, which depends on the variances of the two groups and the sample sizes.</p>
<p>For equal variances (pooled variance), the standard error is calculated as:</p>
<p><span class="math display">\[SE = \sqrt{\frac{s_p^2}{n_1} + \frac{s_p^2}{n_2}} = s_p\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}\]</span></p>
<p>Where <span class="math inline">\(s_p^2\)</span> is the pooled variance:</p>
<p><span class="math display">\[s_p^2 = \frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}\]</span></p>
<p>The t-statistic follows a t-distribution with <span class="math inline">\((n_1 + n_2 - 2)\)</span> degrees of freedom. We compare this t-statistic to the critical value from the t-distribution to determine statistical significance.</p>
</section>
<section id="key-assumptions" class="level3">
<h3 class="anchored" data-anchor-id="key-assumptions">2.2.3 Key Assumptions</h3>
<p>The independent samples t-test makes several key assumptions:</p>
<ol type="1">
<li><strong>Independence:</strong> Observations within and between groups are independent</li>
<li><strong>Normality:</strong> The dependent variable is approximately normally distributed in each group</li>
<li><strong>Homogeneity of variance:</strong> The two groups have similar variances</li>
</ol>
<div class="margin-note">
<p>While t-tests are somewhat robust to violations of normality (especially with larger samples), severe skewness or the presence of outliers can affect results.</p>
</div>
<p>Checking these assumptions is important for valid interpretation:</p>
<ul>
<li>Independence is primarily ensured through study design</li>
<li>Normality can be assessed with histograms, Q-Q plots, or formal tests (e.g., Shapiro-Wilk)</li>
<li>Homogeneity of variance can be checked with Levene’s test</li>
</ul>
<p>If the homogeneity of variance assumption is violated, Welch’s t-test (which doesn’t assume equal variances) should be used instead of the standard t-test.</p>
</section>
<section id="effect-size-for-independent-samples-t-test" class="level3">
<h3 class="anchored" data-anchor-id="effect-size-for-independent-samples-t-test">2.2.4 Effect Size for Independent Samples t-test</h3>
<p>While the p-value tells us whether a difference is statistically significant, the effect size tells us how large or meaningful the difference is.</p>
<div class="definition">
<p><strong>Cohen’s d:</strong> A standardized measure of effect size for comparing two means. It represents the difference between two means divided by the pooled standard deviation.</p>
</div>
<p>For independent samples, Cohen’s d is calculated as:</p>
<p><span class="math display">\[d = \frac{\bar{X}_1 - \bar{X}_2}{s_p}\]</span></p>
<p>Where <span class="math inline">\(s_p\)</span> is the pooled standard deviation:</p>
<p><span class="math display">\[s_p = \sqrt{\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}\]</span></p>
<p>Cohen’s d can be interpreted using these general guidelines:</p>
<ul>
<li>d ≈ 0.2: Small effect</li>
<li>d ≈ 0.5: Medium effect</li>
<li>d ≈ 0.8: Large effect</li>
</ul>
<div class="margin-note">
<p>These guidelines are just rules of thumb. In clinical research, smaller effects may be meaningful for severe conditions or when interventions are low-cost and low-risk.</p>
</div>
<div style="width:175%; margin-left:-75%; position:relative; overflow:visible;">
<pre class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 700

library(shiny)
library(ggplot2)
library(tidyr)
library(dplyr)

ui &lt;- fluidPage(
  titlePanel("Independent Samples t-test Interactive Visualization"),
  
  sidebarLayout(
    sidebarPanel(
      width = 3,
      
      h4("Group Parameters"),
      
      # Group 1 parameters
      numericInput("mean1", "Group 1 Mean:", value = 50, min = 0, max = 100),
      numericInput("sd1", "Group 1 SD:", value = 10, min = 1, max = 30),
      numericInput("n1", "Group 1 Sample Size:", value = 30, min = 5, max = 200),
      
      # Group 2 parameters
      numericInput("mean2", "Group 2 Mean:", value = 55, min = 0, max = 100),
      numericInput("sd2", "Group 2 SD:", value = 10, min = 1, max = 30),
      numericInput("n2", "Group 2 Sample Size:", value = 30, min = 5, max = 200),
      
      hr(),
      actionButton("simulate", "Generate New Data", class = "btn-primary"),
      
      hr(),
      checkboxInput("show_indiv", "Show Individual Data Points", TRUE)
    ),
    
    mainPanel(
      width = 9,
      tabsetPanel(
        tabPanel("Distributions", 
                 plotOutput("distributionPlot"),
                 div(class = "well", 
                     h4("Understanding the Visualization"),
                     p("This plot shows the distribution of values for each group. The dashed vertical lines represent the group means."),
                     p("Notice how the overlap between distributions affects the t-test results. Greater separation between distributions typically leads to more significant results.")
                 )
        ),
        tabPanel("Comparison", 
                 plotOutput("comparisonPlot"),
                 div(class = "well", 
                     h4("Interpreting Group Differences"),
                     p("This plot allows you to visualize the actual difference between groups. The boxplots show the median (center line), interquartile range (box), and range (whiskers)."),
                     p("Individual data points help you see the actual distribution of scores and potential outliers.")
                 )
        ),
        tabPanel("Results", 
                 verbatimTextOutput("ttest_results"),
                 verbatimTextOutput("effect_size"),
                 plotOutput("powerPlot"),
                 div(class = "well", 
                     h4("Statistical Interpretation"),
                     p("The t-test results show whether the difference between groups is statistically significant (p &lt; 0.05)."),
                     p("Cohen's d provides a standardized measure of effect size - how large the difference is in standard deviation units."),
                     p("The power analysis graph shows how the probability of detecting this effect increases with sample size.")
                 )
        )
      )
    )
  )
)

server &lt;- function(input, output, session) {
  
  # Generate data reactively based on inputs
  sim_data &lt;- eventReactive(c(input$simulate, input$mean1, input$mean2, 
                             input$sd1, input$sd2, input$n1, input$n2), {
    set.seed(sample(1:1000, 1))
    group1 &lt;- data.frame(
      value = rnorm(input$n1, input$mean1, input$sd1),
      group = "Group 1"
    )
    
    group2 &lt;- data.frame(
      value = rnorm(input$n2, input$mean2, input$sd2),
      group = "Group 2"
    )
    
    combined &lt;- rbind(group1, group2)
    combined$group &lt;- factor(combined$group)
    
    # Calculate t-test
    t_test_result &lt;- t.test(value ~ group, data = combined, var.equal = (input$sd1 == input$sd2))
    
    # Calculate Cohen's d
    g1_data &lt;- combined$value[combined$group == "Group 1"]
    g2_data &lt;- combined$value[combined$group == "Group 2"]
    pooled_sd &lt;- sqrt(((length(g1_data) - 1) * var(g1_data) + 
                       (length(g2_data) - 1) * var(g2_data)) / 
                       (length(g1_data) + length(g2_data) - 2))
    cohens_d &lt;- abs(mean(g1_data) - mean(g2_data)) / pooled_sd
    
    # Calculate power
    df &lt;- length(g1_data) + length(g2_data) - 2
    non_centrality &lt;- cohens_d * sqrt((length(g1_data) * length(g2_data)) / 
                                      (length(g1_data) + length(g2_data)))
    power &lt;- pt(qt(0.975, df), df, non_centrality, lower.tail = FALSE) + 
             pt(qt(0.025, df), df, non_centrality, lower.tail = TRUE)
    
    list(
      combined = combined,
      t_test = t_test_result,
      cohens_d = cohens_d,
      power = power
    )
  })
  
  # Distribution plot
  output$distributionPlot &lt;- renderPlot({
    req(sim_data())
    data &lt;- sim_data()$combined
    
    ggplot(data, aes(x = value, fill = group)) +
      geom_density(alpha = 0.5) +
      geom_vline(data = data %&gt;% group_by(group) %&gt;% 
                 summarize(mean = mean(value)), 
                 aes(xintercept = mean, color = group),
                 linetype = "dashed", size = 1) +
      labs(title = "Distribution of Values by Group",
           subtitle = "Dashed lines represent group means",
           x = "Value", y = "Density") +
      theme_minimal() +
      theme(legend.position = "top",
            plot.title = element_text(face = "bold", size = 16),
            plot.subtitle = element_text(size = 12)) +
      scale_fill_brewer(palette = "Set1") +
      scale_color_brewer(palette = "Set1")
  })
  
  # Comparison plot
  output$comparisonPlot &lt;- renderPlot({
    req(sim_data())
    data &lt;- sim_data()$combined
    
    p &lt;- ggplot(data, aes(x = group, y = value, fill = group)) +
      geom_boxplot(width = 0.5, alpha = 0.7) +
      stat_summary(fun = mean, geom = "point", shape = 18, size = 4, color = "black") +
      labs(title = "Comparison of Group Means",
           subtitle = "Diamond points represent means",
           x = "Group", y = "Value") +
      theme_minimal() +
      theme(legend.position = "none",
            plot.title = element_text(face = "bold", size = 16),
            plot.subtitle = element_text(size = 12),
            axis.title = element_text(size = 14)) +
      scale_fill_brewer(palette = "Set1")
    
    if(input$show_indiv){
      p &lt;- p + geom_jitter(width = 0.2, alpha = 0.5, size = 2)
    }
    
    p
  })
  
  # Test results
  output$ttest_results &lt;- renderPrint({
    req(sim_data())
    cat("Independent Samples t-test Results:\n\n")
    print(sim_data()$t_test)
  })
  
  # Effect size results
  output$effect_size &lt;- renderText({
    req(sim_data())
    d &lt;- sim_data()$cohens_d
    power &lt;- sim_data()$power
    
    effect_size_interpretation &lt;- case_when(
      d &lt; 0.2 ~ "negligible",
      d &lt; 0.5 ~ "small",
      d &lt; 0.8 ~ "medium",
      TRUE ~ "large"
    )
    
    paste0("Effect Size:\n",
          "Cohen's d = ", round(d, 2), " (", effect_size_interpretation, " effect)\n\n",
          "Statistical Power = ", round(power * 100, 1), "%\n",
          "This means you have a ", round(power * 100, 1), "% chance of detecting this effect if it exists.")
  })
  
  # Power Plot
  output$powerPlot &lt;- renderPlot({
    req(sim_data())
    d &lt;- sim_data()$cohens_d
    
    # Create sequence of sample sizes
    n_seq &lt;- seq(5, 200, by = 5)
    
    # Calculate power for each sample size (assuming equal n in each group)
    power_data &lt;- data.frame(
      n = n_seq,
      power = sapply(n_seq, function(n) {
        df &lt;- 2*n - 2
        non_centrality &lt;- d * sqrt(n/2)
        pt(qt(0.975, df), df, non_centrality, lower.tail = FALSE) + 
          pt(qt(0.025, df), df, non_centrality, lower.tail = TRUE)
      })
    )
    
    # Plot power curve
    ggplot(power_data, aes(x = n, y = power)) +
      geom_line(size = 1.2, color = "blue") +
      geom_hline(yintercept = 0.8, linetype = "dashed", color = "red") +
      geom_text(aes(x = max(n_seq)*0.8, y = 0.82), label = "80% Power", color = "red") +
      geom_vline(xintercept = input$n1, linetype = "dotted") +
      annotate("text", x = input$n1 + 5, y = 0.5, 
               label = paste("Current n =", input$n1), hjust = 0) +
      labs(title = "Power Analysis for Different Sample Sizes",
           subtitle = paste("Based on observed effect size (d =", round(d, 2), ")"),
           x = "Sample Size per Group", 
           y = "Statistical Power") +
      ylim(0, 1) +
      theme_minimal() +
      theme(plot.title = element_text(face = "bold"))
  })
}

shinyApp(ui, server)</code></pre>
</div>
<p>This interactive application allows you to manipulate group means, standard deviations, and sample sizes to see how they affect the t-test results and Cohen’s d.&nbsp;Experiment with different values to develop your intuition about the independent samples t-test:</p>
<ol type="1">
<li>Try increasing the difference between the group means and observe how the p-value and effect size change</li>
<li>Keep the means constant but increase the standard deviations and observe the effect on statistical significance</li>
<li>See how increasing sample size affects the statistical power of the test</li>
</ol>
</section>
</section>
<section id="paired-samples-t-test" class="level2">
<h2 class="anchored" data-anchor-id="paired-samples-t-test">2.3 Paired Samples t-test</h2>
<p>The paired samples t-test (also called the dependent samples t-test) is used when we have two related measurements for each participant.</p>
<div class="definition">
<p><strong>Paired Samples t-test:</strong> A statistical test that compares the means of two related measurements to determine if there is a statistically significant difference between them.</p>
</div>
<section id="when-to-use-the-paired-samples-t-test" class="level3">
<h3 class="anchored" data-anchor-id="when-to-use-the-paired-samples-t-test">2.3.1 When to Use the Paired Samples t-test</h3>
<p>Use the paired samples t-test when:</p>
<ul>
<li>You have two measurements for each participant</li>
<li>The measurements are related or matched in some way</li>
<li>You’re comparing the means of a continuous variable</li>
<li>You want to know if the difference between measurements is statistically significant</li>
</ul>
<p>Common scenarios for paired designs include:</p>
<ul>
<li>Pre-test/post-test measurements (before and after treatment)</li>
<li>Repeated measurements under different conditions</li>
<li>Matched pairs (e.g., twins, or participants matched on key characteristics)</li>
</ul>
<div class="example">
<p><strong>Clinical Example:</strong> A psychologist measures anxiety levels in 25 clients before therapy begins and again after 10 sessions. Since there are two measurements (pre and post) for each client, a paired samples t-test is appropriate to assess whether anxiety levels decreased significantly.</p>
</div>
</section>
<section id="the-logic-of-the-paired-samples-t-test" class="level3">
<h3 class="anchored" data-anchor-id="the-logic-of-the-paired-samples-t-test">2.3.2 The Logic of the Paired Samples t-test</h3>
<p>The paired samples t-test first calculates the difference between each pair of measurements. It then performs a one-sample t-test on these differences to determine if the mean difference is significantly different from zero.</p>
<p>The test is based on the t-statistic:</p>
<p><span class="math display">\[t = \frac{\bar{d}}{s_d / \sqrt{n}}\]</span></p>
<p>Where: - <span class="math inline">\(\bar{d}\)</span> is the mean of the differences - <span class="math inline">\(s_d\)</span> is the standard deviation of the differences - <span class="math inline">\(n\)</span> is the number of pairs</p>
<p>This t-statistic is compared to a t-distribution with <span class="math inline">\((n-1)\)</span> degrees of freedom (where <span class="math inline">\(n\)</span> is the number of pairs) to determine statistical significance.</p>
</section>
<section id="key-assumptions-1" class="level3">
<h3 class="anchored" data-anchor-id="key-assumptions-1">2.3.3 Key Assumptions</h3>
<p>The paired samples t-test makes several key assumptions:</p>
<ol type="1">
<li><p><strong>Independence of pairs:</strong> While the two measurements within a pair are related, the pairs themselves should be independent of each other</p></li>
<li><p><strong>Normality of differences:</strong> The differences between paired measurements should be approximately normally distributed</p></li>
</ol>
<p>Checking these assumptions:</p>
<ul>
<li>Independence is ensured through study design</li>
<li>Normality of differences can be assessed with histograms, Q-Q plots, or formal tests of the difference scores</li>
</ul>
</section>
<section id="statistical-power-and-advantages-of-paired-designs" class="level3">
<h3 class="anchored" data-anchor-id="statistical-power-and-advantages-of-paired-designs">2.3.4 Statistical Power and Advantages of Paired Designs</h3>
<p>A major advantage of paired designs is increased statistical power. By having each participant serve as their own control, paired designs reduce the impact of individual differences, which can be a major source of variability in between-subjects designs.</p>
<div class="margin-note">
<p>When measurements are positively correlated (as they often are in pre-post designs), paired designs can achieve the same statistical power as independent designs with much smaller sample sizes.</p>
</div>
<p>This increased power comes from:</p>
<ol type="1">
<li><strong>Eliminating between-subject variability:</strong> Individual differences are controlled by comparing each participant to themselves</li>
<li><strong>Taking advantage of the correlation between paired measurements:</strong> The more correlated the measurements, the greater the power advantage</li>
</ol>
</section>
<section id="effect-size-for-paired-samples-t-test" class="level3">
<h3 class="anchored" data-anchor-id="effect-size-for-paired-samples-t-test">2.3.5 Effect Size for Paired Samples t-test</h3>
<p>The effect size for a paired samples t-test can also be calculated using Cohen’s d:</p>
<p><span class="math display">\[d = \frac{\bar{d}}{s_d}\]</span></p>
<p>Where: - <span class="math inline">\(\bar{d}\)</span> is the mean difference - <span class="math inline">\(s_d\)</span> is the standard deviation of the differences</p>
<div class="margin-note">
<p>When reporting paired samples t-test results, it’s important to report both the t-statistic and the effect size.</p>
</div>
<div style="width:175%; margin-left:-75%; position:relative; overflow:visible;">
<pre class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 700

library(shiny)
library(ggplot2)
library(dplyr)

ui &lt;- fluidPage(
  titlePanel("Paired Samples t-test Interactive Visualization"),
  
  sidebarLayout(
    sidebarPanel(
      width = 3,
      h4("Sample Parameters"),
      numericInput("sample_size", "Sample Size:", value = 25, min = 5, max = 100),
      
      h4("Pre-Post Parameters"),
      numericInput("pre_mean", "Pre-test Mean:", value = 60, min = 0, max = 100),
      numericInput("post_mean", "Post-test Mean:", value = 50, min = 0, max = 100),
      numericInput("pre_sd", "Pre-test SD:", value = 10, min = 1, max = 30),
      numericInput("post_sd", "Post-test SD:", value = 12, min = 1, max = 30),
      
      sliderInput("correlation", "Correlation between Pre and Post:", 
                  min = -1, max = 1, value = 0.7, step = 0.1),
      
      hr(),
      actionButton("simulate", "Generate New Data", class = "btn-primary"),
      
      hr(),
      h4("Compare Designs"),
      checkboxInput("show_comparison", "Show Independent vs. Paired Comparison", TRUE)
    ),
    
    mainPanel(
      width = 9,
      tabsetPanel(
        tabPanel("Distributions", 
                 plotOutput("distributionPlot"),
                 div(class = "well", 
                     h4("Understanding Pre-Post Distributions"),
                     p("This plot shows the distribution of scores at pre-test and post-test. The dashed lines represent the means for each time point."),
                     p("Note how the correlation between measurements (", textOutput("correlation_text", inline = TRUE), ") affects the paired t-test results. Higher correlations generally lead to more powerful tests.")
                 )
        ),
        tabPanel("Individual Trajectories", 
                 plotOutput("trajectoryPlot"),
                 div(class = "well", 
                     h4("Visualizing Individual Change"),
                     p("This plot shows how each participant changed from pre-test to post-test. Each gray line represents one participant."),
                     p("The red line shows the average trajectory. Notice how individual patterns of change can vary substantially, even when the overall trend is clear.")
                 )
        ),
        tabPanel("Results", 
                 verbatimTextOutput("ttest_results"),
                 verbatimTextOutput("effect_size"),
                 conditionalPanel(
                   condition = "input.show_comparison == true",
                   plotOutput("designComparisonPlot"),
                   verbatimTextOutput("designComparison"),
                   div(class = "well", 
                       h4("Paired vs. Independent Design Comparison"),
                       p("This comparison demonstrates the power advantage of paired designs. By controlling for individual differences, paired designs can detect smaller effects with the same sample size."),
                       p("The power advantage increases with stronger correlations between measurements.")
                   )
                 )
        )
      )
    )
  )
)

server &lt;- function(input, output, session) {
  
  # Output correlation value
  output$correlation_text &lt;- renderText({
    paste0(input$correlation)
  })
  
  # Generate data reactively based on inputs
  sim_data &lt;- eventReactive(c(input$simulate, input$sample_size, input$pre_mean, 
                             input$post_mean, input$pre_sd, input$post_sd, 
                             input$correlation), {
    set.seed(sample(1:1000, 1))
    
    # Create correlated pre-post data
    n &lt;- input$sample_size
    rho &lt;- input$correlation
    
    # Create covariance matrix
    sigma &lt;- matrix(c(input$pre_sd^2, 
                      rho * input$pre_sd * input$post_sd,
                      rho * input$pre_sd * input$post_sd, 
                      input$post_sd^2), 
                    nrow = 2)
    
    # Generate multivariate normal data with correlation
    library(MASS)
    raw_data &lt;- mvrnorm(n, 
                        mu = c(input$pre_mean, input$post_mean), 
                        Sigma = sigma)
    
    # Convert to data frame
    data_wide &lt;- data.frame(
      id = 1:n,
      pre = raw_data[, 1],
      post = raw_data[, 2]
    )
    
    # Create long format for some plots
    data_long &lt;- tidyr::pivot_longer(
      data_wide,
      cols = c(pre, post),
      names_to = "time",
      values_to = "score"
    )
    
    data_long$time &lt;- factor(data_long$time, levels = c("pre", "post"))
    
    # Calculate paired t-test
    t_test_result &lt;- t.test(data_wide$pre, data_wide$post, paired = TRUE)
    
    # Calculate Cohen's d for paired data
    differences &lt;- data_wide$pre - data_wide$post
    cohens_d &lt;- mean(differences) / sd(differences)
    
    # For comparison: calculate independent t-test
    t_test_ind &lt;- t.test(data_wide$pre, data_wide$post, paired = FALSE, var.equal = TRUE)
    
    list(
      wide = data_wide,
      long = data_long,
      paired_t = t_test_result,
      independent_t = t_test_ind,
      cohens_d = cohens_d,
      differences = differences
    )
  })
  
  # Distribution plot
  output$distributionPlot &lt;- renderPlot({
    req(sim_data())
    data &lt;- sim_data()$long
    
    # Calculate mean and SD for annotations
    means &lt;- data %&gt;% 
      group_by(time) %&gt;%
      summarize(
        mean = mean(score),
        sd = sd(score)
      )
    
    ggplot(data, aes(x = score, fill = time)) +
      geom_density(alpha = 0.5) +
      geom_vline(data = means, aes(xintercept = mean, color = time),
                 linetype = "dashed", size = 1) +
      labs(title = "Distribution of Pre and Post Scores",
           subtitle = paste0("Correlation between measures: r = ", input$correlation),
           x = "Score", y = "Density") +
      scale_fill_manual(values = c("pre" = "#1f77b4", "post" = "#ff7f0e"),
                        labels = c("Pre-test", "Post-test")) +
      scale_color_manual(values = c("pre" = "#1f77b4", "post" = "#ff7f0e"),
                        labels = c("Pre-test", "Post-test")) +
      theme_minimal() +
      theme(legend.position = "top",
            legend.title = element_blank(),
            plot.title = element_text(face = "bold", size = 16),
            plot.subtitle = element_text(size = 12))
  })
  
  # Individual trajectories plot
  output$trajectoryPlot &lt;- renderPlot({
    req(sim_data())
    data &lt;- sim_data()$wide
    
    # Convert to long format
    data_long &lt;- tidyr::pivot_longer(
      data,
      cols = c(pre, post),
      names_to = "time",
      values_to = "score"
    )
    
    # Calculate means for annotation
    pre_mean &lt;- mean(data$pre)
    post_mean &lt;- mean(data$post)
    
    # Plot individual trajectories
    ggplot(data_long, aes(x = time, y = score, group = id)) +
      geom_line(alpha = 0.3) +
      geom_point(alpha = 0.3) +
      stat_summary(aes(group = 1), fun = mean, geom = "line", 
                   color = "red", size = 1.5) +
      stat_summary(fun = mean, geom = "point", color = "red", size = 3) +
      annotate("text", x = 1, y = pre_mean + 5, 
               label = paste0("Mean = ", round(pre_mean, 1)), color = "red") +
      annotate("text", x = 2, y = post_mean + 5, 
               label = paste0("Mean = ", round(post_mean, 1)), color = "red") +
      labs(title = "Individual Trajectories from Pre-test to Post-test",
           subtitle = "Red line shows average trajectory",
           x = "", y = "Score") +
      scale_x_discrete(labels = c("Pre-test", "Post-test")) +
      theme_minimal() +
      theme(plot.title = element_text(face = "bold", size = 16),
            plot.subtitle = element_text(size = 12),
            axis.title = element_text(size = 14))
  })
  
  # Test results
  output$ttest_results &lt;- renderPrint({
    req(sim_data())
    cat("Paired Samples t-test Results:\n\n")
    print(sim_data()$paired_t)
  })
  
  # Effect size results
  output$effect_size &lt;- renderText({
    req(sim_data())
    d &lt;- sim_data()$cohens_d
    
    effect_size_interpretation &lt;- case_when(
      abs(d) &lt; 0.2 ~ "negligible",
      abs(d) &lt; 0.5 ~ "small",
      abs(d) &lt; 0.8 ~ "medium",
      TRUE ~ "large"
    )
    
    direction &lt;- ifelse(d &gt; 0, "increase", "decrease")
    
    paste0("Effect Size:\n",
          "Cohen's d = ", round(d, 2), " (", effect_size_interpretation, " effect)\n",
          "This represents a ", direction, " from pre-test to post-test.\n\n",
          "Difference scores (Pre minus Post):\n",
          "Mean difference = ", round(mean(sim_data()$differences), 2), "\n",
          "SD of differences = ", round(sd(sim_data()$differences), 2))
  })
  
  # Design Comparison Plot
  output$designComparisonPlot &lt;- renderPlot({
    req(sim_data())
    data &lt;- sim_data()
    
    # Create a data frame for plotting
    plot_data &lt;- data.frame(
      Design = c("Independent", "Paired"),
      t_value = c(abs(data$independent_t$statistic), abs(data$paired_t$statistic)),
      p_value = c(data$independent_t$p.value, data$paired_t$p.value)
    )
    
    # Create custom color based on significance
    plot_data$sig_color &lt;- ifelse(plot_data$p_value &lt; 0.05, "Significant", "Non-significant")
    
    ggplot(plot_data, aes(x = Design, y = t_value, fill = sig_color)) +
      geom_bar(stat = "identity", width = 0.7) +
      geom_text(aes(label = paste0("t = ", round(t_value, 2), "\np = ", round(p_value, 3))),
                vjust = -0.5, size = 4) +
      labs(title = "Comparison of Independent vs. Paired t-test Results",
           subtitle = "Using the same pre-post data",
           y = "t-statistic (absolute value)",
           x = "") +
      scale_fill_manual(values = c("Significant" = "#28a745", "Non-significant" = "#dc3545")) +
      theme_minimal() +
      theme(legend.title = element_blank(),
            plot.title = element_text(face = "bold", size = 16),
            plot.subtitle = element_text(size = 12))
  })
  
  # Design comparison text
  output$designComparison &lt;- renderText({
    req(sim_data())
    data &lt;- sim_data()
    
    paired_p &lt;- data$paired_t$p.value
    ind_p &lt;- data$independent_t$p.value
    
    paired_sig &lt;- paired_p &lt; 0.05
    ind_sig &lt;- ind_p &lt; 0.05
    
    paste0("Comparison of Statistical Power:\n\n",
          "Independent t-test: t(", round(data$independent_t$parameter, 1), ") = ", 
          round(data$independent_t$statistic, 2), ", p = ", round(ind_p, 3), 
          ifelse(ind_sig, " (significant)", " (not significant)"), "\n\n",
          "Paired t-test: t(", round(data$paired_t$parameter, 1), ") = ", 
          round(data$paired_t$statistic, 2), ", p = ", round(paired_p, 3),
          ifelse(paired_sig, " (significant)", " (not significant)"), "\n\n",
          "This demonstrates that paired designs generally have greater statistical power\n",
          "when there is a positive correlation between measurements (r = ", 
          input$correlation, " in this example).")
  })
}

shinyApp(ui, server)</code></pre>
</div>
<p>Experiment with this interactive application to see how the correlation between measurements affects the power of the paired samples t-test compared to an independent samples t-test. Try the following:</p>
<ol type="1">
<li>Keep the means and standard deviations constant, but vary the correlation between pre and post measurements</li>
<li>Observe how the t-value and p-value change for both the paired and independent t-tests</li>
<li>Notice that when the correlation is high, the paired t-test can detect significant differences that the independent t-test misses</li>
</ol>
</section>
</section>
<section id="choosing-between-independent-and-paired-t-tests" class="level2">
<h2 class="anchored" data-anchor-id="choosing-between-independent-and-paired-t-tests">2.4 Choosing Between Independent and Paired t-tests</h2>
<p>Selecting the appropriate t-test is critical for valid inference. Here’s a decision guide:</p>
<p>Use an <strong>independent samples t-test</strong> when:</p>
<ul>
<li>You have two separate groups of participants</li>
<li>Different participants are in each group</li>
<li>The groups are not systematically related</li>
</ul>
<p>Use a <strong>paired samples t-test</strong> when:</p>
<ul>
<li>You have two measurements from the same participants</li>
<li>Participants serve as their own controls</li>
<li>Participants are matched in meaningful ways</li>
</ul>
<div class="margin-note">
<p>Using the wrong test can lead to incorrect conclusions. Independent t-tests used for paired data will underestimate statistical significance, while paired t-tests used for independent data violate statistical assumptions.</p>
</div>
<p>The most common mistake is using an independent samples t-test for pre-post data, which should be analyzed with a paired samples t-test.</p>
<p>The following decision tree can help you select the appropriate test:</p>
<div style="width:175%; margin-left:-75%; position:relative; overflow:visible;">
<pre class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 500

library(shiny)
library(DiagrammeR)

ui &lt;- fluidPage(
  titlePanel("t-test Decision Tree"),
  
  sidebarLayout(
    sidebarPanel(
      width = 3,
      h4("Scenario Information"),
      selectInput("design_type", "Study Design:", 
                 choices = c(
                   "Two separate groups" = "separate",
                   "Same participants measured twice" = "repeated",
                   "Matched participants" = "matched"
                 )),
      
      conditionalPanel(
        condition = "input.design_type == 'separate'",
        selectInput("var_equal", "Are group variances approximately equal?",
                   choices = c("Yes", "No", "Don't know"))
      ),
      
      conditionalPanel(
        condition = "input.design_type != 'separate'",
        selectInput("dependency", "How strong is the relationship between measurements?",
                   choices = c(
                     "Strong (correlation &gt; 0.5)" = "strong",
                     "Moderate (correlation 0.2-0.5)" = "moderate",
                     "Weak (correlation &lt; 0.2)" = "weak",
                     "Don't know" = "unknown"
                   ))
      ),
      
      numericInput("sample_size", "Sample Size (per group):", 
                  value = 30, min = 5, max = 1000),
      
      hr(),
      h4("Recommendation"),
      verbatimTextOutput("recommendation")
    ),
    
    mainPanel(
      width = 9,
      grVizOutput("decision_tree"),
      div(class = "well",
          h4("Understanding the Decision Process"),
          p("This decision tree guides you through selecting the appropriate t-test based on your research design."),
          p("Key considerations:"),
          tags$ul(
            tags$li(strong("Research design:"), "Are you comparing separate groups or repeated measurements?"),
            tags$li(strong("Variance assumptions:"), "For independent groups, are the variances similar?"),
            tags$li(strong("Relationship between measurements:"), "For paired designs, how strongly are the measurements correlated?"),
            tags$li(strong("Sample size:"), "Smaller samples may require more attention to assumptions.")
          )
      )
    )
  )
)

server &lt;- function(input, output, session) {
  
  # Create the decision tree
  output$decision_tree &lt;- renderGrViz({
    grViz("
    digraph decision_tree {
      # Graph settings
      graph [rankdir = TB, splines = true, fontname = 'Arial', fontsize = 14, bgcolor = 'transparent']
      node [shape = box, style = filled, fillcolor = 'lightblue', fontname = 'Arial', margin = 0.2]
      edge [fontname = 'Arial', fontsize = 12]
      
      # Nodes
      start [label = 'Are you measuring\nthe same participants twice?', fillcolor = 'gold']
      
      # Independent path
      ind_group [label = 'Independent Samples Design']
      equal_var [label = 'Are group variances\napproximately equal?']
      standard_ttest [label = 'Standard Independent\nSamples t-test', fillcolor = '#a6dba0']
      welch_ttest [label = 'Welch\'s t-test\n(unequal variances)', fillcolor = '#a6dba0']
      
      # Paired path
      pair_group [label = 'Paired Samples Design']
      correlated [label = 'Are measurements\nstrongly correlated?']
      paired_ttest [label = 'Paired Samples t-test', fillcolor = '#a6dba0']
      paired_power [label = 'Paired Samples t-test\n(High power advantage)', fillcolor = '#7fc97f']
      
      # Connections
      start -&gt; ind_group [label = 'No']
      start -&gt; pair_group [label = 'Yes']
      
      ind_group -&gt; equal_var
      equal_var -&gt; standard_ttest [label = 'Yes']
      equal_var -&gt; welch_ttest [label = 'No']
      
      pair_group -&gt; correlated
      correlated -&gt; paired_ttest [label = 'Weak/moderate']
      correlated -&gt; paired_power [label = 'Strong']
      
      # Highlight current path based on inputs
      ")
  })
  
  # Generate recommendation based on inputs
  output$recommendation &lt;- renderText({
    if (input$design_type == "separate") {
      # Independent samples case
      if (input$var_equal == "Yes") {
        result &lt;- "Recommended test: Standard Independent Samples t-test\n\n"
        explanation &lt;- "Because you have two separate groups with approximately equal variances, the standard independent samples t-test is appropriate."
      } else if (input$var_equal == "No") {
        result &lt;- "Recommended test: Welch's t-test\n\n"
        explanation &lt;- "Because you have two separate groups with unequal variances, Welch's t-test is more appropriate than the standard t-test."
      } else {
        result &lt;- "Recommended test: Welch's t-test\n\n"
        explanation &lt;- "When uncertain about equality of variances, it's safer to use Welch's t-test, which doesn't assume equal variances and performs well even when variances are equal."
      }
      
      # Add sample size consideration
      if (input$sample_size &lt; 30) {
        explanation &lt;- paste0(explanation, "\n\nNote: With smaller samples (n = ", input$sample_size, " per group), check the normality assumption carefully. Consider non-parametric alternatives if severe non-normality is present.")
      }
      
    } else {
      # Paired samples case
      result &lt;- "Recommended test: Paired Samples t-test\n\n"
      
      if (input$design_type == "repeated") {
        design_explanation &lt;- "because you're measuring the same participants twice"
      } else {
        design_explanation &lt;- "because you're using matched participants"
      }
      
      if (input$dependency == "strong") {
        power_note &lt;- "\n\nWith strong correlation between measurements (r &gt; 0.5), the paired design offers a substantial power advantage over an independent design."
      } else if (input$dependency == "moderate") {
        power_note &lt;- "\n\nWith moderate correlation between measurements (r = 0.2-0.5), the paired design offers some power advantage over an independent design."
      } else if (input$dependency == "weak") {
        power_note &lt;- "\n\nWith weak correlation between measurements (r &lt; 0.2), the paired design offers minimal power advantage over an independent design, but is still more appropriate conceptually."
      } else {
        power_note &lt;- "\n\nEven without knowing the correlation strength, the paired design is more appropriate conceptually for your study."
      }
      
      explanation &lt;- paste0("This test is appropriate ", design_explanation, ".", power_note)
      
      # Add sample size consideration
      if (input$sample_size &lt; 30) {
        explanation &lt;- paste0(explanation, "\n\nNote: With a smaller sample size (n = ", input$sample_size, "), check the normality of the difference scores. Consider non-parametric alternatives like the Wilcoxon signed-rank test if severe non-normality is present.")
      }
    }
    
    paste0(result, explanation)
  })
}

shinyApp(ui, server)</code></pre>
</div>
</section>
<section id="interpretation-and-reporting" class="level2">
<h2 class="anchored" data-anchor-id="interpretation-and-reporting">2.5 Interpretation and Reporting</h2>
<p>When interpreting t-test results, consider both statistical significance and effect size:</p>
<ol type="1">
<li><strong>Statistical significance (p-value):</strong> Indicates whether the observed difference is likely due to chance</li>
<li><strong>Effect size (Cohen’s d):</strong> Indicates the magnitude of the difference</li>
<li><strong>Confidence intervals:</strong> Provide a range of plausible values for the true difference</li>
</ol>
<div class="example">
<p><strong>Reporting Example (Independent Samples):</strong> “Clients receiving CBT (M = 12.3, SD = 4.2) had significantly lower depression scores than those receiving supportive therapy (M = 15.8, SD = 4.5), t(58) = 3.12, p = .003, d = 0.81, 95% CI [1.28, 5.72]. The large effect size suggests that the difference between treatments is clinically meaningful.”</p>
<p><strong>Reporting Example (Paired Samples):</strong> “Depression scores decreased significantly from pre-treatment (M = 18.4, SD = 5.3) to post-treatment (M = 11.6, SD = 6.1), t(24) = 5.89, p &lt; .001, d = 1.18, 95% CI [4.42, 9.18]. This large effect size indicates substantial clinical improvement.”</p>
</div>
<section id="clinical-vs.-statistical-significance-1" class="level3">
<h3 class="anchored" data-anchor-id="clinical-vs.-statistical-significance-1">2.5.1 Clinical vs.&nbsp;Statistical Significance</h3>
<p>Remember that statistical significance doesn’t necessarily imply clinical significance. A statistically significant result with a small effect size might not translate to meaningful improvements in clients’ lives.</p>
<div class="margin-note">
<p>When evaluating treatments, consider not just whether they produce statistically significant improvements, but whether those improvements are large enough to make a difference in clients’ functioning and quality of life.</p>
</div>
<p>Several approaches to assessing clinical significance include:</p>
<ol type="1">
<li><strong>Normative comparisons:</strong> Do post-treatment scores fall within the normal range?</li>
<li><strong>Reliable Change Index (RCI):</strong> Does the change exceed what would be expected due to measurement error?</li>
<li><strong>Minimally Clinically Important Difference (MCID):</strong> Does the change exceed a threshold considered meaningful by patients or clinicians?</li>
<li><strong>Functional outcomes:</strong> Does the change lead to improvements in daily functioning or quality of life?</li>
</ol>
<div style="width:175%; margin-left:-75%; position:relative; overflow:visible;">
<pre class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 600

library(shiny)
library(ggplot2)
library(dplyr)

ui &lt;- fluidPage(
  titlePanel("Statistical vs. Clinical Significance"),
  
  sidebarLayout(
    sidebarPanel(
      width = 3,
      h4("Study Parameters"),
      
      # Sample size
      numericInput("n_treat", "Treatment Group Size:", value = 30, min = 5, max = 1000),
      numericInput("n_control", "Control Group Size:", value = 30, min = 5, max = 1000),
      
      # Effect parameters
      sliderInput("mean_diff", "Mean Difference (Treatment - Control):", 
                 min = -10, max = 10, value = -3, step = 0.5),
      sliderInput("pooled_sd", "Pooled Standard Deviation:", 
                 min = 1, max = 10, value = 5, step = 0.5),
      
      hr(),
      
      # Clinical significance parameters
      h4("Clinical Significance Criteria"),
      numericInput("mcid", "Minimally Clinically Important Difference (MCID):", 
                  value = 5, min = 0, max = 20),
      numericInput("clinical_cutoff", "Clinical/Non-clinical Cutoff Score:", 
                  value = 10, min = 0, max = 50),
      numericInput("reliability", "Test Reliability (rxx):", 
                  value = 0.8, min = 0, max = 1, step = 0.05),
      
      actionButton("simulate", "Run Simulation", class = "btn-primary")
    ),
    
    mainPanel(
      width = 9,
      tabsetPanel(
        tabPanel("Distribution Comparison",
                 plotOutput("distributionPlot"),
                 div(class = "well",
                     h4("Understanding Statistical vs. Clinical Significance"),
                     p("This plot shows the distributions of scores in the treatment and control groups."),
                     p("Statistical significance (p-value) tells us whether the difference between groups is likely due to chance."),
                     p("Clinical significance tells us whether the difference is meaningful in practical terms.")
                 )
        ),
        tabPanel("Individual-Level Analysis",
                 plotOutput("individualPlot"),
                 div(class = "well",
                     h4("Individual-Level Clinical Significance"),
                     p("This visualization shows the proportion of participants who:"),
                     tags$ul(
                       tags$li("Achieved reliable change (change beyond measurement error)"),
                       tags$li("Crossed the clinical cutoff (moved from clinical to non-clinical range)"),
                       tags$li("Achieved both reliable and clinically significant change")
                     ),
                     p("Groups may differ statistically but with few individuals showing clinically meaningful improvement.")
                 )
        ),
        tabPanel("Results Summary",
                 verbatimTextOutput("statistical_results"),
                 verbatimTextOutput("clinical_results"),
                 div(class = "well",
                     h4("Implications for Interpretation"),
                     p("When evaluating treatment effectiveness, consider both:"),
                     tags$ul(
                       tags$li("Statistical significance: Is the effect likely due to chance?"),
                       tags$li("Effect size: How large is the difference?"),
                       tags$li("Clinical significance: Does the treatment produce meaningful change in patients' lives?")
                     ),
                     p("A statistically significant difference might not be clinically meaningful, and vice versa.")
                 )
        )
      )
    )
  )
)

server &lt;- function(input, output, session) {
  
  # Generate simulated data
  sim_data &lt;- eventReactive(c(input$simulate, input$n_treat, input$n_control, 
                             input$mean_diff, input$pooled_sd), {
    set.seed(sample(1:1000, 1))
    
    # Control group (standard normal distribution scaled by pooled SD)
    control_mean &lt;- 15  # Arbitrary baseline
    control_scores &lt;- rnorm(input$n_control, mean = control_mean, sd = input$pooled_sd)
    
    # Treatment group (mean shifted by the specified difference)
    treat_mean &lt;- control_mean + input$mean_diff
    treat_scores &lt;- rnorm(input$n_treat, mean = treat_mean, sd = input$pooled_sd)
    
    # Combine into a dataset
    data &lt;- data.frame(
      id = 1:(input$n_treat + input$n_control),
      group = c(rep("Treatment", input$n_treat), rep("Control", input$n_control)),
      score = c(treat_scores, control_scores)
    )
    
    # Perform t-test
    t_result &lt;- t.test(score ~ group, data = data)
    
    # Calculate Cohen's d
    g1_data &lt;- data$score[data$group == "Treatment"]
    g2_data &lt;- data$score[data$group == "Control"]
    pooled_sd_calc &lt;- sqrt(((length(g1_data) - 1) * var(g1_data) + 
                           (length(g2_data) - 1) * var(g2_data)) / 
                           (length(g1_data) + length(g2_data) - 2))
    cohens_d &lt;- (mean(g1_data) - mean(g2_data)) / pooled_sd_calc
    
    # Add clinical significance metrics
    
    # 1. Calculate reliable change index (RCI)
    SEM &lt;- input$pooled_sd * sqrt(1 - input$reliability)
    Sdiff &lt;- sqrt(2 * SEM^2)
    RCI_threshold &lt;- 1.96 * Sdiff
    
    # Generate pre-post scores for simulating individual-level change
    # We'll use the control group as a baseline and treatment effect as change
    pre_scores &lt;- rnorm(input$n_treat, mean = control_mean, sd = input$pooled_sd)
    post_scores &lt;- pre_scores + input$mean_diff + rnorm(input$n_treat, mean = 0, sd = SEM * 2)
    
    # Determine reliable change for each person
    reliable_change &lt;- abs(post_scores - pre_scores) &gt; RCI_threshold
    
    # Determine clinically significant change (crossing cutoff)
    # Assuming lower scores are better
    crossed_cutoff &lt;- pre_scores &gt; input$clinical_cutoff &amp; post_scores &lt; input$clinical_cutoff
    
    # Both reliable and clinically significant change
    full_recovery &lt;- reliable_change &amp; crossed_cutoff
    
    # Calculate percentages
    pct_reliable &lt;- mean(reliable_change) * 100
    pct_cutoff &lt;- mean(crossed_cutoff) * 100
    pct_full &lt;- mean(full_recovery) * 100
    
    # Result data
    individual_data &lt;- data.frame(
      id = 1:input$n_treat,
      pre = pre_scores,
      post = post_scores,
      change = post_scores - pre_scores,
      reliable = reliable_change,
      crossed = crossed_cutoff,
      full = full_recovery
    )
    
    # Combine all results
    return(list(
      data = data,
      t_result = t_result,
      cohens_d = cohens_d,
      mcid_achieved = abs(input$mean_diff) &gt;= input$mcid,
      individual_data = individual_data,
      pct_reliable = pct_reliable,
      pct_cutoff = pct_cutoff,
      pct_full = pct_full,
      rci_threshold = RCI_threshold
    ))
  })
  
  # Plot group distributions
  output$distributionPlot &lt;- renderPlot({
    req(sim_data())
    
    data &lt;- sim_data()$data
    
    # Add statistical test result for annotation
    p_value &lt;- sim_data()$t_result$p.value
    sig_text &lt;- ifelse(p_value &lt; 0.05, 
                     paste0("Statistically Significant (p = ", round(p_value, 3), ")"),
                     paste0("Not Statistically Significant (p = ", round(p_value, 3), ")"))
    
    # Add clinical significance for annotation
    d &lt;- abs(sim_data()$cohens_d)
    mcid_achieved &lt;- sim_data()$mcid_achieved
    
    if (mcid_achieved) {
      clin_text &lt;- paste0("Clinically Significant (Difference &gt; MCID of ", input$mcid, ")")
    } else {
      clin_text &lt;- paste0("Not Clinically Significant (Difference &lt; MCID of ", input$mcid, ")")
    }
    
    # Density plot
    ggplot(data, aes(x = score, fill = group)) +
      geom_density(alpha = 0.5) +
      geom_vline(data = data %&gt;% group_by(group) %&gt;% 
                 summarize(mean = mean(score)), 
                 aes(xintercept = mean, color = group),
                 linetype = "dashed", size = 1) +
      geom_vline(xintercept = input$clinical_cutoff, linetype = "dotted", 
                color = "darkred", size = 1) +
      annotate("text", x = input$clinical_cutoff + 1, y = 0, 
               label = "Clinical Cutoff", angle = 90, color = "darkred") +
      labs(title = "Treatment vs. Control Group Score Distributions",
           subtitle = paste0(sig_text, "\n", clin_text),
           x = "Score (lower is better)", y = "Density") +
      theme_minimal() +
      theme(legend.position = "top",
            legend.title = element_blank(),
            plot.title = element_text(face = "bold", size = 16),
            plot.subtitle = element_text(size = 12)) +
      scale_fill_manual(values = c("Treatment" = "#1f77b4", "Control" = "#ff7f0e")) +
      scale_color_manual(values = c("Treatment" = "#1f77b4", "Control" = "#ff7f0e"))
  })
  
  # Plot individual-level changes
  output$individualPlot &lt;- renderPlot({
    req(sim_data())
    
    ind_data &lt;- sim_data()$individual_data
    
    # Create a summary for plotting
    summary_data &lt;- data.frame(
      Category = c("Reliable Change", "Crossed Clinical Cutoff", "Both (Full Recovery)"),
      Percentage = c(sim_data()$pct_reliable, sim_data()$pct_cutoff, sim_data()$pct_full)
    )
    
    # Set factor levels for ordering
    summary_data$Category &lt;- factor(summary_data$Category, 
                                  levels = c("Reliable Change", 
                                            "Crossed Clinical Cutoff", 
                                            "Both (Full Recovery)"))
    
    # Bar chart of percentages
    ggplot(summary_data, aes(x = Category, y = Percentage, fill = Category)) +
      geom_bar(stat = "identity", width = 0.6) +
      geom_text(aes(label = paste0(round(Percentage, 1), "%")), 
               vjust = -0.5, size = 5) +
      labs(title = "Individual-Level Clinical Significance Metrics",
           subtitle = paste0("Mean Change = ", round(mean(ind_data$change), 2), 
                           ", RCI Threshold = ", round(sim_data()$rci_threshold, 2)),
           x = "", y = "Percentage of Treatment Group") +
      theme_minimal() +
      theme(legend.position = "none",
            plot.title = element_text(face = "bold", size = 16),
            plot.subtitle = element_text(size = 12),
            axis.text.x = element_text(size = 12)) +
      scale_fill_brewer(palette = "Set2") +
      ylim(0, 100)
  })
  
  # Statistical results output
  output$statistical_results &lt;- renderText({
    req(sim_data())
    
    t_result &lt;- sim_data()$t_result
    data &lt;- sim_data()$data
    
    # Calculate means and SDs
    treat_stats &lt;- data %&gt;% 
      filter(group == "Treatment") %&gt;%
      summarize(M = mean(score), SD = sd(score))
    
    control_stats &lt;- data %&gt;% 
      filter(group == "Control") %&gt;%
      summarize(M = mean(score), SD = sd(score))
    
    paste0("Statistical Significance Results:\n\n",
          "Treatment Group: M = ", round(treat_stats$M, 2), ", SD = ", round(treat_stats$SD, 2), "\n",
          "Control Group: M = ", round(control_stats$M, 2), ", SD = ", round(control_stats$SD, 2), "\n\n",
          "Independent Samples t-test: t(", round(t_result$parameter, 1), ") = ", 
          round(t_result$statistic, 2), ", p = ", 
          ifelse(t_result$p.value &lt; 0.001, "&lt; .001", round(t_result$p.value, 3)), "\n",
          "Cohen's d = ", round(sim_data()$cohens_d, 2), " (", 
          case_when(
            abs(sim_data()$cohens_d) &lt; 0.2 ~ "negligible",
            abs(sim_data()$cohens_d) &lt; 0.5 ~ "small",
            abs(sim_data()$cohens_d) &lt; 0.8 ~ "medium",
            TRUE ~ "large"
          ), " effect size)\n",
          "95% CI for mean difference: [", 
          round(t_result$conf.int[1], 2), ", ", round(t_result$conf.int[2], 2), "]")
  })
  
  # Clinical significance output
  output$clinical_results &lt;- renderText({
    req(sim_data())
    
    ind_data &lt;- sim_data()$individual_data
    data &lt;- sim_data()$data
    
    # Compare mean difference to MCID
    mcid_comparison &lt;- ifelse(abs(input$mean_diff) &gt;= input$mcid,
                             paste0("The mean difference (", round(abs(input$mean_diff), 2), 
                                   ") exceeds the MCID (", input$mcid, ")."),
                             paste0("The mean difference (", round(abs(input$mean_diff), 2), 
                                   ") is smaller than the MCID (", input$mcid, ")."))
    
    paste0("Clinical Significance Results:\n\n",
          mcid_comparison, "\n\n",
          "Individual-level metrics in the treatment group:\n",
          "- ", round(sim_data()$pct_reliable, 1), "% achieved reliable change (change &gt; RCI threshold of ", 
          round(sim_data()$rci_threshold, 2), ")\n",
          "- ", round(sim_data()$pct_cutoff, 1), "% crossed the clinical cutoff (", input$clinical_cutoff, ")\n",
          "- ", round(sim_data()$pct_full, 1), "% achieved both reliable change and crossed the cutoff\n\n",
          "Interpretation:\n",
          ifelse(sim_data()$pct_full &gt; 30, 
                "A substantial proportion of individuals showed clinically meaningful improvement.",
                ifelse(sim_data()$pct_full &gt; 10,
                      "Some individuals showed clinically meaningful improvement, but the majority did not.",
                      "Few individuals showed clinically meaningful improvement despite the statistical results.")))
  })
}

shinyApp(ui, server)</code></pre>
</div>
<p>Experiment with the interactive application above to see how effect size, sample size, and clinical significance criteria interact. As you adjust the parameters, pay attention to how a statistically significant result might not be clinically significant, and vice versa.</p>
</section>
</section>
<section id="common-misinterpretations" class="level2">
<h2 class="anchored" data-anchor-id="common-misinterpretations">2.6 Common Misinterpretations</h2>
<p>Avoid these common misinterpretations of t-test results:</p>
<ol type="1">
<li><p><strong>Misinterpreting non-significant results:</strong> Failing to reject the null hypothesis does not prove that there is no difference between groups. It simply means there’s insufficient evidence to conclude that a difference exists.</p></li>
<li><p><strong>Overinterpreting p-values:</strong> A very small p-value doesn’t necessarily indicate a large or important effect. Similarly, a p-value just above 0.05 doesn’t mean there is definitively no effect.</p></li>
<li><p><strong>Ignoring assumptions:</strong> Violating t-test assumptions can lead to invalid conclusions. Always check assumptions before interpreting results.</p></li>
<li><p><strong>Equating statistical significance with clinical significance:</strong> A statistically significant difference isn’t necessarily large enough to be clinically meaningful.</p></li>
</ol>
</section>
<section id="summary-1" class="level2">
<h2 class="anchored" data-anchor-id="summary-1">2.7 Summary</h2>
<p>T-tests are foundational statistical tools for comparing two means. Key points to remember:</p>
<ul>
<li>Independent samples t-tests compare means from two separate groups</li>
<li>Paired samples t-tests compare means from related observations</li>
<li>Both tests have assumptions that should be checked</li>
<li>Report both statistical significance (p-value) and effect size (Cohen’s d)</li>
<li>Consider clinical significance in addition to statistical significance</li>
</ul>
<p>In the next chapter, we’ll extend these concepts to scenarios with more than two groups using Analysis of Variance (ANOVA).</p>
<pre class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 700

library(shiny)
library(shinyjs)

ui &lt;- fluidPage(
  useShinyjs(),
  tags$head(
    tags$style(HTML("
      .quiz-container {
        max-width: 800px;
        margin: 0 auto;
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 20px;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
      }
      .question {
        margin-bottom: 30px;
        padding-bottom: 20px;
        border-bottom: 1px solid #dee2e6;
      }
      .question-title {
        font-weight: bold;
        margin-bottom: 15px;
        color: #212529;
      }
      .feedback {
        margin-top: 15px;
        padding: 15px;
        border-radius: 5px;
      }
      .correct {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
      }
      .incorrect {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
      }
      .panel-heading {
        background-color: #6c757d;
        color: white;
        padding: 10px 15px;
        border-radius: 5px 5px 0 0;
      }
      .panel-body {
        background-color: white;
        padding: 15px;
        border: 1px solid #dee2e6;
        border-top: none;
        border-radius: 0 0 5px 5px;
      }
      .result-container {
        margin-top: 20px;
        text-align: center;
      }
      .btn-submit-answer {
        margin-top: 10px;
      }
      .explanation {
        font-style: italic;
        margin-top: 10px;
      }
    "))
  ),
  
  div(class = "container-fluid",
      div(class = "row",
          div(class = "col-md-12",
              div(class = "quiz-container",
                  
                  # Quiz header
                  div(class = "panel-heading",
                      h2("Chapter 2 Quiz: Comparing Two Groups", style = "margin-top: 0;")
                  ),
                  
                  div(class = "panel-body",
                      p("Test your understanding of t-tests and their applications. For each question, select the best answer and click 'Submit' to see feedback."),
                      
                      # Question 1
                      div(class = "question", id = "q1_container",
                          div(class = "question-title", "Question 1: When to Use Independent vs. Paired t-tests"),
                          p("A researcher measures depression in 30 participants who receive CBT and 30 different participants who receive psychodynamic therapy. What type of t-test should be used to compare the effectiveness of these therapies?"),
                          
                          radioButtons("q1", NULL, 
                                     choices = c(
                                       "Independent samples t-test" = "correct",
                                       "Paired samples t-test" = "incorrect1",
                                       "One-sample t-test" = "incorrect2",
                                       "Welch's t-test" = "incorrect3"
                                     )),
                          actionButton("check1", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback1")
                      ),
                      
                      # Question 2
                      div(class = "question", id = "q2_container",
                          div(class = "question-title", "Question 2: Paired Designs"),
                          p("A clinical psychologist measures anxiety in 25 clients before and after an 8-week mindfulness intervention. What type of t-test is appropriate, and what are the advantages of this design?"),
                          
                          radioButtons("q2", NULL, 
                                     choices = c(
                                       "Paired samples t-test; it controls for individual differences and has greater statistical power when measurements are correlated." = "correct",
                                       "Independent samples t-test; it allows for comparisons across different time points without making assumptions about the correlation between measurements." = "incorrect1",
                                       "Paired samples t-test; it allows for a larger sample size because each participant contributes two data points." = "incorrect2",
                                       "Independent samples t-test; it's more robust to violations of the normality assumption than the paired samples t-test." = "incorrect3"
                                     )),
                          actionButton("check2", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback2")
                      ),
                      
                      # Question 3
                      div(class = "question", id = "q3_container",
                          div(class = "question-title", "Question 3: Interpreting t-test Results"),
                          p("A study reports: \"The treatment group (M = 14.3, SD = 3.2) showed significantly lower anxiety than the control group (M = 16.1, SD = 3.5), t(58) = 2.11, p = .039, d = 0.54.\" How would you interpret these results?"),
                          
                          radioButtons("q3", NULL, 
                                     choices = c(
                                       "The treatment group had lower anxiety than the control group, with a medium effect size. The difference is statistically significant but may be of moderate clinical importance." = "correct",
                                       "The treatment group had lower anxiety than the control group, with a large effect size. The difference is both statistically and clinically significant." = "incorrect1",
                                       "The treatment group had lower anxiety than the control group, but the effect is not statistically significant (p &gt; .01) and therefore likely due to chance." = "incorrect2", 
                                       "The treatment reduced anxiety by 0.54 standard deviations, which is not enough to be considered clinically meaningful regardless of statistical significance." = "incorrect3"
                                     )),
                          actionButton("check3", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback3")
                      ),
                      
                      # Question 4
                      div(class = "question", id = "q4_container",
                          div(class = "question-title", "Question 4: t-test Assumptions"),
                          p("What are the key assumptions of the independent samples t-test, and how can they be checked?"),
                          
                          radioButtons("q4", NULL, 
                                     choices = c(
                                       "Independence, normality, and homogeneity of variance; checked through study design, histograms/Q-Q plots, and Levene's test, respectively." = "correct",
                                       "Random sampling, normal distribution, and equal sample sizes; checked through random assignment, Kolmogorov-Smirnov test, and ensuring equal n in each group." = "incorrect1",
                                       "Independence, linearity, and homoscedasticity; checked through correlation analysis, scatterplots, and Breusch-Pagan test." = "incorrect2",
                                       "Large sample size, balanced design, and sphericity; checked through power analysis, equal group sizes, and Mauchly's test." = "incorrect3"
                                     )),
                          actionButton("check4", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback4")
                      ),
                      
                      # Question 5
                      div(class = "question", id = "q5_container",
                          div(class = "question-title", "Question 5: Statistical vs. Clinical Significance"),
                          p("A large study (N = 500) comparing two therapies finds a statistically significant difference (p = .01) but a small effect size (d = 0.25). What is the most appropriate conclusion?"),
                          
                          radioButtons("q5", NULL, 
                                     choices = c(
                                       "The difference between therapies is statistically reliable but may have limited clinical importance due to the small effect size." = "correct",
                                       "The small p-value indicates that one therapy is definitely superior to the other in clinical practice." = "incorrect1",
                                       "The small effect size means the results should be discounted despite statistical significance." = "incorrect2",
                                       "With such a large sample, even this small effect size indicates clinically meaningful differences between the therapies." = "incorrect3"
                                     )),
                          actionButton("check5", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback5")
                      ),
                      
                      # Score display
                      div(id = "score_section", class = "result-container",
                          actionButton("calculate_score", "Calculate My Score", class = "btn-success btn-lg"),
                          htmlOutput("final_score")
                      )
                  )
              )
          )
      )
  )
)

server &lt;- function(input, output, session) {
  
  # Initialize score tracking
  score &lt;- reactiveVal(0)
  answered &lt;- reactiveVal(rep(FALSE, 5))
  
  # Question 1 feedback
  observeEvent(input$check1, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[1] &lt;- TRUE
    answered(current_answered)
    
    # Check if correct and update score
    is_correct &lt;- input$q1 == "correct"
    if(is_correct) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback1 &lt;- renderUI({
      if(is_correct) {
        div(class = "feedback correct",
            h4("Correct!"),
            p(class = "explanation", "The independent samples t-test is appropriate here because there are two separate, unrelated groups of participants. Each participant is in only one group (either CBT or psychodynamic therapy), so the observations are independent between groups.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "A paired samples t-test would be appropriate if the same participants received both therapies or if participants were matched in some way. Here, there are different participants in each group, so an independent samples t-test is needed. One-sample t-test compares one group to a known value, and Welch's is a variant of the independent t-test used when variances are unequal.")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check1")
  })
  
  # Question 2 feedback
  observeEvent(input$check2, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[2] &lt;- TRUE
    answered(current_answered)
    
    # Check if correct and update score
    is_correct &lt;- input$q2 == "correct"
    if(is_correct) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback2 &lt;- renderUI({
      if(is_correct) {
        div(class = "feedback correct",
            h4("Correct!"),
            p(class = "explanation", "A paired samples t-test is appropriate because the same clients are measured twice (before and after intervention). This design reduces error variance by controlling for individual differences—each person serves as their own control. When pre and post measurements are positively correlated (as they typically are), paired designs have substantially greater statistical power than independent designs with the same number of participants.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "When the same participants are measured at two time points, a paired samples t-test is appropriate. The key advantage is not about sample size (each participant still provides only one difference score), but about controlling for individual differences, which reduces error variance and increases statistical power. Independent samples t-tests are not appropriate for pre-post designs and do not have the described advantages.")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check2")
  })
  
  # Question 3 feedback
  observeEvent(input$check3, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[3] &lt;- TRUE
    answered(current_answered)
    
    # Check if correct and update score
    is_correct &lt;- input$q3 == "correct"
    if(is_correct) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback3 &lt;- renderUI({
      if(is_correct) {
        div(class = "feedback correct",
            h4("Correct!"),
            p(class = "explanation", "The results show a statistically significant difference (p = .039 &lt; .05) between the treatment and control groups, with the treatment group showing lower anxiety. The effect size (d = 0.54) is considered medium according to Cohen's guidelines. This suggests a reliable difference of moderate magnitude, which may or may not translate to clinically meaningful improvements, depending on context and clinical significance criteria.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "The p-value of .039 indicates statistical significance at the conventional .05 level. The effect size (d = 0.54) is considered medium, not large, according to Cohen's guidelines. We can't automatically determine clinical significance based solely on statistical significance or effect size without additional context about what constitutes a meaningful change for this particular anxiety measure and population.")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check3")
  })
  
  # Question 4 feedback
  observeEvent(input$check4, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[4] &lt;- TRUE
    answered(current_answered)
    
    # Check if correct and update score
    is_correct &lt;- input$q4 == "correct"
    if(is_correct) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback4 &lt;- renderUI({
      if(is_correct) {
        div(class = "feedback correct",
            h4("Correct!"),
            p(class = "explanation", "The key assumptions of the independent samples t-test are: (1) Independence of observations within and between groups, which is primarily ensured through proper study design; (2) Normal distribution of the dependent variable in each group, which can be checked using histograms, Q-Q plots, or formal tests like Shapiro-Wilk; and (3) Homogeneity of variance (equal variances between groups), which can be assessed using Levene's test.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "The three primary assumptions for independent samples t-tests are independence, normality, and homogeneity of variance. Equal sample sizes are not required, although they make the test more robust to variance violations. Linearity and homoscedasticity are assumptions for regression, not t-tests. Sphericity is an assumption for repeated measures ANOVA, not t-tests.")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check4")
  })
  
  # Question 5 feedback
  observeEvent(input$check5, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[5] &lt;- TRUE
    answered(current_answered)
    
    # Check if correct and update score
    is_correct &lt;- input$q5 == "correct"
    if(is_correct) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback5 &lt;- renderUI({
      if(is_correct) {
        div(class = "feedback correct",
            h4("Correct!"),
            p(class = "explanation", "With a large sample size (N = 500), even small effects can be statistically significant. The p-value of .01 indicates the difference is likely not due to chance, but the small effect size (d = 0.25) suggests the magnitude of difference between therapies is modest. This distinction between statistical and clinical significance is crucial—a statistically significant difference might not translate to meaningful differences in clinical outcomes for patients.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "Statistical significance (p-value) only tells us that the observed difference is unlikely to be due to chance; it doesn't necessarily indicate clinical importance. The small effect size (d = 0.25) suggests the magnitude of difference between therapies is quite modest, regardless of sample size. We should neither automatically accept the superiority of one therapy based solely on statistical significance nor dismiss findings entirely due to a small effect size—context matters for interpreting clinical relevance.")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check5")
  })
  
  # Calculate and display final score
  observeEvent(input$calculate_score, {
    # Check if all questions have been answered
    if(!all(answered())) {
      output$final_score &lt;- renderUI({
        div(class = "alert alert-warning",
            h4("Please answer all questions first!"),
            p("Make sure you've submitted an answer for each question before calculating your score.")
        )
      })
      return()
    }
    
    # Calculate percentage
    total &lt;- 5
    current_score &lt;- score()
    percentage &lt;- round((current_score / total) * 100)
    
    # Generate feedback based on score
    feedback &lt;- if(percentage &gt;= 80) {
      "Excellent work! You have a strong understanding of t-tests and their applications in clinical psychology."
    } else if(percentage &gt;= 60) {
      "Good job! You understand many key concepts about t-tests, but might want to review some areas to strengthen your understanding."
    } else {
      "You might benefit from reviewing this chapter again to strengthen your understanding of t-tests and their applications."
    }
    
    # Display score and feedback
    output$final_score &lt;- renderUI({
      div(class = "well well-lg",
          h3(paste0("Your Score: ", current_score, "/", total, " (", percentage, "%)")),
          p(feedback),
          if(percentage &lt; 100) {
            p("Review the questions you missed and the explanations provided to deepen your understanding.")
          } else {
            p("Perfect score! You're well-prepared to move on to the next chapter on ANOVA.")
          }
      )
    })
    
    # Disable the button after clicking
    disable("calculate_score")
  })
}

shinyApp(ui, server)</code></pre>
<hr>
</section>
</section>
<section id="comparing-multiple-groups-anova" class="level1 unnumbered">
<h1 class="unnumbered">3. Comparing Multiple Groups: ANOVA</h1>
<div class="key-concepts">
<p><strong>Key Concepts:</strong></p>
<ul>
<li>Analysis of Variance (ANOVA) for comparing more than two groups</li>
<li>Partitioning variance into between-group and within-group components</li>
<li>Main effects and interactions in factorial designs</li>
<li>Between-subjects, within-subjects, and mixed designs</li>
<li>Assumptions of ANOVA and how to check them</li>
<li>Post-hoc tests and planned comparisons</li>
<li>Effect sizes for ANOVA (η², partial η², ω²)</li>
</ul>
</div>
<p>## 3.1 Introduction to ANOVA</p>
<p>Analysis of Variance (ANOVA) extends the logic of the t-test to scenarios where we need to compare more than two groups or examine the effects of multiple independent variables simultaneously.</p>
<div class="definition">
<p><strong>Analysis of Variance (ANOVA):</strong> A collection of statistical models used to analyze the differences among multiple group means by comparing variances.</p>
</div>
<p>::: margin-note While t-tests and ANOVA are typically discussed as separate tests, the independent samples t-test is actually a special case of one-way ANOVA with exactly two groups. :::</p>
<p>ANOVA is based on comparing the variance between groups to the variance within groups. If the between-group variance is large relative to the within-group variance, we can conclude that the groups differ significantly.</p>
<p>The primary advantage of ANOVA over conducting multiple t-tests is that it controls the familywise error rate, reducing the likelihood of Type I errors when making multiple comparisons.</p>
<section id="one-way-anova" class="level2">
<h2 class="anchored" data-anchor-id="one-way-anova">3.2 One-way ANOVA</h2>
<p>The simplest form of ANOVA is the one-way (or single-factor) ANOVA, which compares means across multiple groups defined by a single independent variable.</p>
<div class="definition">
<p><strong>One-way ANOVA:</strong> A statistical test that compares means across three or more groups defined by a single independent variable.</p>
</div>
<p>### 3.2.1 When to Use One-way ANOVA</p>
<p>Use one-way ANOVA when:</p>
<ul>
<li>You have one independent variable (factor) with three or more levels</li>
<li>You have one continuous dependent variable</li>
<li>You want to know if there are significant differences among the group means</li>
</ul>
<div class="example">
<p><strong>Clinical Example:</strong> A researcher wants to compare the effectiveness of three different therapies for PTSD: prolonged exposure (PE), cognitive processing therapy (CPT), and eye movement desensitization and reprocessing (EMDR). They randomly assign 20 clients to each therapy and measure PTSD symptom severity after treatment. One-way ANOVA is appropriate to determine if there are significant differences among the three therapies.</p>
</div>
<p>### 3.2.2 The Logic of ANOVA: Partitioning Variance</p>
<p>The fundamental idea behind ANOVA is partitioning the total variance in the data into two components:</p>
<ol type="1">
<li><strong>Between-group variance:</strong> Variance due to differences between group means</li>
<li><strong>Within-group variance:</strong> Variance due to individual differences within groups</li>
</ol>
<p>The F-statistic in ANOVA is the ratio of these two sources of variance:</p>
<p><span class="math display">\[F = \frac{\text{Between-group variance}}{\text{Within-group variance}}\]</span></p>
<p>If the between-group variance is large relative to the within-group variance (resulting in a large F-value), we can conclude that the groups differ significantly.</p>
<div class="margin-note">
<p>The F-statistic follows an F-distribution, which depends on two types of degrees of freedom: degrees of freedom for the numerator (between-group variance) and denominator (within-group variance).</p>
</div>
<p>### 3.2.3 Key Assumptions of ANOVA</p>
<p>One-way ANOVA has several key assumptions:</p>
<ol type="1">
<li><strong>Independence:</strong> Observations within and between groups are independent</li>
<li><strong>Normality:</strong> The dependent variable is approximately normally distributed in each group</li>
<li><strong>Homogeneity of variance:</strong> The groups have similar variances</li>
</ol>
<p>Checking these assumptions:</p>
<ul>
<li>Independence is ensured through proper study design</li>
<li>Normality can be assessed with histograms, Q-Q plots, or formal tests for each group</li>
<li>Homogeneity of variance can be checked with Levene’s test</li>
</ul>
<div class="margin-note">
<p>ANOVA is reasonably robust to moderate violations of normality, especially with balanced designs and larger sample sizes. It’s more sensitive to violations of homogeneity of variance, especially with unequal group sizes.</p>
</div>
<p>### 3.2.4 Post-hoc Tests and Planned Comparisons</p>
<p>If the overall ANOVA is significant, we typically want to know which specific groups differ from each other. There are two approaches to examining specific group differences:</p>
<ol type="1">
<li><p><strong>Post-hoc tests:</strong> Conducted after finding a significant ANOVA result, these tests compare all possible pairs of groups while controlling for multiple comparisons</p></li>
<li><p><strong>Planned comparisons:</strong> Specific comparisons determined before conducting the analysis, based on theoretical hypotheses</p></li>
</ol>
<p>Common post-hoc tests include:</p>
<ul>
<li><strong>Tukey’s HSD:</strong> Compares all possible pairs of means and is appropriate when you want to examine all pairwise comparisons</li>
<li><strong>Bonferroni:</strong> Controls the familywise error rate by adjusting the significance level for the number of comparisons</li>
<li><strong>Scheffé:</strong> The most conservative test, appropriate when examining all possible contrasts</li>
</ul>
<div class="example">
<p><strong>Clinical Example (continued):</strong> The researcher conducting the PTSD treatment study finds a significant one-way ANOVA result (F(2, 57) = 4.89, p = .011), indicating that the three therapies differ in effectiveness. They then conduct Tukey’s HSD post-hoc tests and find that PE and CPT do not differ significantly from each other, but both are significantly more effective than EMDR.</p>
</div>
<p>### 3.2.5 Effect Sizes for One-way ANOVA</p>
<p>Several effect size measures can be used with ANOVA:</p>
<p>::: definition <strong>Eta-squared (η²):</strong> The proportion of the total variance attributed to the effect. It ranges from 0 to 1.</p>
<p><strong>Omega-squared (ω²):</strong> A less biased alternative to eta-squared that accounts for sample size. :::</p>
<p>Interpretation guidelines for η²:</p>
<ul>
<li>η² ≈ 0.01: Small effect</li>
<li>η² ≈ 0.06: Medium effect</li>
<li>η² ≈ 0.14: Large effect</li>
</ul>
<div style="width:175%; margin-left:-75%; position:relative; overflow:visible;">
<pre class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 600

install.packages(c("shiny", "ggplot2", "dplyr", "tidyr", "emmeans"))
library(shiny)
library(ggplot2)
library(dplyr)
library(tidyr)
library(emmeans)

ui &lt;- fluidPage(
  titlePanel("One-way ANOVA Interactive Visualization"),
  
  sidebarLayout(
    sidebarPanel(
      h4("Group Parameters"),
      
      # Group 1 parameters
      numericInput("mean1", "Group 1 Mean:", value = 50, min = 0, max = 100),
      numericInput("sd1", "Group 1 SD:", value = 10, min = 1, max = 30),
      numericInput("n1", "Group 1 Sample Size:", value = 25, min = 5, max = 100),
      
      # Group 2 parameters
      numericInput("mean2", "Group 2 Mean:", value = 55, min = 0, max = 100),
      numericInput("sd2", "Group 2 SD:", value = 10, min = 1, max = 30),
      numericInput("n2", "Group 2 Sample Size:", value = 25, min = 5, max = 100),
      
      # Group 3 parameters
      numericInput("mean3", "Group 3 Mean:", value = 60, min = 0, max = 100),
      numericInput("sd3", "Group 3 SD:", value = 10, min = 1, max = 30),
      numericInput("n3", "Group 3 Sample Size:", value = 25, min = 5, max = 100),
      
      hr(),
      actionButton("simulate", "Generate New Data"),
      
      hr(),
      checkboxInput("show_indiv", "Show Individual Data Points", TRUE),
      selectInput("posthoc", "Post-hoc Test:",
                  choices = c("Tukey HSD" = "tukey", 
                              "Bonferroni" = "bonferroni",
                              "Scheffe" = "scheffe"),
                  selected = "tukey")
    ),
    
    mainPanel(
      tabsetPanel(
        tabPanel("Visualization", plotOutput("anovaPlot")),
        tabPanel("ANOVA Results", 
                 verbatimTextOutput("anova_results"),
                 verbatimTextOutput("effect_size")),
        tabPanel("Post-hoc Tests", 
                 verbatimTextOutput("posthoc_results"),
                 plotOutput("posthoc_plot")),
        tabPanel("Assumptions", 
                 plotOutput("assumption_plots"),
                 verbatimTextOutput("assumption_tests"))
      )
    )
  )
)

server &lt;- function(input, output, session) {
  
  # Generate data reactively based on inputs
  sim_data &lt;- eventReactive(c(input$simulate, input$mean1, input$mean2, input$mean3,
                              input$sd1, input$sd2, input$sd3,
                              input$n1, input$n2, input$n3), {
                                set.seed(sample(1:1000, 1))
                                
                                # Generate the data for each group
                                group1 &lt;- data.frame(
                                  value = rnorm(input$n1, input$mean1, input$sd1),
                                  group = "Group 1"
                                )
                                
                                group2 &lt;- data.frame(
                                  value = rnorm(input$n2, input$mean2, input$sd2),
                                  group = "Group 2"
                                )
                                
                                group3 &lt;- data.frame(
                                  value = rnorm(input$n3, input$mean3, input$sd3),
                                  group = "Group 3"
                                )
                                
                                combined &lt;- rbind(group1, group2, group3)
                                combined$group &lt;- factor(combined$group, levels = c("Group 1", "Group 2", "Group 3"))
                                
                                # Perform the ANOVA
                                anova_result &lt;- aov(value ~ group, data = combined)
                                anova_summary &lt;- summary(anova_result)
                                
                                # Effect size (eta-squared)
                                df_anova &lt;- anova_summary[[1]]
                                SST &lt;- sum(df_anova$`Sum Sq`)
                                eta_squared &lt;- df_anova$`Sum Sq`[1] / SST
                                
                                # Tukey's HSD post-hoc test
                                posthoc_tukey &lt;- TukeyHSD(anova_result)
                                
                                # Create emmeans object for other post-hoc comparisons
                                emmeans_model &lt;- emmeans(anova_result, specs = "group")
                                
                                # Normality test for residuals
                                shapiro_test &lt;- shapiro.test(residuals(anova_result))
                                
                                # Homogeneity of variance test
                                levene_test &lt;- car::leveneTest(value ~ group, data = combined)
                                
                                list(
                                  data = combined,
                                  anova = anova_result,
                                  anova_summary = anova_summary,
                                  eta_squared = eta_squared,
                                  posthoc_tukey = posthoc_tukey,
                                  emmeans_model = emmeans_model,
                                  shapiro_test = shapiro_test,
                                  levene_test = levene_test
                                )
                              })
  
  # ANOVA visualization
  output$anovaPlot &lt;- renderPlot({
    req(sim_data())
    data &lt;- sim_data()$data
    
    # Calculate summary statistics for annotation
    stats &lt;- data %&gt;%
      group_by(group) %&gt;%
      summarize(
        mean = mean(value),
        sd = sd(value),
        n = n(),
        se = sd / sqrt(n)
      )
    
    # Grand mean for reference line
    grand_mean &lt;- mean(data$value)
    
    # Create the plot
    p &lt;- ggplot(data, aes(x = group, y = value, fill = group)) +
      geom_boxplot(width = 0.5, alpha = 0.7) +
      stat_summary(fun = mean, geom = "point", shape = 18, size = 4, color = "black") +
      geom_hline(yintercept = grand_mean, linetype = "dashed", color = "red") +
      annotate("text", x = 3, y = grand_mean + 2, 
               label = paste("Grand Mean =", round(grand_mean, 1)), 
               color = "red", hjust = 1) +
      labs(title = "One-way ANOVA: Comparison of Group Means",
           subtitle = "Diamond points represent means, red line is grand mean",
           x = "Group", y = "Value") +
      theme_minimal() +
      theme(legend.position = "none",
            plot.title = element_text(face = "bold", size = 16),
            plot.subtitle = element_text(size = 12),
            axis.title = element_text(size = 14)) +
      scale_fill_brewer(palette = "Set1")
    
    if(input$show_indiv){
      p &lt;- p + geom_jitter(width = 0.2, alpha = 0.5, size = 2)
    }
    
    # Add mean ± SE labels
    p &lt;- p + geom_text(data = stats, 
                       aes(x = group, y = mean, label = paste0("M = ", round(mean, 1), 
                                                               "\nSD = ", round(sd, 1))),
                       vjust = -1.5, size = 3.5)
    
    # Add the ANOVA F and p-value as a caption
    f_value &lt;- sim_data()$anova_summary[[1]]$`F value`[1]
    p_value &lt;- sim_data()$anova_summary[[1]]$`Pr(&gt;F)`[1]
    sig_stars &lt;- if(p_value &lt; 0.001) "***" else if(p_value &lt; 0.01) "**" else if(p_value &lt; 0.05) "*" else "ns"
    
    p &lt;- p + labs(caption = paste0("F(", 
                                   sim_data()$anova_summary[[1]]$Df[1], ", ", 
                                   sim_data()$anova_summary[[1]]$Df[2], ") = ", 
                                   round(f_value, 2), ", p ", 
                                   ifelse(p_value &lt; 0.001, "&lt; 0.001", paste0("= ", round(p_value, 3))),
                                   " ", sig_stars))
    
    p
  })
  
  # ANOVA results
  output$anova_results &lt;- renderPrint({
    req(sim_data())
    cat("One-way ANOVA Results:\n\n")
    print(sim_data()$anova_summary)
  })
  
  # Effect size results
  output$effect_size &lt;- renderText({
    req(sim_data())
    eta_squared &lt;- sim_data()$eta_squared
    
    effect_size_interpretation &lt;- case_when(
      eta_squared &lt; 0.01 ~ "negligible",
      eta_squared &lt; 0.06 ~ "small",
      eta_squared &lt; 0.14 ~ "medium",
      TRUE ~ "large"
    )
    
    paste0("Effect Size:\n",
           "Eta-squared (η²) = ", round(eta_squared, 3), " (", effect_size_interpretation, " effect)\n\n",
           "This means that ", round(eta_squared * 100, 1), "% of the total variance in the dependent variable ",
           "is explained by group membership.")
  })
  
  # Post-hoc test results
  output$posthoc_results &lt;- renderPrint({
    req(sim_data())
    
    if(input$posthoc == "tukey") {
      cat("Tukey's HSD Post-hoc Test:\n\n")
      print(sim_data()$posthoc_tukey)
    } else if(input$posthoc == "bonferroni") {
      cat("Bonferroni-adjusted Pairwise Comparisons:\n\n")
      pairs(sim_data()$emmeans_model, adjust = "bonferroni")
    } else if(input$posthoc == "scheffe") {
      cat("Scheffe's Post-hoc Test:\n\n")
      pairs(sim_data()$emmeans_model, adjust = "scheffe")
    }
  })
  
  # Post-hoc test plot
  output$posthoc_plot &lt;- renderPlot({
    req(sim_data())
    
    # Get means and CIs from the emmeans object
    means_data &lt;- as.data.frame(sim_data()$emmeans_model)
    
    # Get pairwise comparisons
    if(input$posthoc == "tukey") {
      pairs_data &lt;- as.data.frame(pairs(sim_data()$emmeans_model, adjust = "tukey"))
    } else if(input$posthoc == "bonferroni") {
      pairs_data &lt;- as.data.frame(pairs(sim_data()$emmeans_model, adjust = "bonferroni"))
    } else if(input$posthoc == "scheffe") {
      pairs_data &lt;- as.data.frame(pairs(sim_data()$emmeans_model, adjust = "scheffe"))
    }
    
    # Mark significant comparisons
    pairs_data$significant &lt;- pairs_data$p.value &lt; 0.05
    
    # Plot means with confidence intervals
    p1 &lt;- ggplot(means_data, aes(x = group, y = emmean, color = group)) +
      geom_point(size = 3) +
      geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = 0.2) +
      labs(title = "Group Means with 95% Confidence Intervals",
           x = "Group", y = "Estimated Mean") +
      theme_minimal() +
      theme(legend.position = "none") +
      scale_color_brewer(palette = "Set1")
    
    # Plot pairwise comparisons
    p2 &lt;- ggplot(pairs_data, aes(x = contrast, y = estimate, fill = significant)) +
      geom_col() +
      geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = 0.2) +
      labs(title = paste0("Pairwise Comparisons (", 
                          ifelse(input$posthoc == "tukey", "Tukey's HSD", 
                                 ifelse(input$posthoc == "bonferroni", "Bonferroni", "Scheffe")), 
                          " Adjusted)"),
           x = "Contrast", y = "Mean Difference") +
      scale_fill_manual(values = c("TRUE" = "#28a745", "FALSE" = "#dc3545"),
                        labels = c("TRUE" = "Significant", "FALSE" = "Non-significant")) +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1),
            legend.title = element_blank()) +
      geom_hline(yintercept = 0, linetype = "dashed")
    
    # Combine the plots
    gridExtra::grid.arrange(p1, p2, nrow = 2, heights = c(1, 1.2))
  })
  
  # Assumption plots
  output$assumption_plots &lt;- renderPlot({
    req(sim_data())
    
    # Residuals for checking assumptions
    residuals &lt;- residuals(sim_data()$anova)
    fitted &lt;- fitted(sim_data()$anova)
    
    # Create a data frame with residuals and fitted values
    assumption_data &lt;- data.frame(
      residuals = residuals,
      fitted = fitted,
      group = sim_data()$data$group
    )
    
    # Create a QQ plot for normality
    p1 &lt;- ggplot(assumption_data, aes(sample = residuals)) +
      stat_qq() +
      stat_qq_line() +
      labs(title = "Q-Q Plot of Residuals",
           x = "Theoretical Quantiles", 
           y = "Sample Quantiles") +
      theme_minimal()
    
    # Create a residuals vs fitted plot for homogeneity
    p2 &lt;- ggplot(assumption_data, aes(x = fitted, y = residuals, color = group)) +
      geom_point() +
      geom_hline(yintercept = 0, linetype = "dashed") +
      labs(title = "Residuals vs. Fitted Values",
           x = "Fitted Values", 
           y = "Residuals") +
      theme_minimal() +
      scale_color_brewer(palette = "Set1")
    
    # Create a histogram of residuals
    p3 &lt;- ggplot(assumption_data, aes(x = residuals)) +
      geom_histogram(bins = 20, fill = "steelblue", color = "white") +
      labs(title = "Distribution of Residuals",
           x = "Residuals", 
           y = "Count") +
      theme_minimal()
    
    # Combine the plots
    gridExtra::grid.arrange(p1, p2, p3, nrow = 2)
  })
  
  # Assumption tests
  output$assumption_tests &lt;- renderText({
    req(sim_data())
    
    # Results from normality and homogeneity tests
    shapiro_p &lt;- sim_data()$shapiro_test$p.value
    levene_p &lt;- sim_data()$levene_test$`Pr(&gt;F)`[1]
    
    shapiro_result &lt;- ifelse(shapiro_p &lt; 0.05, 
                             "significantly non-normal (assumption violated)", 
                             "approximately normal (assumption met)")
    
    levene_result &lt;- ifelse(levene_p &lt; 0.05, 
                            "significantly different variances (assumption violated)", 
                            "approximately equal variances (assumption met)")
    
    paste0("Tests of ANOVA Assumptions:\n\n",
           "1. Normality of Residuals (Shapiro-Wilk Test):\n",
           "   W = ", round(sim_data()$shapiro_test$statistic, 3), 
           ", p = ", round(shapiro_p, 3), "\n",
           "   Interpretation: Residuals are ", shapiro_result, "\n\n",
           "2. Homogeneity of Variances (Levene's Test):\n",
           "   F(", sim_data()$levene_test$Df[1], ", ", sim_data()$levene_test$Df[2], ") = ", 
           round(sim_data()$levene_test$`F value`[1], 3), 
           ", p = ", round(levene_p, 3), "\n",
           "   Interpretation: Groups have ", levene_result, "\n\n",
           "Note: If normality is violated but sample sizes are large (n &gt; 30 per group), ANOVA is generally robust.\n",
           "If homogeneity of variance is violated, consider using Welch's ANOVA instead.")
  })
}

shinyApp(ui, server)</code></pre>
</div>
<p>Use this interactive application to explore how different group means, variances, and sample sizes affect the results of a one-way ANOVA.</p>
</section>
<section id="two-way-anova" class="level2">
<h2 class="anchored" data-anchor-id="two-way-anova">3.3 Two-way ANOVA</h2>
<p>Two-way ANOVA extends the one-way model by examining the effects of two independent variables (factors) simultaneously, including their potential interaction.</p>
<div class="definition">
<p><strong>Two-way ANOVA:</strong> A statistical test that examines the influence of two different independent variables on one continuous dependent variable, including their potential interaction.</p>
</div>
<p>### 3.3.1 When to Use Two-way ANOVA</p>
<p>Use two-way ANOVA when:</p>
<ul>
<li>You have two independent variables (factors)</li>
<li>You have one continuous dependent variable</li>
<li>You want to examine main effects and potential interactions</li>
</ul>
<div class="example">
<p><strong>Clinical Example:</strong> A researcher investigates how treatment type (CBT vs.&nbsp;medication) and comorbidity status (present vs.&nbsp;absent) affect depression outcomes. They have four groups: CBT with comorbidity, CBT without comorbidity, medication with comorbidity, and medication without comorbidity. Two-way ANOVA can examine the main effects of treatment and comorbidity, as well as their interaction.</p>
</div>
<p>### 3.3.2 Main Effects and Interactions</p>
<p>Two-way ANOVA allows us to examine three types of effects:</p>
<ol type="1">
<li><strong>Main effect of Factor A:</strong> The overall effect of Factor A, averaging across all levels of Factor B</li>
<li><strong>Main effect of Factor B:</strong> The overall effect of Factor B, averaging across all levels of Factor A</li>
<li><strong>Interaction effect (A × B):</strong> The effect of Factor A depends on the level of Factor B (or vice versa)</li>
</ol>
<div class="margin-note">
<p>An interaction occurs when the effect of one factor depends on the level of another factor. Graphically, non-parallel lines in an interaction plot suggest an interaction.</p>
</div>
<p>Understanding and interpreting interactions is crucial in two-way ANOVA:</p>
<ul>
<li>If the interaction is significant, the main effects should be interpreted with caution</li>
<li>A significant interaction often requires examining simple effects (the effect of one factor at each level of the other factor)</li>
</ul>
<div class="example">
<p><strong>Clinical Example (continued):</strong> The researcher finds a significant interaction between treatment type and comorbidity status. Further analysis reveals that CBT is more effective than medication for clients without comorbidities, but both treatments are equally effective for clients with comorbidities. This interaction would not have been detected with separate one-way ANOVAs.</p>
</div>
<p>### 3.3.3 Effect Sizes for Two-way ANOVA</p>
<p>In two-way ANOVA, we typically report partial eta-squared (partial η²) as the effect size for each effect (both main effects and the interaction).</p>
<div class="definition">
<p><strong>Partial eta-squared (partial η²):</strong> The proportion of variance in the dependent variable explained by a specific effect, excluding variance explained by other effects.</p>
</div>
<p>Interpretation guidelines for partial η²:</p>
<ul>
<li>Partial η² ≈ 0.01: Small effect</li>
<li>Partial η² ≈ 0.06: Medium effect</li>
<li>Partial η² ≈ 0.14: Large effect</li>
</ul>
<div style="width:175%; margin-left:-75%; position:relative; overflow:visible;">
<pre class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 600

install.packages(c("shiny", "ggplot2", "dplyr", "tidyr", "emmeans"))
library(shiny)
library(ggplot2)
library(dplyr)
library(tidyr)

ui &lt;- fluidPage(
  titlePanel("Two-way ANOVA and Interaction Visualization"),
  
  sidebarLayout(
    sidebarPanel(
      width = 3,
      h4("Factor A: Treatment"),
      
      # Factor A settings
      numericInput("mean_a1", "A1 (CBT) Mean:", value = 10, min = 0, max = 30),
      numericInput("mean_a2", "A2 (Medication) Mean:", value = 15, min = 0, max = 30),
      
      h4("Factor B: Comorbidity"),
      
      # Factor B settings
      numericInput("mean_b1", "B1 (No Comorbidity) Mean:", value = 8, min = 0, max = 30),
      numericInput("mean_b2", "B2 (Comorbidity) Mean:", value = 17, min = 0, max = 30),
      
      h4("Interaction"),
      
      # Interaction strength
      sliderInput("interaction", "Interaction Strength:", 
                  min = -10, max = 10, value = -5, step = 0.5),
      
      h4("Data Parameters"),
      
      # Standard deviation
      sliderInput("sd", "Standard Deviation:", 
                  min = 1, max = 10, value = 3, step = 0.5),
      
      # Sample size
      sliderInput("n_per_cell", "Sample Size per Cell:", 
                  min = 5, max = 50, value = 20, step = 5),
      
      hr(),
      actionButton("simulate", "Generate New Data", class = "btn-primary"),
      
      h4("Display Options"),
      checkboxInput("show_means", "Show Cell Means", TRUE)
    ),
    
    mainPanel(
      tabsetPanel(
        tabPanel("Interaction Plot", 
                 plotOutput("interactionPlot"),
                 div(class = "well",
                     h4("Understanding Interactions"),
                     p("This plot shows the relationship between the two factors. Non-parallel lines indicate an interaction effect."),
                     p("When an interaction is present, the effect of one factor depends on the level of the other factor."),
                     p("Current interaction value: ", textOutput("interaction_value", inline = TRUE))
                 )),
        tabPanel("Cell Means", 
                 plotOutput("cellMeansPlot"),
                 div(class = "well",
                     h4("Cell Means Visualization"),
                     p("This plot shows the mean values for each combination of factors."),
                     p("The height of each bar represents the mean score for that specific combination of Factor A (Treatment) and Factor B (Comorbidity).")
                 )),
        tabPanel("ANOVA Results", 
                 verbatimTextOutput("anova_results"),
                 verbatimTextOutput("effect_sizes"),
                 div(class = "well",
                     h4("Interpreting Two-way ANOVA Results"),
                     p("The ANOVA table shows the significance of:"),
                     tags$ul(
                       tags$li(strong("Main effect of Factor A (Treatment):"), " Is there an overall effect of treatment type, averaging across comorbidity status?"),
                       tags$li(strong("Main effect of Factor B (Comorbidity):"), " Is there an overall effect of comorbidity status, averaging across treatment types?"),
                       tags$li(strong("A × B Interaction:"), " Does the effect of treatment depend on comorbidity status (or vice versa)?")
                     ),
                     p("When interaction is significant, interpret main effects with caution.")
                 ))
      )
    )
  )
)

server &lt;- function(input, output, session) {
  
  # Output the current interaction value
  output$interaction_value &lt;- renderText({
    input$interaction
  })
  
  # Generate data based on inputs
  sim_data &lt;- eventReactive(c(input$simulate, input$mean_a1, input$mean_a2,
                              input$mean_b1, input$mean_b2, input$interaction,
                              input$sd, input$n_per_cell), {
                                set.seed(sample(1:1000, 1))
                                
                                # Calculate cell means based on main effects and interaction
                                # To make this interpretable, we'll calculate as:
                                # Cell mean = grand mean + effect_A + effect_B + (interaction*adjustment)
                                
                                # Grand mean
                                grand_mean &lt;- (input$mean_a1 + input$mean_a2 + input$mean_b1 + input$mean_b2) / 4
                                
                                # Main effects
                                effect_a1 &lt;- input$mean_a1 - grand_mean
                                effect_a2 &lt;- input$mean_a2 - grand_mean
                                effect_b1 &lt;- input$mean_b1 - grand_mean
                                effect_b2 &lt;- input$mean_b2 - grand_mean
                                
                                # Cell means without interaction
                                mean_a1b1 &lt;- grand_mean + effect_a1 + effect_b1
                                mean_a1b2 &lt;- grand_mean + effect_a1 + effect_b2
                                mean_a2b1 &lt;- grand_mean + effect_a2 + effect_b1
                                mean_a2b2 &lt;- grand_mean + effect_a2 + effect_b2
                                
                                # Add interaction effect 
                                # We'll adjust so that +interaction makes A1B1 and A2B2 higher, 
                                # while A1B2 and A2B1 lower (classic crossover interaction)
                                mean_a1b1 &lt;- mean_a1b1 + input$interaction/2
                                mean_a2b2 &lt;- mean_a2b2 + input$interaction/2
                                mean_a1b2 &lt;- mean_a1b2 - input$interaction/2
                                mean_a2b1 &lt;- mean_a2b1 - input$interaction/2
                                
                                # Generate data
                                n &lt;- input$n_per_cell
                                
                                # Prepare container for all data
                                all_data &lt;- data.frame()
                                
                                # A1B1 group
                                a1b1_data &lt;- data.frame(
                                  treatment = rep("CBT", n),
                                  comorbidity = rep("No Comorbidity", n),
                                  score = rnorm(n, mean = mean_a1b1, sd = input$sd)
                                )
                                all_data &lt;- rbind(all_data, a1b1_data)
                                
                                # A1B2 group
                                a1b2_data &lt;- data.frame(
                                  treatment = rep("CBT", n),
                                  comorbidity = rep("Comorbidity", n),
                                  score = rnorm(n, mean = mean_a1b2, sd = input$sd)
                                )
                                all_data &lt;- rbind(all_data, a1b2_data)
                                
                                # A2B1 group
                                a2b1_data &lt;- data.frame(
                                  treatment = rep("Medication", n),
                                  comorbidity = rep("No Comorbidity", n),
                                  score = rnorm(n, mean = mean_a2b1, sd = input$sd)
                                )
                                all_data &lt;- rbind(all_data, a2b1_data)
                                
                                # A2B2 group
                                a2b2_data &lt;- data.frame(
                                  treatment = rep("Medication", n),
                                  comorbidity = rep("Comorbidity", n),
                                  score = rnorm(n, mean = mean_a2b2, sd = input$sd)
                                )
                                all_data &lt;- rbind(all_data, a2b2_data)
                                
                                # Convert factors
                                all_data$treatment &lt;- factor(all_data$treatment, 
                                                             levels = c("CBT", "Medication"))
                                all_data$comorbidity &lt;- factor(all_data$comorbidity, 
                                                               levels = c("No Comorbidity", "Comorbidity"))
                                
                                # Run ANOVA
                                anova_result &lt;- aov(score ~ treatment * comorbidity, data = all_data)
                                anova_summary &lt;- summary(anova_result)
                                
                                # Calculate effect sizes (partial eta-squared)
                                anova_table &lt;- anova_summary[[1]]
                                
                                # Calculate partial eta-squared for each effect
                                partial_eta_squared &lt;- anova_table$`Sum Sq` / (anova_table$`Sum Sq` + anova_table$`Sum Sq`[length(anova_table$`Sum Sq`)])
                                
                                # Create mean summary 
                                mean_summary &lt;- all_data %&gt;%
                                  group_by(treatment, comorbidity) %&gt;%
                                  summarize(
                                    mean = mean(score),
                                    sd = sd(score),
                                    n = n(),
                                    se = sd / sqrt(n)
                                  )
                                
                                # Store all results
                                list(
                                  data = all_data,
                                  anova = anova_result,
                                  anova_summary = anova_summary,
                                  cell_means = data.frame(
                                    a1b1 = mean_a1b1,
                                    a1b2 = mean_a1b2,
                                    a2b1 = mean_a2b1,
                                    a2b2 = mean_a2b2
                                  ),
                                  mean_summary = mean_summary,
                                  partial_eta_squared = partial_eta_squared
                                )
                              })
  
  # Interaction plot
  output$interactionPlot &lt;- renderPlot({
    req(sim_data())
    
    # Calculate means for each combination of factors
    mean_data &lt;- sim_data()$mean_summary
    
    # Create the interaction plot
    ggplot(mean_data, aes(x = comorbidity, y = mean, group = treatment, color = treatment)) +
      geom_line(size = 1.5) +
      geom_point(size = 4) +
      geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = 0.2, size = 1) +
      labs(title = "Interaction Plot: Treatment × Comorbidity",
           subtitle = "Error bars represent standard errors",
           x = "Comorbidity Status",
           y = "Depression Score (lower is better)") +
      theme_minimal() +
      theme(legend.position = "top",
            plot.title = element_text(face = "bold", size = 16),
            plot.subtitle = element_text(size = 12),
            axis.title = element_text(size = 14),
            legend.title = element_blank()) +
      scale_color_brewer(palette = "Set1")
  })
  
  # Cell means plot
  output$cellMeansPlot &lt;- renderPlot({
    req(sim_data())
    
    # Get the mean data
    mean_data &lt;- sim_data()$mean_summary
    
    # Convert to factorial design format
    mean_data$group &lt;- paste(mean_data$treatment, mean_data$comorbidity, sep = "\n")
    
    # Create the bar plot
    p &lt;- ggplot(mean_data, aes(x = group, y = mean, fill = treatment)) +
      geom_bar(stat = "identity", position = "dodge", width = 0.7) +
      geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                    width = 0.2, position = position_dodge(0.7)) +
      labs(title = "Cell Means: Treatment × Comorbidity",
           subtitle = "Error bars represent standard errors",
           x = "",
           y = "Depression Score (lower is better)") +
      theme_minimal() +
      theme(legend.position = "top",
            plot.title = element_text(face = "bold", size = 16),
            plot.subtitle = element_text(size = 12),
            axis.title = element_text(size = 14),
            legend.title = element_blank()) +
      scale_fill_brewer(palette = "Set1")
    
    # Add mean values on bars if requested
    if(input$show_means) {
      p &lt;- p + geom_text(aes(label = round(mean, 1)), 
                         position = position_dodge(0.7),
                         vjust = -0.5)
    }
    
    p
  })
  
  # ANOVA results
  output$anova_results &lt;- renderPrint({
    req(sim_data())
    cat("Two-way ANOVA Results:\n\n")
    print(sim_data()$anova_summary)
  })
  
  # Effect size results
  output$effect_sizes &lt;- renderText({
    req(sim_data())
    
    p_eta_sq &lt;- sim_data()$partial_eta_squared
    
    # Get p-values
    anova_table &lt;- sim_data()$anova_summary[[1]]
    p_values &lt;- anova_table$`Pr(&gt;F)`
    
    # Interpret effect sizes
    interpret_eta &lt;- function(eta) {
      if (eta &lt; 0.01) return("negligible")
      if (eta &lt; 0.06) return("small")
      if (eta &lt; 0.14) return("medium")
      return("large")
    }
    
    # Format output
    paste0("Effect Sizes (Partial η²):\n\n",
           "1. Treatment: ", round(p_eta_sq[1], 3), " (", interpret_eta(p_eta_sq[1]), " effect",
           ifelse(p_values[1] &lt; 0.05, ", significant)", ", not significant)"), "\n\n",
           "2. Comorbidity: ", round(p_eta_sq[2], 3), " (", interpret_eta(p_eta_sq[2]), " effect",
           ifelse(p_values[2] &lt; 0.05, ", significant)", ", not significant)"), "\n\n", 
           "3. Treatment × Comorbidity Interaction: ", 
           round(p_eta_sq[3], 3), " (", interpret_eta(p_eta_sq[3]), " effect",
           ifelse(p_values[3] &lt; 0.05, ", significant)", ", not significant)"), "\n\n",
           "Interpretation:\n",
           ifelse(p_values[3] &lt; 0.05, 
                  "The significant interaction indicates that the effect of treatment depends on comorbidity status. Main effects should be interpreted with caution.",
                  "No significant interaction was found. Main effects can be interpreted independently."))
  })
}

shinyApp(ui, server)</code></pre>
</div>
<p>Use this interactive application to explore how different patterns of means affect main effects and interactions in a two-way ANOVA.</p>
</section>
<section id="between-subjects-within-subjects-and-mixed-designs" class="level2">
<h2 class="anchored" data-anchor-id="between-subjects-within-subjects-and-mixed-designs">3.4 Between-subjects, Within-subjects, and Mixed Designs</h2>
<p>ANOVA designs can be classified based on how participants are assigned to conditions:</p>
<p>::: definition <strong>Between-subjects design:</strong> Different participants are in different groups or conditions.</p>
<p><strong>Within-subjects design:</strong> The same participants experience all conditions or are measured multiple times.</p>
<p><strong>Mixed design:</strong> Combines both between-subjects and within-subjects factors. :::</p>
<p>### 3.4.1 Between-subjects ANOVA</p>
<p>In a between-subjects ANOVA, different participants are in different groups:</p>
<ul>
<li>Each participant provides one data point</li>
<li>Individual differences can increase error variance</li>
<li>Typically requires larger sample sizes for adequate power</li>
<li>Not affected by carryover effects or practice effects</li>
</ul>
<p>Both one-way and two-way ANOVAs can be between-subjects designs, as in the examples we’ve discussed so far.</p>
<section id="within-subjects-anova-repeated-measures" class="level3">
<h3 class="anchored" data-anchor-id="within-subjects-anova-repeated-measures">3.4.2 Within-subjects ANOVA (Repeated Measures)</h3>
<p>In a within-subjects ANOVA, the same participants experience all conditions or are measured multiple times:</p>
<ul>
<li>Each participant provides multiple data points</li>
<li>Reduces the impact of individual differences, increasing power</li>
<li>Requires fewer participants than between-subjects designs</li>
<li>May be affected by carryover effects or practice effects</li>
</ul>
<div class="definition">
<p><strong>Repeated Measures ANOVA:</strong> A type of ANOVA used when the same participants are measured multiple times or under multiple conditions.</p>
</div>
<div class="example">
<p><strong>Clinical Example:</strong> A researcher measures anxiety symptoms in 30 clients at three time points: pre-treatment, mid-treatment, and post-treatment. A within-subjects (repeated measures) ANOVA is appropriate to examine changes over time.</p>
</div>
<section id="additional-assumptions-for-repeated-measures-anova" class="level4">
<h4 class="anchored" data-anchor-id="additional-assumptions-for-repeated-measures-anova">Additional Assumptions for Repeated Measures ANOVA</h4>
<p>Within-subjects designs have an additional assumption:</p>
<p><strong>Sphericity:</strong> The variances of the differences between all possible pairs of groups are equal.</p>
<div class="margin-note">
<p>Sphericity can be assessed using Mauchly’s test. If sphericity is violated, corrections like Greenhouse-Geisser or Huynh-Feldt can be applied.</p>
</div>
<p>### 3.4.3 Mixed ANOVA</p>
<p>Mixed designs combine both between-subjects and within-subjects factors:</p>
<ul>
<li>At least one between-subjects factor and one within-subjects factor</li>
<li>Allow examination of interactions between between-subjects and within-subjects factors</li>
<li>Common in longitudinal clinical studies</li>
</ul>
<div class="example">
<p><strong>Clinical Example:</strong> A researcher compares two therapies (CBT vs.&nbsp;psychodynamic) for depression, measuring symptoms at three time points (pre, mid, post). Therapy type is a between-subjects factor (different participants in each therapy), while time is a within-subjects factor (each participant measured at all time points). A mixed ANOVA can examine both the main effects and their interaction.</p>
</div>
<p>:::{style=“width:175%; margin-left:-75%; position:relative; overflow:visible;”}</p>
<pre class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 600

install.packages(c("shiny", "ggplot2", "dplyr", "tidyr"))
library(shiny)
library(ggplot2)
library(dplyr)
library(tidyr)

ui &lt;- fluidPage(
  titlePanel("Repeated Measures ANOVA Visualization"),
  
  sidebarLayout(
    sidebarPanel(
      width = 3,
      h4("Time Point Means"),
      
      # Time point means
      numericInput("mean_t1", "Pre-treatment Mean:", value = 25, min = 0, max = 50),
      numericInput("mean_t2", "Mid-treatment Mean:", value = 18, min = 0, max = 50),
      numericInput("mean_t3", "Post-treatment Mean:", value = 12, min = 0, max = 50),
      
      h4("Variance Parameters"),
      
      # Individual difference variance
      sliderInput("subject_var", "Between-Subject Variance:", 
                  min = 1, max = 30, value = 15, step = 1),
      
      # Within-subject variance
      sliderInput("error_var", "Within-Subject Variance:", 
                  min = 1, max = 20, value = 5, step = 1),
      
      # Sample size
      sliderInput("n_subjects", "Number of Subjects:", 
                  min = 5, max = 50, value = 20, step = 5),
      
      hr(),
      actionButton("simulate", "Generate New Data", class = "btn-primary"),
      
      h4("Display Options"),
      checkboxInput("show_individual", "Show Individual Trajectories", TRUE)
    ),
    
    mainPanel(
      tabsetPanel(
        tabPanel("Visualization", 
                 plotOutput("rmPlot"),
                 div(class = "well",
                     h4("Understanding Repeated Measures Design"),
                     p("This plot shows how scores change across three time points. Each line represents one participant."),
                     p("In a repeated measures design, the same participants are measured multiple times, allowing us to track individual change."),
                     p("This increases statistical power by controlling for individual differences.")
                 )),
        tabPanel("ANOVA Results", 
                 verbatimTextOutput("anova_results"),
                 verbatimTextOutput("effect_size"),
                 div(class = "well",
                     h4("Interpretation of Results"),
                     p("The ANOVA table shows whether there are significant differences across time points."),
                     p("Repeated measures designs typically have greater power than between-subjects designs with the same number of participants."),
                     p("Effect sizes for repeated measures are often larger because individual differences are controlled.")
                 )),
        tabPanel("Power Comparison", 
                 plotOutput("powerPlot"),
                 div(class = "well",
                     h4("Between vs. Within Design Power Comparison"),
                     p("This plot compares the statistical power of between-subjects and within-subjects designs."),
                     p("For the same effect size, within-subjects designs typically require fewer participants to achieve the same power."),
                     p("This advantage increases with stronger correlations between repeated measurements.")
                 ))
      )
    )
  )
)

server &lt;- function(input, output, session) {
  
  # Generate data based on inputs
  sim_data &lt;- eventReactive(c(input$simulate, input$mean_t1, input$mean_t2,
                              input$mean_t3, input$subject_var, input$error_var,
                              input$n_subjects), {
                                set.seed(sample(1:1000, 1))
                                
                                # Number of subjects
                                n_subjects &lt;- input$n_subjects
                                
                                # Create subject-level random effects (individual differences)
                                subject_effects &lt;- rnorm(n_subjects, mean = 0, sd = sqrt(input$subject_var))
                                
                                # Create data frame
                                data_long &lt;- data.frame()
                                
                                # Generate data for each time point
                                for (subj in 1:n_subjects) {
                                  # Add subject's baseline (individual difference)
                                  base_score &lt;- subject_effects[subj]
                                  
                                  # Generate three time points with error
                                  t1 &lt;- input$mean_t1 + base_score + rnorm(1, 0, sqrt(input$error_var))
                                  t2 &lt;- input$mean_t2 + base_score + rnorm(1, 0, sqrt(input$error_var))
                                  t3 &lt;- input$mean_t3 + base_score + rnorm(1, 0, sqrt(input$error_var))
                                  
                                  # Add to data frame
                                  subj_data &lt;- data.frame(
                                    subject = subj,
                                    time = c("Pre", "Mid", "Post"),
                                    score = c(t1, t2, t3)
                                  )
                                  
                                  data_long &lt;- rbind(data_long, subj_data)
                                }
                                
                                # Convert to factors
                                data_long$subject &lt;- factor(data_long$subject)
                                data_long$time &lt;- factor(data_long$time, levels = c("Pre", "Mid", "Post"))
                                
                                # Convert to wide format for analysis
                                data_wide &lt;- data_long %&gt;%
                                  pivot_wider(
                                    id_cols = subject,
                                    names_from = time,
                                    values_from = score
                                  )
                                
                                # Calculate correlations between time points
                                cors &lt;- cor(data_wide[, c("Pre", "Mid", "Post")])
                                
                                # Perform repeated measures ANOVA
                                aov_result &lt;- aov(score ~ time + Error(subject/time), data = data_long)
                                aov_summary &lt;- summary(aov_result)
                                
                                # Calculate effect size (partial eta-squared)
                                # First, compute SS_time
                                SS_time &lt;- var(c(input$mean_t1, input$mean_t2, input$mean_t3)) * 3 * n_subjects
                                
                                # Compute SS_residual (approximation)
                                SS_residual &lt;- input$error_var * 3 * n_subjects
                                
                                # Calculate partial eta-squared
                                partial_eta_sq &lt;- SS_time / (SS_time + SS_residual)
                                
                                # Calculate means
                                time_means &lt;- data_long %&gt;%
                                  group_by(time) %&gt;%
                                  summarize(
                                    mean = mean(score),
                                    sd = sd(score),
                                    n = n(),
                                    se = sd / sqrt(n)
                                  )
                                
                                # Return results
                                list(
                                  data_long = data_long,
                                  data_wide = data_wide,
                                  aov_result = aov_result,
                                  aov_summary = aov_summary,
                                  cors = cors,
                                  partial_eta_sq = partial_eta_sq,
                                  time_means = time_means
                                )
                              })
  
  # Generate repeated measures plot
  output$rmPlot &lt;- renderPlot({
    req(sim_data())
    
    data &lt;- sim_data()$data_long
    means &lt;- sim_data()$time_means
    
    # Main plot
    p &lt;- ggplot() +
      labs(title = "Anxiety Scores Over Time",
           subtitle = "Within-subjects (Repeated Measures) Design",
           x = "Time Point", 
           y = "Anxiety Score (higher = more severe)") +
      theme_minimal() +
      theme(plot.title = element_text(face = "bold", size = 16),
            plot.subtitle = element_text(size = 12),
            axis.title = element_text(size = 14))
    
    # Add individual trajectories if requested
    if (input$show_individual) {
      p &lt;- p + geom_line(data = data, 
                         aes(x = time, y = score, group = subject, color = subject),
                         alpha = 0.3) +
        theme(legend.position = "none")
    }
    
    # Add mean line
    p &lt;- p + 
      geom_line(data = means, 
                aes(x = time, y = mean, group = 1), 
                size = 2, color = "red") +
      geom_point(data = means, 
                 aes(x = time, y = mean), 
                 size = 4, color = "red") +
      geom_errorbar(data = means, 
                    aes(x = time, y = mean, ymin = mean - se, ymax = mean + se), 
                    width = 0.2, color = "red") +
      geom_text(data = means, 
                aes(x = time, y = mean, 
                    label = paste0("M = ", round(mean, 1))), 
                vjust = -1.5, color = "red")
    
    p
  })
  
  # ANOVA results
  output$anova_results &lt;- renderPrint({
    req(sim_data())
    
    # Print ANOVA results
    cat("Repeated Measures ANOVA Results:\n\n")
    print(sim_data()$aov_summary)
    
    # Print correlations between time points
    cat("\nCorrelations Between Time Points:\n")
    print(round(sim_data()$cors, 3))
  })
  
  # Effect size output
  output$effect_size &lt;- renderText({
    req(sim_data())
    
    eta_sq &lt;- sim_data()$partial_eta_sq
    
    # Interpret effect size
    effect_size_interpretation &lt;- case_when(
      eta_sq &lt; 0.01 ~ "negligible",
      eta_sq &lt; 0.06 ~ "small",
      eta_sq &lt; 0.14 ~ "medium",
      TRUE ~ "large"
    )
    
    paste0("Effect Size:\n\n",
           "Partial η² = ", round(eta_sq, 3), " (", effect_size_interpretation, " effect)\n\n",
           "This means that approximately ", round(eta_sq * 100, 1), "% of the variance in scores ",
           "that is not explained by individual differences is accounted for by time point.\n\n",
           "Between-subject variance: ", input$subject_var, "\n",
           "Within-subject variance: ", input$error_var, "\n\n",
           "By controlling for individual differences (between-subject variance), ",
           "the repeated measures design increases power compared to a between-subjects design.")
  })
  
  # Power comparison plot
  output$powerPlot &lt;- renderPlot({
    req(sim_data())
    
    # Get correlation between measurements
    cors &lt;- sim_data()$cors
    avg_cor &lt;- mean(c(cors[1,2], cors[1,3], cors[2,3]))
    
    # Calculate effect sizes for between and within designs
    # Given the same mean difference
    mean_diff &lt;- (input$mean_t1 - input$mean_t3)
    
    # Between-subjects design effect size (Cohen's d)
    pooled_sd_between &lt;- sqrt(input$subject_var + input$error_var)
    d_between &lt;- abs(mean_diff) / pooled_sd_between
    
    # Within-subjects design effect size (dz)
    sd_diff &lt;- sqrt(2 * input$error_var * (1 - avg_cor))
    d_within &lt;- abs(mean_diff) / sd_diff
    
    # Function to calculate power
    calculate_power &lt;- function(d, n, design) {
      if (design == "between") {
        # Between-subjects (independent t-test)
        df &lt;- 2*n - 2
        ncp &lt;- d * sqrt(n/2)
      } else {
        # Within-subjects (paired t-test)
        df &lt;- n - 1
        ncp &lt;- d * sqrt(n)
      }
      
      # Calculate power
      crit &lt;- qt(0.975, df)
      power &lt;- 1 - pt(crit, df, ncp)
      return(power)
    }
    
    # Calculate power across a range of sample sizes
    n_range &lt;- seq(5, 100, by = 5)
    
    power_data &lt;- data.frame(
      n = rep(n_range, 2),
      design = c(rep("Between-Subjects", length(n_range)),
                 rep("Within-Subjects", length(n_range))),
      power = c(
        sapply(n_range, function(n) calculate_power(d_between, n, "between")),
        sapply(n_range, function(n) calculate_power(d_within, n, "within"))
      )
    )
    
    # Find where each design reaches 80% power
    n80_between &lt;- min(n_range[power_data$design == "Between-Subjects" &amp; 
                                 power_data$power &gt;= 0.8], 
                       100, na.rm = TRUE)
    
    n80_within &lt;- min(n_range[power_data$design == "Within-Subjects" &amp; 
                                power_data$power &gt;= 0.8], 
                      100, na.rm = TRUE)
    
    # Create power curve plot
    ggplot(power_data, aes(x = n, y = power, color = design)) +
      geom_line(size = 1.5) +
      geom_hline(yintercept = 0.8, linetype = "dashed", color = "darkgray") +
      geom_vline(xintercept = n80_between, linetype = "dotted", color = "#E41A1C") +
      geom_vline(xintercept = n80_within, linetype = "dotted", color = "#377EB8") +
      annotate("text", x = n80_between + 5, y = 0.4, 
               label = paste0("n = ", n80_between), color = "#E41A1C") +
      annotate("text", x = n80_within + 5, y = 0.3, 
               label = paste0("n = ", n80_within), color = "#377EB8") +
      annotate("text", x = 75, y = 0.85, 
               label = "80% Power", color = "darkgray") +
      labs(title = "Power Comparison: Between vs. Within-Subjects Design",
           subtitle = paste0("Average correlation between measurements: r = ", 
                             round(avg_cor, 2)),
           x = "Sample Size", 
           y = "Statistical Power",
           color = "Design") +
      scale_color_brewer(palette = "Set1") +
      theme_minimal() +
      theme(legend.position = "top",
            plot.title = element_text(face = "bold", size = 16),
            plot.subtitle = element_text(size = 12)) +
      annotate("text", x = 75, y = 0.15, 
               label = paste0("Within-subjects design requires approximately ", 
                              round(n80_between/n80_within, 1), 
                              "× fewer participants\nfor the same power"),
               hjust = 0.5)
  })
}

shinyApp(ui, server)</code></pre>
<p>:::</p>
<p>Use this interactive application to explore within-subjects designs and how they compare to between-subjects designs in terms of statistical power.</p>
</section>
</section>
</section>
<section id="interpretation-and-reporting-1" class="level2">
<h2 class="anchored" data-anchor-id="interpretation-and-reporting-1">3.5 Interpretation and Reporting</h2>
<p>When interpreting ANOVA results, consider:</p>
<ol type="1">
<li><strong>Overall F-test:</strong> Is there a significant overall effect?</li>
<li><strong>Main effects and interactions:</strong> Which specific effects are significant?</li>
<li><strong>Post-hoc tests or planned comparisons:</strong> Which specific groups differ?</li>
<li><strong>Effect sizes:</strong> How large are the effects?</li>
</ol>
<p>::: example <strong>Reporting Example (Two-way ANOVA):</strong> “A two-way ANOVA revealed a significant main effect of treatment type, F(1, 76) = 8.43, p = .005, partial η² = .10, with CBT showing lower depression scores than medication. There was also a significant main effect of comorbidity status, F(1, 76) = 12.65, p &lt; .001, partial η² = .14, with comorbid clients showing higher depression scores. These main effects were qualified by a significant interaction, F(1, 76) = 7.89, p = .006, partial η² = .09. Simple effects analyses indicated that CBT was more effective than medication for clients without comorbidities (p = .001), but both treatments were equally effective for clients with comorbidities (p = .78).” :::</p>
<p>## 3.6 Summary</p>
<p>ANOVA extends the t-test to more complex designs involving multiple groups or factors. Key points to remember:</p>
<ul>
<li>One-way ANOVA compares means across three or more groups defined by a single factor</li>
<li>Two-way ANOVA examines the effects of two factors, including their potential interaction</li>
<li>ANOVA designs can be between-subjects, within-subjects, or mixed</li>
<li>Significant ANOVA results should be followed by appropriate post-hoc tests or planned comparisons</li>
<li>Report and interpret effect sizes in addition to p-values</li>
</ul>
<p>In the next chapter, we’ll explore regression analysis, which examines relationships between continuous variables rather than differences between groups.</p>
<pre class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 700

library(shiny)
library(shinyjs)

ui &lt;- fluidPage(
  useShinyjs(),
  tags$head(
    tags$style(HTML("
      .quiz-container {
        max-width: 800px;
        margin: 0 auto;
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 20px;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
      }
      .question {
        margin-bottom: 30px;
        padding-bottom: 20px;
        border-bottom: 1px solid #dee2e6;
      }
      .question-title {
        font-weight: bold;
        margin-bottom: 15px;
        color: #212529;
      }
      .feedback {
        margin-top: 15px;
        padding: 15px;
        border-radius: 5px;
      }
      .correct {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
      }
      .incorrect {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
      }
      .panel-heading {
        background-color: #6c757d;
        color: white;
        padding: 10px 15px;
        border-radius: 5px 5px 0 0;
      }
      .panel-body {
        background-color: white;
        padding: 15px;
        border: 1px solid #dee2e6;
        border-top: none;
        border-radius: 0 0 5px 5px;
      }
      .result-container {
        margin-top: 20px;
        text-align: center;
      }
      .btn-submit-answer {
        margin-top: 10px;
      }
      .explanation {
        font-style: italic;
        margin-top: 10px;
      }
    "))
  ),
  
  div(class = "container-fluid",
      div(class = "row",
          div(class = "col-md-12",
              div(class = "quiz-container",
                  
                  # Quiz header
                  div(class = "panel-heading",
                      h2("Chapter 3 Quiz: Comparing Multiple Groups", style = "margin-top: 0;")
                  ),
                  
                  div(class = "panel-body",
                      p("Test your understanding of ANOVA and its applications. For each question, select the best answer and click 'Submit' to see feedback."),
                      
                      # Question 1
                      div(class = "question", id = "q1_container",
                          div(class = "question-title", "Question 1: When to Use ANOVA"),
                          p("A researcher wants to compare the effectiveness of four different anxiety treatments. What statistical test is most appropriate?"),
                          
                          radioButtons("q1", NULL, 
                                     choices = c(
                                       "One-way ANOVA" = "correct",
                                       "Independent samples t-test" = "incorrect1",
                                       "Chi-square test" = "incorrect2",
                                       "Correlation analysis" = "incorrect3"
                                     )),
                          actionButton("check1", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback1")
                      ),
                      
                      # Question 2
                      div(class = "question", id = "q2_container",
                          div(class = "question-title", "Question 2: Understanding Interactions"),
                          p("In a two-way ANOVA examining the effects of therapy type (CBT vs. psychodynamic) and therapy format (individual vs. group) on depression outcomes, a significant interaction is found. What does this mean?"),
                          
                          radioButtons("q2", NULL, 
                                     choices = c(
                                       "The effect of therapy type depends on the therapy format (or vice versa)." = "correct",
                                       "Both therapy type and therapy format have significant main effects." = "incorrect1",
                                       "Neither therapy type nor therapy format has a significant effect on depression outcomes." = "incorrect2",
                                       "CBT is more effective than psychodynamic therapy regardless of format." = "incorrect3"
                                     )),
                          actionButton("check2", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback2")
                      ),
                      
                      # Question 3
                      div(class = "question", id = "q3_container",
                          div(class = "question-title", "Question 3: Post-hoc Tests"),
                          p("A researcher conducts a one-way ANOVA comparing three treatment groups and obtains a significant F-value (p = .008). What should they do next?"),
                          
                          radioButtons("q3", NULL, 
                                     choices = c(
                                       "Conduct post-hoc tests (e.g., Tukey's HSD) to determine which specific groups differ significantly." = "correct",
                                       "Report that all groups differ significantly from each other." = "incorrect1",
                                       "Conclude that the treatment is effective without further analysis." = "incorrect2", 
                                       "Calculate effect sizes but avoid any further group comparisons." = "incorrect3"
                                     )),
                          actionButton("check3", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback3")
                      ),
                      
                      # Question 4
                      div(class = "question", id = "q4_container",
                          div(class = "question-title", "Question 4: Assumptions of ANOVA"),
                          p("Which of the following is NOT an assumption of one-way ANOVA?"),
                          
                          radioButtons("q4", NULL, 
                                     choices = c(
                                       "Equal sample sizes in all groups" = "correct",
                                       "Independence of observations" = "incorrect1",
                                       "Normality of the dependent variable in each group" = "incorrect2",
                                       "Homogeneity of variance across groups" = "incorrect3"
                                     )),
                          actionButton("check4", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback4")
                      ),
                      
                      # Question 5
                      div(class = "question", id = "q5_container",
                          div(class = "question-title", "Question 5: Between vs. Within Designs"),
                          p("A researcher wants to compare three time points (pre-treatment, mid-treatment, post-treatment) for a single group of participants. What type of ANOVA should they use?"),
                          
                          radioButtons("q5", NULL, 
                                     choices = c(
                                       "One-way repeated measures ANOVA" = "correct",
                                       "One-way between-subjects ANOVA" = "incorrect1",
                                       "Two-way ANOVA" = "incorrect2",
                                       "Factorial ANOVA" = "incorrect3"
                                     )),
                          actionButton("check5", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback5")
                      ),
                      
                      # Score display
                      div(id = "score_section", class = "result-container",
                          actionButton("calculate_score", "Calculate My Score", class = "btn-success btn-lg"),
                          htmlOutput("final_score")
                      )
                  )
              )
          )
      )
  )
)

server &lt;- function(input, output, session) {
  
  # Initialize score tracking
  score &lt;- reactiveVal(0)
  answered &lt;- reactiveVal(rep(FALSE, 5))
  
  # Question 1 feedback
  observeEvent(input$check1, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[1] &lt;- TRUE
    answered(current_answered)
    
    # Check if correct and update score
    is_correct &lt;- input$q1 == "correct"
    if(is_correct) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback1 &lt;- renderUI({
      if(is_correct) {
        div(class = "feedback correct",
            h4("Correct!"),
            p(class = "explanation", "One-way ANOVA is appropriate when comparing means across three or more groups defined by a single factor. In this case, the researcher is comparing four different anxiety treatments, so one-way ANOVA would be the most appropriate test. It allows for testing whether there are any significant differences among the four group means while controlling the familywise error rate.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "With four treatment groups, a one-way ANOVA is the appropriate choice. Independent samples t-tests would require multiple comparisons (six t-tests for all possible pairs), increasing the risk of Type I errors. Chi-square tests are for categorical data, not continuous outcomes like treatment effectiveness. Correlation analysis examines relationships between variables, not differences between groups.")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check1")
  })
  
  # Question 2 feedback
  observeEvent(input$check2, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[2] &lt;- TRUE
    answered(current_answered)
    
    # Check if correct and update score
    is_correct &lt;- input$q2 == "correct"
    if(is_correct) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback2 &lt;- renderUI({
      if(is_correct) {
        div(class = "feedback correct",
            h4("Correct!"),
            p(class = "explanation", "A significant interaction in a two-way ANOVA indicates that the effect of one factor depends on the level of the other factor. In this case, it means that the effectiveness of therapy type (CBT vs. psychodynamic) depends on the therapy format (individual vs. group), or conversely, that the effect of therapy format depends on the therapy type. For example, CBT might be more effective in individual format while psychodynamic therapy might be more effective in group format.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "A significant interaction specifically indicates that the effect of one factor depends on the level of the other factor. It does not simply indicate that both factors have main effects—that would be determined by separate F-tests for each main effect. An interaction means that you cannot interpret the effect of therapy type without considering the therapy format, and vice versa. The presence of an interaction does not automatically tell us which therapy is more effective overall.")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check2")
  })
  
  # Question 3 feedback
  observeEvent(input$check3, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[3] &lt;- TRUE
    answered(current_answered)
    
    # Check if correct and update score
    is_correct &lt;- input$q3 == "correct"
    if(is_correct) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback3 &lt;- renderUI({
      if(is_correct) {
        div(class = "feedback correct",
            h4("Correct!"),
            p(class = "explanation", "A significant F-value in ANOVA indicates that there are statistically significant differences somewhere among the groups, but it doesn't tell us which specific groups differ. Post-hoc tests like Tukey's HSD, Bonferroni, or Scheffé are designed to make pairwise comparisons while controlling for multiple testing. These tests will reveal which particular groups differ significantly from each other.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "A significant ANOVA result only tells us that there are significant differences somewhere among the groups, not that all groups differ from each other. To determine which specific groups differ, we need to conduct post-hoc tests or planned comparisons. While calculating effect sizes is important, it doesn't help identify which groups differ. Simply concluding that 'the treatment is effective' is inappropriate because ANOVA compares multiple groups and doesn't specify which treatment(s) might be effective.")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check3")
  })
  
  # Question 4 feedback
  observeEvent(input$check4, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[4] &lt;- TRUE
    answered(current_answered)
    
    # Check if correct and update score
    is_correct &lt;- input$q4 == "correct"
    if(is_correct) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback4 &lt;- renderUI({
      if(is_correct) {
        div(class = "feedback correct",
            h4("Correct!"),
            p(class = "explanation", "Equal sample sizes (balanced design) is not a formal assumption of ANOVA, although having equal sample sizes makes ANOVA more robust to violations of the homogeneity of variance assumption. The key assumptions of one-way ANOVA are: independence of observations, normality of the dependent variable in each group, and homogeneity of variance across groups.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "The three main assumptions of one-way ANOVA are: (1) independence of observations within and between groups, (2) normality of the dependent variable within each group, and (3) homogeneity of variance across groups. Equal sample sizes, while helpful for robustness, is not a formal assumption of ANOVA. ANOVA can be conducted with unequal sample sizes, though this makes the test more sensitive to violations of the homogeneity of variance assumption.")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check4")
  })
  
  # Question 5 feedback
  observeEvent(input$check5, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[5] &lt;- TRUE
    answered(current_answered)
    
    # Check if correct and update score
    is_correct &lt;- input$q5 == "correct"
    if(is_correct) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback5 &lt;- renderUI({
      if(is_correct) {
        div(class = "feedback correct",
            h4("Correct!"),
            p(class = "explanation", "When the same participants are measured at multiple time points, a repeated measures (within-subjects) design is appropriate. Since there's a single factor (time) with three levels (pre, mid, post), a one-way repeated measures ANOVA should be used. This design takes advantage of the correlation between repeated measurements and controls for individual differences, typically resulting in greater statistical power than a between-subjects design.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "When the same participants are measured at three time points, a within-subjects design is being used, so a repeated measures ANOVA is appropriate. A between-subjects ANOVA would be used if different participants were in each time point group. A two-way ANOVA involves two factors, but this scenario only has one factor (time). A factorial ANOVA is a general term for ANOVA with multiple factors, which doesn't fit this single-factor design.")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check5")
  })
  
  # Calculate and display final score
  observeEvent(input$calculate_score, {
    # Check if all questions have been answered
    if(!all(answered())) {
      output$final_score &lt;- renderUI({
        div(class = "alert alert-warning",
            h4("Please answer all questions first!"),
            p("Make sure you've submitted an answer for each question before calculating your score.")
        )
      })
      return()
    }
    
    # Calculate percentage
    total &lt;- 5
    current_score &lt;- score()
    percentage &lt;- round((current_score / total) * 100)
    
    # Generate feedback based on score
    feedback &lt;- if(percentage &gt;= 80) {
      "Excellent work! You have a strong understanding of ANOVA and its applications in clinical psychology."
    } else if(percentage &gt;= 60) {
      "Good job! You understand many key concepts about ANOVA, but might want to review some areas to strengthen your understanding."
    } else {
      "You might benefit from reviewing this chapter again to strengthen your understanding of ANOVA concepts."
    }
    
    # Display score and feedback
    output$final_score &lt;- renderUI({
      div(class = "well well-lg",
          h3(paste0("Your Score: ", current_score, "/", total, " (", percentage, "%)")),
          p(feedback),
          if(percentage &lt; 100) {
            p("Review the questions you missed and the explanations provided to deepen your understanding.")
          } else {
            p("Perfect score! You're well-prepared to move on to the next chapter on regression analysis.")
          }
      )
    })
    
    # Disable the button after clicking
    disable("calculate_score")
  })
}

shinyApp(ui, server)</code></pre>
<hr>
</section>
</section>
<section id="relationships-between-variables-regression" class="level1 unnumbered">
<h1 class="unnumbered">4. Relationships Between Variables: Regression</h1>
<div class="key-concepts">
<p><strong>Key Concepts:</strong></p>
<ul>
<li>Simple linear regression for examining the relationship between two variables</li>
<li>Multiple regression for examining relationships with multiple predictors</li>
<li>Logistic regression for binary outcomes</li>
<li>Assumptions of regression models and how to check them</li>
<li>Interpretation of regression coefficients and effect sizes</li>
<li>Model selection and evaluation</li>
<li>Prediction vs.&nbsp;explanation in regression models</li>
</ul>
</div>
<section id="introduction-to-regression" class="level2">
<h2 class="anchored" data-anchor-id="introduction-to-regression">4.1 Introduction to Regression</h2>
<p>Regression analysis is a powerful statistical method for examining relationships between variables. Unlike t-tests and ANOVA, which focus on group differences, regression focuses on how variables relate to each other and how one variable might predict another.</p>
<div class="definition">
<p><strong>Regression Analysis:</strong> A set of statistical methods for estimating the relationships between a dependent variable and one or more independent variables.</p>
</div>
<div class="margin-note">
<p>Regression can be used for both prediction (using independent variables to predict a dependent variable) and explanation (understanding the relationship between variables).</p>
</div>
<p>In clinical psychology, regression is commonly used to:</p>
<ul>
<li>Identify predictors of treatment outcomes</li>
<li>Examine relationships between psychological constructs</li>
<li>Control for confounding variables</li>
<li>Develop prediction models for clinical phenomena</li>
</ul>
</section>
<section id="simple-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="simple-linear-regression">4.2 Simple Linear Regression</h2>
<p>Simple linear regression examines the relationship between a single predictor variable (X) and an outcome variable (Y).</p>
<div class="definition">
<p><strong>Simple Linear Regression:</strong> A statistical method for examining the linear relationship between one independent variable and one dependent variable.</p>
</div>
<section id="the-linear-regression-model" class="level3">
<h3 class="anchored" data-anchor-id="the-linear-regression-model">4.2.1 The Linear Regression Model</h3>
<p>The simple linear regression model can be represented as:</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1X + \varepsilon\]</span></p>
<p>Where:</p>
<ul>
<li>Y is the dependent variable</li>
<li>X is the independent variable</li>
<li><span class="math inline">\(\beta_0\)</span> is the intercept (the value of Y when X = 0)</li>
<li><span class="math inline">\(\beta_1\)</span> is the slope (the change in Y for a one-unit change in X)</li>
<li><span class="math inline">\(\varepsilon\)</span> is the error term (the difference between the predicted and actual values)</li>
</ul>
<p>The model finds the best-fitting line through the data points by minimizing the sum of squared errors (the distances between the observed Y values and the predicted Y values).</p>
</section>
<section id="when-to-use-simple-linear-regression" class="level3">
<h3 class="anchored" data-anchor-id="when-to-use-simple-linear-regression">4.2.2 When to Use Simple Linear Regression</h3>
<p>Use simple linear regression when:</p>
<ul>
<li>You have one continuous independent variable</li>
<li>You have one continuous dependent variable</li>
<li>You want to examine the relationship between these variables</li>
<li>You want to predict the dependent variable based on the independent variable</li>
</ul>
<div class="example">
<p><strong>Clinical Example:</strong> A researcher wants to examine the relationship between therapy session attendance (number of sessions attended) and reduction in depression symptoms. Simple linear regression can determine if more sessions predict greater symptom reduction and quantify this relationship.</p>
</div>
</section>
<section id="correlation-vs.-regression" class="level3">
<h3 class="anchored" data-anchor-id="correlation-vs.-regression">4.2.3 Correlation vs.&nbsp;Regression</h3>
<p>Correlation and regression are closely related:</p>
<div class="margin-note">
<p>Correlation (r) ranges from -1 to 1, while the coefficient of determination (R²) ranges from 0 to 1.</p>
</div>
<ul>
<li><strong>Correlation (r):</strong> Measures the strength and direction of the linear relationship between two variables</li>
<li><strong>Regression (β):</strong> Quantifies how much Y changes for a one-unit change in X</li>
<li><strong>Coefficient of determination (R²):</strong> The proportion of variance in Y explained by X</li>
</ul>
<p>The relationship between these metrics:</p>
<ul>
<li>R² = r²</li>
<li>The sign of <span class="math inline">\(\beta_1\)</span> is the same as the sign of r</li>
<li>If X and Y are standardized, <span class="math inline">\(\beta_1\)</span> = r</li>
</ul>
</section>
<section id="key-assumptions-of-simple-linear-regression" class="level3">
<h3 class="anchored" data-anchor-id="key-assumptions-of-simple-linear-regression">4.2.4 Key Assumptions of Simple Linear Regression</h3>
<p>Simple linear regression makes several key assumptions:</p>
<ol type="1">
<li><strong>Linearity:</strong> The relationship between X and Y is linear</li>
<li><strong>Independence:</strong> Observations are independent of each other</li>
<li><strong>Homoscedasticity:</strong> The variance of errors is consistent across all values of X</li>
<li><strong>Normality of residuals:</strong> The residuals (errors) follow a normal distribution</li>
</ol>
<p>Checking these assumptions:</p>
<ul>
<li>Linearity: Scatterplots of Y vs.&nbsp;X</li>
<li>Independence: Ensured through proper study design</li>
<li>Homoscedasticity: Residuals vs.&nbsp;fitted values plot</li>
<li>Normality of residuals: Histogram or Q-Q plot of residuals</li>
</ul>
</section>
<section id="interpretation-of-regression-results" class="level3">
<h3 class="anchored" data-anchor-id="interpretation-of-regression-results">4.2.5 Interpretation of Regression Results</h3>
<p>Key elements to interpret in simple linear regression:</p>
<ol type="1">
<li><strong>Regression coefficient (<span class="math inline">\(\beta_1\)</span>):</strong> The change in Y for a one-unit change in X</li>
<li><strong>Intercept (<span class="math inline">\(\beta_0\)</span>):</strong> The predicted value of Y when X = 0 (which may not be meaningful depending on the scale of X)</li>
<li><strong>Statistical significance (p-value):</strong> Indicates whether the relationship is statistically significant</li>
<li><strong>R² (coefficient of determination):</strong> The proportion of variance in Y explained by X</li>
</ol>
<div class="example">
<p><strong>Interpretation Example:</strong> “There was a significant relationship between session attendance and symptom reduction (β = 0.42, p = .003), with each additional therapy session associated with a 0.42-point decrease in depression scores. Session attendance explained 18% of the variance in symptom reduction (R² = .18).”</p>
</div>
<div style="width:175%; margin-left:-75%; position:relative; overflow:visible;">
<pre class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 700

install.packages(c("shiny", "ggplot2", "shinyjs"))
library(shiny)
library(ggplot2)
library(shinyjs)

ui &lt;- fluidPage(
  titlePanel("Simple Linear Regression Interactive Visualization"),
  
  sidebarLayout(
    # Left side: Controls
    sidebarPanel(
      width = 3,
      
      # Clinical context first - this will drive other UI elements
      selectInput("clinicalContext", "Choose a clinical example:",
                  choices = c(
                    "General" = "general",
                    "Therapy Sessions &amp; Outcome" = "therapy",
                    "Depression &amp; Social Support" = "depression",
                    "Anxiety &amp; CBT Skill Application" = "anxiety"
                  )),
      
      hr(),
      
      # Data Parameters - these will update based on clinical context
      h4("Data Parameters"),
      sliderInput("sampleSize", "Sample Size:", 
                  min = 10, max = 100, value = 30),
      
      # These sliders will be updated dynamically based on context
      uiOutput("xParametersUI"),
      uiOutput("errorSDUI"),
      
      hr(),
      
      # Regression Parameters
      h4("Regression Parameters"),
      uiOutput("regressionParametersUI"),
      actionButton("resample", "Generate New Data", 
                   class = "btn-primary btn-block"),
      
      hr(),
      
      # Display Options
      h4("Display Options"),
      checkboxInput("showCI", "Show Confidence Interval", TRUE),
      checkboxInput("showPI", "Show Prediction Interval", FALSE),
      checkboxInput("showEquation", "Show Regression Equation", TRUE)
    ),
    
    # Right side: Content
    mainPanel(
      width = 9,
      tabsetPanel(
        tabPanel("Visualization", 
                 br(),
                 htmlOutput("contextDescription"),
                 br(),
                 plotOutput("regressionPlot", height = "400px")),
        
        tabPanel("Model Details", 
                 br(),
                 verbatimTextOutput("modelSummary"),
                 br(),
                 plotOutput("diagnosticPlot", height = "400px")),
        
        tabPanel("Equation Breakdown", 
                 br(),
                 htmlOutput("equationExplanation"),
                 br(),
                 verbatimTextOutput("coefficientInterpretation"))
      )
    )
  )
)

server &lt;- function(input, output, session) {
  
  # Dynamic UI elements based on clinical context
  output$xParametersUI &lt;- renderUI({
    context &lt;- input$clinicalContext
    
    switch(context,
           "general" = list(
             sliderInput("xmean", "X Mean:", min = 0, max = 100, value = 50),
             sliderInput("xsd", "X Standard Deviation:", min = 1, max = 30, value = 10)
           ),
           "therapy" = list(
             sliderInput("xmean", "Average Number of Sessions:", min = 4, max = 20, value = 10),
             sliderInput("xsd", "Session Count Variation:", min = 1, max = 6, value = 3)
           ),
           "depression" = list(
             sliderInput("xmean", "Average Social Support:", min = 10, max = 50, value = 30),
             sliderInput("xsd", "Support Variation:", min = 1, max = 10, value = 5)
           ),
           "anxiety" = list(
             sliderInput("xmean", "Average Practice (hours/week):", min = 0, max = 10, value = 3),
             sliderInput("xsd", "Practice Variation:", min = 0.5, max = 3, value = 1)
           )
    )
  })
  
  output$errorSDUI &lt;- renderUI({
    context &lt;- input$clinicalContext
    
    switch(context,
           "general" = sliderInput("errorSD", "Error Standard Deviation:", min = 1, max = 30, value = 8),
           "therapy" = sliderInput("errorSD", "Outcome Variability:", min = 1, max = 15, value = 5),
           "depression" = sliderInput("errorSD", "Depression Score Variability:", min = 1, max = 8, value = 3),
           "anxiety" = sliderInput("errorSD", "Anxiety Score Variability:", min = 1, max = 5, value = 2)
    )
  })
  
  output$regressionParametersUI &lt;- renderUI({
    context &lt;- input$clinicalContext
    
    switch(context,
           "general" = list(
             sliderInput("intercept", "True Intercept (β₀):", min = -10, max = 10, value = 0),
             sliderInput("slope", "True Slope (β₁):", min = -2, max = 2, value = 1, step = 0.1)
           ),
           "therapy" = list(
             sliderInput("intercept", "Baseline Improvement:", min = -5, max = 15, value = 5),
             sliderInput("slope", "Improvement per Session:", min = 0, max = 3, value = 1.2, step = 0.1)
           ),
           "depression" = list(
             sliderInput("intercept", "Baseline Depression:", min = 10, max = 25, value = 20),
             sliderInput("slope", "Effect of Support:", min = -1, max = 0, value = -0.4, step = 0.05)
           ),
           "anxiety" = list(
             sliderInput("intercept", "Baseline Anxiety:", min = 5, max = 20, value = 15),
             sliderInput("slope", "Effect of Practice:", min = -2, max = 0, value = -1, step = 0.1)
           )
    )
  })
  
  # Update axis labels based on clinical context
  axisLabels &lt;- reactive({
    switch(input$clinicalContext,
           "general" = list(x = "Independent Variable (X)", y = "Dependent Variable (Y)"),
           "therapy" = list(x = "Number of Therapy Sessions", y = "Symptom Severity Reduction"),
           "depression" = list(x = "Social Support Score", y = "Depression Severity"),
           "anxiety" = list(x = "CBT Skills Practice (hours/week)", y = "Anxiety Level")
    )
  })
  
  # Generate descriptive context
  output$contextDescription &lt;- renderUI({
    context_html &lt;- switch(input$clinicalContext,
                           "general" = "
        &lt;div class='alert alert-info'&gt;
          &lt;h4&gt;General Linear Relationship&lt;/h4&gt;
          &lt;p&gt;This shows a general linear relationship between two variables. Adjust the parameters
          to see how they affect the regression line and model fit.&lt;/p&gt;
        &lt;/div&gt;
      ",
                           "therapy" = "
        &lt;div class='alert alert-info'&gt;
          &lt;h4&gt;Therapy Sessions &amp; Outcome&lt;/h4&gt;
          &lt;p&gt;This model examines the relationship between the number of therapy sessions attended and
          reduction in symptom severity. A positive slope indicates that more sessions are associated
          with greater symptom reduction.&lt;/p&gt;
        &lt;/div&gt;
      ",
                           "depression" = "
        &lt;div class='alert alert-info'&gt;
          &lt;h4&gt;Depression &amp; Social Support&lt;/h4&gt;
          &lt;p&gt;This model examines the relationship between perceived social support and depression severity.
          A negative slope would indicate that higher social support is associated with lower depression scores.&lt;/p&gt;
        &lt;/div&gt;
      ",
                           "anxiety" = "
        &lt;div class='alert alert-info'&gt;
          &lt;h4&gt;Anxiety &amp; CBT Skill Practice&lt;/h4&gt;
          &lt;p&gt;This model examines the relationship between time spent practicing CBT skills and anxiety levels.
          A negative slope would indicate that more practice is associated with lower anxiety.&lt;/p&gt;
        &lt;/div&gt;
      "
    )
    HTML(context_html)
  })
  
  # Trigger resampling when context changes
  observeEvent(input$clinicalContext, {
    # This will force the reactive simData to recalculate
    runjs("$('#resample').click();")
  })
  
  # Generate data reactively
  simData &lt;- reactive({
    # Regenerate data when button is clicked or required inputs change
    input$resample
    
    # Validate that all necessary inputs exist before proceeding
    req(input$sampleSize, input$xmean, input$xsd, input$errorSD, 
        input$intercept, input$slope, input$clinicalContext)
    
    set.seed(sample(1:1000, 1))
    n &lt;- input$sampleSize
    
    # Generate X based on defined parameters appropriate for the context
    if (input$clinicalContext == "therapy") {
      # For therapy sessions, round to whole numbers
      x &lt;- round(rnorm(n, mean = input$xmean, sd = input$xsd))
      # Ensure no negative session counts
      x &lt;- pmax(x, 1)  
    } else if (input$clinicalContext == "anxiety") {
      # For practice hours, ensure non-negative values
      x &lt;- pmax(rnorm(n, mean = input$xmean, sd = input$xsd), 0)
    } else {
      # For other contexts, use normal distribution
      x &lt;- rnorm(n, mean = input$xmean, sd = input$xsd)
    }
    
    # Calculate theoretical y based on regression equation
    y_theory &lt;- input$intercept + input$slope * x
    
    # Add random error
    error &lt;- rnorm(n, mean = 0, sd = input$errorSD)
    
    # Create actual y with error
    y &lt;- y_theory + error
    
    # Adjust y values for specific contexts if needed
    if (input$clinicalContext == "depression") {
      # PHQ-9 range: 0-27
      y &lt;- pmin(pmax(y, 0), 27)
    } else if (input$clinicalContext == "anxiety") {
      # GAD-7 range: 0-21
      y &lt;- pmin(pmax(y, 0), 21)
    }
    
    # Create data frame
    data.frame(x = x, y = y)
  })
  
  # Calculate derived correlation
  derivedCorrelation &lt;- reactive({
    validate(need(simData(), "Generating data..."))
    data &lt;- simData()
    cor(data$x, data$y)
  })
  
  # Fit linear model
  fitModel &lt;- reactive({
    validate(need(simData(), "Generating data..."))
    lm(y ~ x, data = simData())
  })
  
  # Create regression plot
  output$regressionPlot &lt;- renderPlot({
    validate(need(simData(), "Generating data..."))
    validate(need(fitModel(), "Fitting model..."))
    
    data &lt;- simData()
    model &lt;- fitModel()
    
    # Create base plot
    p &lt;- ggplot(data, aes(x = x, y = y)) +
      geom_point(color = "steelblue", alpha = 0.6)
    
    # Add smooth line with confidence interval if requested
    p &lt;- p + geom_smooth(method = "lm", se = input$showCI, color = "darkred")
    
    # Set appropriate labels
    p &lt;- p + labs(
      title = paste("Simple Linear Regression:", 
                    switch(input$clinicalContext,
                           "general" = "General Example",
                           "therapy" = "Therapy Sessions &amp; Outcome",
                           "depression" = "Depression &amp; Social Support",
                           "anxiety" = "Anxiety &amp; CBT Skill Practice")),
      subtitle = paste0("Sample Size = ", input$sampleSize, 
                        ", Correlation r = ", round(derivedCorrelation(), 3)),
      x = axisLabels()$x,
      y = axisLabels()$y
    )
    
    # Add equation if requested
    if (input$showEquation) {
      p &lt;- p + 
        annotate("text", x = min(data$x), y = max(data$y), 
                 label = paste0("y = ", round(coef(model)[1], 2), 
                                ifelse(coef(model)[2] &gt;= 0, " + ", " - "), 
                                abs(round(coef(model)[2], 2)), "x"),
                 hjust = 0, vjust = 1, size = 5)
    }
    
    # Add prediction intervals if requested
    if (input$showPI) {
      newdata &lt;- data.frame(x = seq(min(data$x), max(data$x), length.out = 100))
      pred_intervals &lt;- predict(model, newdata, interval = "prediction")
      
      pred_data &lt;- cbind(newdata, pred_intervals)
      
      p &lt;- p + 
        geom_line(data = pred_data, 
                  aes(x = x, y = lwr), 
                  linetype = "dashed", color = "blue", alpha = 0.5) +
        geom_line(data = pred_data, 
                  aes(x = x, y = upr), 
                  linetype = "dashed", color = "blue", alpha = 0.5)
    }
    
    # Add R² annotation
    r2 &lt;- summary(model)$r.squared
    p &lt;- p + 
      annotate("text", x = max(data$x), y = min(data$y), 
               label = paste0("R² = ", round(r2, 3)), 
               hjust = 1, vjust = 0, size = 5)
    
    p + theme_minimal() +
      theme(
        plot.title = element_text(face = "bold", size = 16),
        axis.title = element_text(size = 14),
        legend.position = "none"
      )
  })
  
  # Model summary output
  output$modelSummary &lt;- renderPrint({
    validate(need(simData(), "Generating data..."))
    validate(need(fitModel(), "Fitting model..."))
    
    # Add context-specific interpretation
    cat("## Linear Regression Analysis\n\n")
    
    cat("### Model Summary\n")
    print(summary(fitModel()))
    
    cat("\n\n### Statistical Details\n")
    cat(paste0("True intercept (β₀): ", input$intercept, "\n"))
    cat(paste0("True slope (β₁): ", input$slope, "\n"))
    cat(paste0("Error SD: ", input$errorSD, "\n"))
    cat(paste0("Observed correlation (r): ", round(derivedCorrelation(), 3), "\n"))
    
    cat("\n\n### Clinical Interpretation\n")
    
    model &lt;- fitModel()
    slope &lt;- coef(model)[2]
    p_value &lt;- summary(model)$coefficients[2,4]
    r2 &lt;- summary(model)$r.squared
    
    significance &lt;- ifelse(p_value &lt; 0.05, "significant", "not significant")
    
    cat(paste0("In this ", input$clinicalContext, " context:\n\n"))
    
    context_interp &lt;- switch(input$clinicalContext,
                             "general" = paste0("The relationship between the independent and dependent variables is ", 
                                                significance, ". For each one-unit increase in X, Y changes by ", 
                                                round(slope, 2), " units."),
                             
                             "therapy" = paste0("The relationship between therapy sessions and symptom reduction is ", 
                                                significance, ". Each additional therapy session is associated with a ", 
                                                abs(round(slope, 2)), " point ", 
                                                ifelse(slope &gt; 0, "increase", "decrease"), 
                                                " in symptom reduction."),
                             
                             "depression" = paste0("The relationship between social support and depression severity is ", 
                                                   significance, ". Each one-point increase in social support score is associated with a ", 
                                                   abs(round(slope, 2)), " point ", 
                                                   ifelse(slope &lt; 0, "decrease", "increase"), 
                                                   " in depression severity."),
                             
                             "anxiety" = paste0("The relationship between CBT skills practice and anxiety level is ", 
                                                significance, ". Each additional hour of weekly practice is associated with a ", 
                                                abs(round(slope, 2)), " point ", 
                                                ifelse(slope &lt; 0, "decrease", "increase"), 
                                                " in anxiety level.")
    )
    
    cat(context_interp)
    cat(paste0("\n\nThe R² value of ", round(r2, 3), " indicates that approximately ", 
               round(r2 * 100), "% of the variance in ", 
               axisLabels()$y, " can be explained by ", 
               axisLabels()$x, "."))
  })
  
  # Diagnostic plots
  output$diagnosticPlot &lt;- renderPlot({
    validate(need(simData(), "Generating data..."))
    validate(need(fitModel(), "Fitting model..."))
    
    model &lt;- fitModel()
    data &lt;- simData()
    
    # Create a 2x2 layout with base R for better stability
    par(mfrow = c(2, 2))
    
    # Residuals vs Fitted
    plot(fitted(model), residuals(model),
         xlab = "Fitted values", ylab = "Residuals",
         main = "Residuals vs Fitted",
         pch = 19, col = "steelblue")
    abline(h = 0, lty = 2)
    
    # Normal Q-Q Plot
    qqnorm(residuals(model), pch = 19, col = "steelblue")
    qqline(residuals(model), col = "red")
    
    # Scale-Location Plot
    plot(fitted(model), sqrt(abs(residuals(model))),
         xlab = "Fitted values", ylab = "√|Residuals|",
         main = "Scale-Location",
         pch = 19, col = "steelblue")
    
    # Residuals vs Leverage
    plot(hatvalues(model), residuals(model),
         xlab = "Leverage", ylab = "Residuals",
         main = "Residuals vs Leverage",
         pch = 19, col = "steelblue")
    abline(h = 0, lty = 2)
  })
  
  # Equation explanation with step-by-step calculations
  output$equationExplanation &lt;- renderUI({
    validate(need(simData(), "Generating data..."))
    validate(need(fitModel(), "Fitting model..."))
    
    model &lt;- fitModel()
    data &lt;- simData()
    
    # Extract model parameters
    intercept &lt;- coef(model)[1]
    slope &lt;- coef(model)[2]
    
    # Pick a sample point for demonstration
    sample_index &lt;- sample(1:nrow(data), 1)
    x_sample &lt;- data$x[sample_index]
    y_sample &lt;- data$y[sample_index]
    y_pred &lt;- predict(model, newdata = data.frame(x = x_sample))
    residual &lt;- y_sample - y_pred
    
    # Get context-specific variable names
    x_name &lt;- gsub(" \\(.*\\)", "", axisLabels()$x)
    y_name &lt;- gsub(" \\(.*\\)", "", axisLabels()$y)
    
    HTML(paste0(
      "&lt;div class='well'&gt;",
      "&lt;h4&gt;Linear Regression Equation Breakdown&lt;/h4&gt;",
      "&lt;p&gt;The simple linear regression equation is:&lt;/p&gt;",
      "&lt;p style='text-align: center;'&gt;&lt;strong&gt;Y = β₀ + β₁X + ε&lt;/strong&gt;&lt;/p&gt;",
      "&lt;p&gt;Where:&lt;/p&gt;",
      "&lt;ul&gt;",
      "&lt;li&gt;Y is the dependent variable (", y_name, ")&lt;/li&gt;",
      "&lt;li&gt;X is the independent variable (", x_name, ")&lt;/li&gt;",
      "&lt;li&gt;β₀ is the intercept (value of Y when X = 0)&lt;/li&gt;",
      "&lt;li&gt;β₁ is the slope (change in Y for a one-unit change in X)&lt;/li&gt;",
      "&lt;li&gt;ε is the error term (difference between predicted and actual values)&lt;/li&gt;",
      "&lt;/ul&gt;",
      "&lt;p&gt;For our estimated model:&lt;/p&gt;",
      "&lt;p style='text-align: center;'&gt;&lt;strong&gt;", y_name, " = ", round(intercept, 2), 
      ifelse(slope &gt;= 0, " + ", " - "), abs(round(slope, 2)), " × ", x_name, "&lt;/strong&gt;&lt;/p&gt;",
      "&lt;hr&gt;",
      "&lt;h4&gt;Step-by-Step Prediction Example&lt;/h4&gt;",
      "&lt;p&gt;Let's predict ", y_name, " for a specific value of ", x_name, " = ", round(x_sample, 2), ":&lt;/p&gt;",
      "&lt;p&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Substitute X into the equation&lt;/p&gt;",
      "&lt;p&gt;", y_name, " = ", round(intercept, 2), ifelse(slope &gt;= 0, " + ", " - "), 
      abs(round(slope, 2)), " × ", round(x_sample, 2), "&lt;/p&gt;",
      "&lt;p&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; Calculate&lt;/p&gt;",
      "&lt;p&gt;", y_name, " = ", round(intercept, 2), ifelse(slope * x_sample &gt;= 0, " + ", " - "), 
      abs(round(slope * x_sample, 2)), "&lt;/p&gt;",
      "&lt;p&gt;", y_name, " = ", round(y_pred, 2), "&lt;/p&gt;",
      "&lt;p&gt;The actual observed ", y_name, " value was ", round(y_sample, 2), 
      ", giving a residual (error) of ", round(residual, 2), ".&lt;/p&gt;",
      "&lt;/div&gt;"
    ))
  })
  
  # Coefficient interpretation
  output$coefficientInterpretation &lt;- renderText({
    validate(need(simData(), "Generating data..."))
    validate(need(fitModel(), "Fitting model..."))
    
    model &lt;- fitModel()
    r2 &lt;- summary(model)$r.squared
    
    intercept &lt;- coef(model)[1]
    slope &lt;- coef(model)[2]
    
    # Compare estimated vs true parameters
    paste0(
      "Comparison of True vs. Estimated Parameters:\n\n",
      "Parameter       | True Value | Estimated Value | Difference\n",
      "--------------- | ---------- | --------------- | ----------\n",
      "Intercept (β₀)  | ", sprintf("%-10s", input$intercept), " | ", 
      sprintf("%-15s", round(intercept, 3)), " | ", round(intercept - input$intercept, 3), "\n",
      "Slope (β₁)      | ", sprintf("%-10s", input$slope), " | ", 
      sprintf("%-15s", round(slope, 3)), " | ", round(slope - input$slope, 3), "\n\n",
      
      "Statistical Measures:\n",
      "- R² (Coefficient of determination): ", round(r2, 3), "\n",
      "- Pearson's r (Correlation): ", round(derivedCorrelation(), 3), "\n",
      "- Error standard deviation: ", input$errorSD, "\n\n",
      
      "Interpretation in ", input$clinicalContext, " context:\n\n",
      "The intercept (", round(intercept, 2), ") represents the expected ", axisLabels()$y, 
      " when ", axisLabels()$x, " is zero.\n\n",
      "The slope (", round(slope, 2), ") indicates that for each one-unit increase in ", 
      axisLabels()$x, ", ", axisLabels()$y, " changes by ", round(slope, 2), " units.\n\n",
      "In clinical terms, this ", ifelse(abs(slope) &lt; 0.2, "might be considered a small effect",
                                         ifelse(abs(slope) &lt; 0.5, "represents a moderate effect",
                                                "represents a substantial effect")), "."
    )
  })
}

shinyApp(ui, server)</code></pre>
</div>
<p>Use this interactive application to explore how changing the slope, intercept, and error variance affects the regression line and model fit.</p>
</section>
</section>
<section id="multiple-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="multiple-linear-regression">4.3 Multiple Linear Regression</h2>
<p>Multiple linear regression extends simple linear regression to include multiple predictors, allowing us to examine more complex relationships and control for potential confounding variables.</p>
<div class="definition">
<p><strong>Multiple Linear Regression:</strong> A statistical method for examining the relationship between multiple independent variables and one dependent variable.</p>
</div>
<section id="the-multiple-regression-model" class="level3">
<h3 class="anchored" data-anchor-id="the-multiple-regression-model">4.3.1 The Multiple Regression Model</h3>
<p>The multiple regression model can be represented as:</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_pX_p + \varepsilon\]</span></p>
<p>Where:</p>
<ul>
<li>Y is the dependent variable</li>
<li>X₁, X₂, …, X_p are the independent variables</li>
<li>β₀ is the intercept</li>
<li>β₁, β₂, …, β_p are the regression coefficients</li>
<li>ε is the error term</li>
</ul>
</section>
<section id="when-to-use-multiple-regression" class="level3">
<h3 class="anchored" data-anchor-id="when-to-use-multiple-regression">4.3.2 When to Use Multiple Regression</h3>
<p>Use multiple regression when:</p>
<ul>
<li>You have multiple continuous or categorical independent variables</li>
<li>You have one continuous dependent variable</li>
<li>You want to examine the unique contribution of each predictor</li>
<li>You want to control for potential confounding variables</li>
</ul>
<div class="example">
<p><strong>Clinical Example:</strong> A researcher wants to predict treatment outcomes based on multiple factors: pre-treatment symptom severity, therapeutic alliance, and number of sessions attended. Multiple regression can determine the unique contribution of each factor while controlling for the others.</p>
</div>
</section>
<section id="unique-and-shared-variance" class="level3">
<h3 class="anchored" data-anchor-id="unique-and-shared-variance">4.3.3 Unique and Shared Variance</h3>
<p>A key concept in multiple regression is the distinction between unique and shared variance:</p>
<ul>
<li><strong>Unique variance:</strong> The portion of variance in Y explained by a predictor that is not explained by other predictors</li>
<li><strong>Shared variance:</strong> The portion of variance in Y explained jointly by multiple predictors</li>
</ul>
<div class="margin-note">
<p>The regression coefficient for each predictor represents its unique contribution to the dependent variable, controlling for all other predictors in the model.</p>
</div>
<p>When predictors are correlated (as they often are in psychological research), the unique contribution of each predictor may be smaller than its individual correlation with the dependent variable would suggest.</p>
</section>
<section id="multicollinearity" class="level3">
<h3 class="anchored" data-anchor-id="multicollinearity">4.3.4 Multicollinearity</h3>
<p>Multicollinearity occurs when independent variables are highly correlated with each other, which can cause problems in multiple regression.</p>
<div class="definition">
<p><strong>Multicollinearity:</strong> A condition where two or more independent variables in a regression model are highly correlated, making it difficult to determine their individual effects.</p>
</div>
<p>Problems caused by multicollinearity:</p>
<ul>
<li>Unstable regression coefficients</li>
<li>Inflated standard errors</li>
<li>Difficulty determining the importance of predictors</li>
</ul>
<p>Detecting multicollinearity:</p>
<ul>
<li>Correlation matrix among predictors</li>
<li>Variance Inflation Factor (VIF)</li>
<li>Tolerance values</li>
</ul>
<div class="margin-note">
<p>As a rule of thumb, VIF values greater than 5 (or tolerance values less than 0.2) suggest problematic multicollinearity.</p>
</div>
</section>
<section id="categorical-predictors" class="level3">
<h3 class="anchored" data-anchor-id="categorical-predictors">4.3.5 Categorical Predictors</h3>
<p>Multiple regression can include categorical predictors by converting them to dummy variables:</p>
<ul>
<li>Binary variables (0 or 1) that represent category membership</li>
<li>A categorical variable with k categories requires k-1 dummy variables</li>
<li>The omitted category serves as the reference category</li>
</ul>
<div class="example">
<p><strong>Clinical Example:</strong> A researcher includes therapy type (CBT, psychodynamic, or supportive) as a predictor in a regression model. They create two dummy variables: CBT (1 if CBT, 0 otherwise) and psychodynamic (1 if psychodynamic, 0 otherwise), with supportive therapy as the reference category.</p>
</div>
</section>
<section id="model-selection-and-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="model-selection-and-evaluation">4.3.6 Model Selection and Evaluation</h3>
<p>There are several approaches to selecting predictors for a multiple regression model:</p>
<ol type="1">
<li><strong>Theoretical approach:</strong> Include predictors based on theory and prior research</li>
<li><strong>Hierarchical approach:</strong> Enter predictors in a specific order based on theoretical importance</li>
<li><strong>Stepwise approach:</strong> Add or remove predictors based on statistical criteria</li>
</ol>
<div class="margin-note">
<p>Stepwise methods can be useful for exploratory analyses but can capitalize on chance and may not yield the most theoretically meaningful model.</p>
</div>
<p>Evaluating multiple regression models:</p>
<ul>
<li><strong>Adjusted R²:</strong> R² adjusted for the number of predictors (useful for comparing models with different numbers of predictors)</li>
<li><strong>Change in R²:</strong> The change in explained variance when adding predictors</li>
<li><strong>F-test for model fit:</strong> Tests whether the model as a whole is statistically significant</li>
<li><strong>Information criteria:</strong> AIC (Akaike Information Criterion) or BIC (Bayesian Information Criterion)</li>
</ul>
</section>
<section id="interpretation-of-multiple-regression-results" class="level3">
<h3 class="anchored" data-anchor-id="interpretation-of-multiple-regression-results">4.3.7 Interpretation of Multiple Regression Results</h3>
<p>Key elements to interpret in multiple regression:</p>
<ol type="1">
<li><strong>Overall model fit:</strong> R², adjusted R², F-test</li>
<li><strong>Individual predictors:</strong> Regression coefficients, p-values, confidence intervals</li>
<li><strong>Relative importance:</strong> Standardized coefficients (beta weights) for comparing predictors measured on different scales</li>
</ol>
<div class="example">
<p><strong>Interpretation Example:</strong> “The multiple regression model with three predictors (pre-treatment severity, therapeutic alliance, and sessions attended) explained 42% of the variance in treatment outcomes (R² = .42, F(3, 96) = 23.14, p &lt; .001). Pre-treatment severity (β = -0.38, p &lt; .001) and therapeutic alliance (β = 0.45, p &lt; .001) were significant predictors, while sessions attended was not (β = 0.11, p = .18). The standardized coefficients indicate that therapeutic alliance was the strongest predictor, followed by pre-treatment severity.”</p>
</div>
<div style="width:175%; margin-left:-75%; position:relative; overflow:visible;">
<pre class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 700

install.packages(c("shiny", "ggplot2", "dplyr", "tidyr", "GGally", "car", "corrplot"))
library(shiny)
library(ggplot2)
library(dplyr)
library(tidyr)
library(GGally)
library(car)
library(corrplot)

ui &lt;- fluidPage(
  titlePanel("Multiple Regression Visualization"),
  
  sidebarLayout(
    sidebarPanel(
      width = 3,
      
      h4("Dataset Parameters"),
      
      # Sample size
      sliderInput("sampleSize", "Sample Size:", 
                  min = 20, max = 200, value = 50, step = 10),
      
      hr(),
      
      h4("Predictor Variables"),
      
      # Predictor 1 (Pre-treatment severity)
      h5("Pre-treatment Severity (X₁)"),
      sliderInput("effect1", "Effect on Outcome (β₁):", 
                  min = -1, max = 1, value = -0.4, step = 0.1),
      
      # Predictor 2 (Therapeutic alliance)
      h5("Therapeutic Alliance (X₂)"),
      sliderInput("effect2", "Effect on Outcome (β₂):", 
                  min = -1, max = 1, value = 0.5, step = 0.1),
      sliderInput("x1x2_cor", "Correlation with X₁:", 
                  min = -0.8, max = 0.8, value = -0.3, step = 0.1),
      
      # Predictor 3 (Sessions attended)
      h5("Sessions Attended (X₃)"),
      sliderInput("effect3", "Effect on Outcome (β₃):", 
                  min = -1, max = 1, value = 0.2, step = 0.1),
      sliderInput("x1x3_cor", "Correlation with X₁:", 
                  min = -0.8, max = 0.8, value = -0.1, step = 0.1),
      sliderInput("x2x3_cor", "Correlation with X₂:", 
                  min = -0.8, max = 0.8, value = 0.3, step = 0.1),
      
      hr(),
      
      # Error variance
      sliderInput("errorSD", "Error Standard Deviation:", 
                  min = 0.5, max = 3, value = 1, step = 0.1),
      
      actionButton("simulate", "Generate New Data", class = "btn-primary btn-block"),
      
      hr(),
      
      # Model selection options
      h4("Model Options"),
      checkboxGroupInput("predictors", "Include Predictors:",
                         choices = c("Pre-treatment Severity (X₁)" = "X1",
                                    "Therapeutic Alliance (X₂)" = "X2",
                                    "Sessions Attended (X₃)" = "X3"),
                         selected = c("X1", "X2", "X3"))
    ),
    
    mainPanel(
      width = 9,
      tabsetPanel(
        tabPanel("Correlations", 
                 plotOutput("correlationPlot", height = "500px"),
                 div(class = "well",
                     h4("Understanding Correlations"),
                     p("This plot shows the relationships between all variables. The diagonal shows the distribution of each variable,
                       the upper triangle shows scatter plots with fitted lines, and the lower triangle shows the correlation coefficients."),
                     p("Strong correlations between predictors (multicollinearity) can make it difficult to determine the unique
                       contribution of each predictor to the outcome.")
                 )),
        
        tabPanel("Variance Explained", 
                 plotOutput("variancePlot", height = "500px"),
                 div(class = "well",
                     h4("Understanding Unique and Shared Variance"),
                     p("This plot shows how much variance in the outcome is explained by each predictor uniquely, and how much
                       is shared among predictors."),
                     p("The total R² indicates the proportion of variance in the outcome explained by all predictors combined."),
                     p("When predictors are correlated, the unique variance explained by each predictor (semi-partial correlations squared)
                       is typically smaller than their zero-order correlation squared.")
                 )),
        
        tabPanel("Regression Results", 
                 verbatimTextOutput("regressionSummary"),
                 plotOutput("coefficientPlot", height = "300px"),
                 div(class = "well",
                     h4("Interpreting Regression Results"),
                     p("The regression summary shows:"),
                     tags$ul(
                       tags$li(strong("Overall model fit:"), " R², adjusted R², F-test"),
                       tags$li(strong("Individual predictors:"), " Coefficients, standard errors, t-values, p-values"),
                       tags$li(strong("Variance Inflation Factors (VIF):"), " Measures of multicollinearity")
                     ),
                     p("The coefficient plot shows the standardized regression coefficients (beta weights) with their confidence intervals,
                       which allow for comparing the relative importance of predictors measured on different scales.")
                 )),
        
        tabPanel("Assumptions", 
                 plotOutput("assumptionPlots", height = "600px"),
                 div(class = "well",
                     h4("Checking Regression Assumptions"),
                     p("These diagnostic plots help assess the assumptions of multiple regression:"),
                     tags$ul(
                       tags$li(strong("Residuals vs Fitted:"), " Checks linearity and homoscedasticity"),
                       tags$li(strong("Normal Q-Q:"), " Checks normality of residuals"),
                       tags$li(strong("Scale-Location:"), " Another check for homoscedasticity"),
                       tags$li(strong("Residuals vs Leverage:"), " Identifies influential observations")
                     ),
                     p("Violations of these assumptions can affect the validity of your regression results.")
                 ))
      )
    )
  )
)

server &lt;- function(input, output, session) {
  
  # Generate data based on inputs
  simData &lt;- eventReactive(c(input$simulate, input$sampleSize, input$effect1, 
                             input$effect2, input$effect3, input$x1x2_cor, 
                             input$x1x3_cor, input$x2x3_cor, input$errorSD), {
    set.seed(sample(1:1000, 1))
    
    n &lt;- input$sampleSize
    
    # Create correlation matrix for predictors
    cor_matrix &lt;- matrix(c(
      1, input$x1x2_cor, input$x1x3_cor,
      input$x1x2_cor, 1, input$x2x3_cor,
      input$x1x3_cor, input$x2x3_cor, 1
    ), nrow = 3, ncol = 3)
    
    # Generate multivariate normal predictors
    mvn_data &lt;- MASS::mvrnorm(n, mu = c(0, 0, 0), Sigma = cor_matrix)
    
    # Convert to data frame
    data &lt;- data.frame(
      X1 = mvn_data[, 1],  # Pre-treatment severity
      X2 = mvn_data[, 2],  # Therapeutic alliance
      X3 = mvn_data[, 3]   # Sessions attended
    )
    
    # Scale predictors to have mean = 0, sd = 1
    data$X1 &lt;- scale(data$X1)
    data$X2 &lt;- scale(data$X2)
    data$X3 &lt;- scale(data$X3)
    
    # Generate outcome variable with specified effects and error
    data$Y &lt;- input$effect1 * data$X1 + 
              input$effect2 * data$X2 + 
              input$effect3 * data$X3 + 
              rnorm(n, 0, input$errorSD)
    
    # Calculate correlations and partial correlations
    cor_y_x1 &lt;- cor(data$Y, data$X1)
    cor_y_x2 &lt;- cor(data$Y, data$X2)
    cor_y_x3 &lt;- cor(data$Y, data$X3)
    
    # Return the data
    return(list(
      data = data,
      cor_y_x1 = cor_y_x1,
      cor_y_x2 = cor_y_x2,
      cor_y_x3 = cor_y_x3
    ))
  })
  
  # Fit regression model based on selected predictors
  fitModel &lt;- reactive({
    req(simData())
    
    data &lt;- simData()$data
    
    # Create formula based on selected predictors
    predictors &lt;- input$predictors
    if (length(predictors) == 0) {
      # If no predictors selected, just fit intercept
      formula &lt;- Y ~ 1
    } else {
      # Create formula with selected predictors
      formula_text &lt;- paste("Y ~", paste(predictors, collapse = " + "))
      formula &lt;- as.formula(formula_text)
    }
    
    # Fit the model
    model &lt;- lm(formula, data = data)
    
    # Calculate VIFs if more than one predictor
    if (length(predictors) &gt; 1) {
      vifs &lt;- car::vif(model)
    } else if (length(predictors) == 1) {
      vifs &lt;- c(1)  # VIF is 1 for a single predictor
      names(vifs) &lt;- predictors
    } else {
      vifs &lt;- NULL
    }
    
    return(list(
      model = model,
      vifs = vifs
    ))
  })
  
  # Correlation plot
  output$correlationPlot &lt;- renderPlot({
    req(simData())
    
    data &lt;- simData()$data
    
    # Create correlation matrix plot
    data_renamed &lt;- data %&gt;%
      rename(
        `Pre-treatment Severity` = X1,
        `Therapeutic Alliance` = X2,
        `Sessions Attended` = X3,
        `Treatment Outcome` = Y
      )
    
    GGally::ggpairs(data_renamed, 
                   title = "Correlations Between Variables",
                   upper = list(continuous = GGally::wrap("points", alpha = 0.5, color = "steelblue")),
                   lower = list(continuous = GGally::wrap("cor", size = 5, color = "darkred")),
                   diag = list(continuous = GGally::wrap("densityDiag", fill = "lightblue"))) +
      theme_minimal() +
      theme(
        plot.title = element_text(face = "bold", size = 16),
        axis.text = element_text(size = 10),
        strip.text = element_text(size = 12)
      )
  })
  
  # Variance explained plot
  output$variancePlot &lt;- renderPlot({
    req(simData(), fitModel())
    
    data &lt;- simData()$data
    model_result &lt;- fitModel()
    model &lt;- model_result$model
    
    # Check if we have at least one predictor
    if (length(input$predictors) == 0) {
      # No predictors selected, show empty plot with message
      plot(0, 0, type = "n", axes = FALSE, xlab = "", ylab = "",
           xlim = c(0, 1), ylim = c(0, 1))
      text(0.5, 0.5, "Please select at least one predictor", cex = 1.5)
      return()
    }
    
    # Create a data frame with variance decomposition
    
    # Zero-order correlations (squared)
    r2_y_x1 &lt;- cor(data$Y, data$X1)^2
    r2_y_x2 &lt;- cor(data$Y, data$X2)^2
    r2_y_x3 &lt;- cor(data$Y, data$X3)^2
    
    # Semi-partial correlations (unique variance)
    # We'll calculate these by comparing full model with models excluding each predictor
    
    # Full model R²
    full_r2 &lt;- summary(model)$r.squared
    
    # Setup for variance decomposition
    variance_data &lt;- data.frame()
    
    # Calculate unique and shared variance components
    if ("X1" %in% input$predictors) {
      # Model without X1
      if (length(input$predictors) &gt; 1) {
        formula_without_x1 &lt;- as.formula(paste("Y ~", paste(setdiff(input$predictors, "X1"), collapse = " + ")))
        model_without_x1 &lt;- lm(formula_without_x1, data = data)
        r2_without_x1 &lt;- summary(model_without_x1)$r.squared
        unique_x1 &lt;- full_r2 - r2_without_x1
      } else {
        unique_x1 &lt;- full_r2  # X1 is the only predictor
      }
      
      variance_data &lt;- rbind(variance_data, 
                           data.frame(
                             variable = "Pre-treatment Severity (X₁)",
                             type = "Unique",
                             value = unique_x1
                           ))
      
      variance_data &lt;- rbind(variance_data, 
                           data.frame(
                             variable = "Pre-treatment Severity (X₁)",
                             type = "Total",
                             value = r2_y_x1
                           ))
    }
    
    if ("X2" %in% input$predictors) {
      # Model without X2
      if (length(input$predictors) &gt; 1) {
        formula_without_x2 &lt;- as.formula(paste("Y ~", paste(setdiff(input$predictors, "X2"), collapse = " + ")))
        model_without_x2 &lt;- lm(formula_without_x2, data = data)
        r2_without_x2 &lt;- summary(model_without_x2)$r.squared
        unique_x2 &lt;- full_r2 - r2_without_x2
      } else {
        unique_x2 &lt;- full_r2  # X2 is the only predictor
      }
      
      variance_data &lt;- rbind(variance_data, 
                           data.frame(
                             variable = "Therapeutic Alliance (X₂)",
                             type = "Unique",
                             value = unique_x2
                           ))
      
      variance_data &lt;- rbind(variance_data, 
                           data.frame(
                             variable = "Therapeutic Alliance (X₂)",
                             type = "Total",
                             value = r2_y_x2
                           ))
    }
    
    if ("X3" %in% input$predictors) {
      # Model without X3
      if (length(input$predictors) &gt; 1) {
        formula_without_x3 &lt;- as.formula(paste("Y ~", paste(setdiff(input$predictors, "X3"), collapse = " + ")))
        model_without_x3 &lt;- lm(formula_without_x3, data = data)
        r2_without_x3 &lt;- summary(model_without_x3)$r.squared
        unique_x3 &lt;- full_r2 - r2_without_x3
      } else {
        unique_x3 &lt;- full_r2  # X3 is the only predictor
      }
      
      variance_data &lt;- rbind(variance_data, 
                           data.frame(
                             variable = "Sessions Attended (X₃)",
                             type = "Unique",
                             value = unique_x3
                           ))
      
      variance_data &lt;- rbind(variance_data, 
                           data.frame(
                             variable = "Sessions Attended (X₃)",
                             type = "Total",
                             value = r2_y_x3
                           ))
    }
    
    # Add full model R²
    variance_data &lt;- rbind(variance_data, 
                         data.frame(
                           variable = "Full Model",
                           type = "R²",
                           value = full_r2
                         ))
    
    # Calculate shared variance
    if (length(input$predictors) &gt; 1) {
      # Sum of unique variances
      sum_unique &lt;- sum(variance_data$value[variance_data$type == "Unique"])
      shared &lt;- full_r2 - sum_unique
      
      variance_data &lt;- rbind(variance_data, 
                           data.frame(
                             variable = "Shared",
                             type = "Shared",
                             value = shared
                           ))
    }
    
    # Set factor order
    variance_data$variable &lt;- factor(variance_data$variable, 
                                    levels = c("Pre-treatment Severity (X₁)", 
                                              "Therapeutic Alliance (X₂)", 
                                              "Sessions Attended (X₃)",
                                              "Shared",
                                              "Full Model"))
    
    variance_data$type &lt;- factor(variance_data$type, 
                                levels = c("Unique", "Shared", "Total", "R²"))
    
    # Create the bar chart
    ggplot(variance_data, aes(x = variable, y = value, fill = type)) +
      geom_bar(stat = "identity", position = "dodge") +
      labs(title = "Variance Explained in Treatment Outcome",
           subtitle = paste0("Total R² = ", round(full_r2, 3)),
           x = "",
           y = "Proportion of Variance (R²)",
           fill = "Variance Type") +
      scale_fill_manual(values = c("Unique" = "#1f77b4", 
                                   "Shared" = "#ff7f0e", 
                                   "Total" = "#2ca02c",
                                   "R²" = "#9467bd")) +
      theme_minimal() +
      theme(
        plot.title = element_text(face = "bold", size = 16),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 12),
        axis.title = element_text(size = 14),
        legend.position = "top"
      ) +
      geom_text(aes(label = round(value, 3)), position = position_dodge(width = 0.9), vjust = -0.5)
  })
  
  # Regression summary output
  output$regressionSummary &lt;- renderPrint({
    req(simData(), fitModel())
    
    model_result &lt;- fitModel()
    model &lt;- model_result$model
    vifs &lt;- model_result$vifs
    
    # Print the model summary
    cat("## Multiple Regression Results\n\n")
    print(summary(model))
    
    # Print VIFs if available
    if (!is.null(vifs)) {
      cat("\n\nVariance Inflation Factors (VIFs):\n")
      print(vifs)
      
      # Interpretation of VIFs
      if (any(vifs &gt; 5)) {
        cat("\nNote: VIF values &gt; 5 indicate potential multicollinearity issues.\n")
      } else if (any(vifs &gt; 2.5)) {
        cat("\nNote: VIF values between 2.5 and 5 suggest moderate correlation between predictors.\n")
      } else {
        cat("\nNote: All VIF values are &lt; 2.5, suggesting low multicollinearity.\n")
      }
    }
    
    # Clinical interpretation
    cat("\n\n## Clinical Interpretation\n\n")
    
    # Only proceed if at least one predictor is included
    if (length(input$predictors) &gt; 0) {
      # Overall model fit
      r2 &lt;- summary(model)$r.squared
      adj_r2 &lt;- summary(model)$adj.r.squared
      f_stat &lt;- summary(model)$fstatistic
      p_val &lt;- pf(f_stat[1], f_stat[2], f_stat[3], lower.tail = FALSE)
      
      cat(paste0("The multiple regression model explains ", round(r2 * 100, 1), 
                "% of the variance in treatment outcomes (R² = ", round(r2, 3), 
                ", adjusted R² = ", round(adj_r2, 3), ")."))
      
      if (p_val &lt; 0.05) {
        cat(" The overall model is statistically significant")
        if (p_val &lt; 0.001) {
          cat(" (p &lt; .001).\n\n")
        } else {
          cat(paste0(" (p = ", round(p_val, 3), ").\n\n"))
        }
      } else {
        cat(paste0(" The overall model is not statistically significant (p = ", 
                  round(p_val, 3), ").\n\n"))
      }
      
      # Individual predictors
      coefs &lt;- summary(model)$coefficients
      
      if ("X1" %in% input$predictors) {
        idx &lt;- which(rownames(coefs) == "X1")
        b1 &lt;- coefs[idx, 1]
        p1 &lt;- coefs[idx, 4]
        sig1 &lt;- ifelse(p1 &lt; 0.05, "significant", "not significant")
        
        cat(paste0("Pre-treatment severity is a ", sig1, " predictor"))
        if (p1 &lt; 0.05) {
          cat(paste0(" (β = ", round(b1, 2)))
          if (p1 &lt; 0.001) {
            cat(", p &lt; .001)")
          } else {
            cat(paste0(", p = ", round(p1, 3), ")"))
          }
          
          cat(paste0(". Higher pre-treatment severity is associated with ", 
                    ifelse(b1 &gt; 0, "better", "worse"), " treatment outcomes.\n\n"))
        } else {
          cat(".\n\n")
        }
      }
      
      if ("X2" %in% input$predictors) {
        idx &lt;- which(rownames(coefs) == "X2")
        b2 &lt;- coefs[idx, 1]
        p2 &lt;- coefs[idx, 4]
        sig2 &lt;- ifelse(p2 &lt; 0.05, "significant", "not significant")
        
        cat(paste0("Therapeutic alliance is a ", sig2, " predictor"))
        if (p2 &lt; 0.05) {
          cat(paste0(" (β = ", round(b2, 2)))
          if (p2 &lt; 0.001) {
            cat(", p &lt; .001)")
          } else {
            cat(paste0(", p = ", round(p2, 3), ")"))
          }
          
          cat(paste0(". Stronger therapeutic alliance is associated with ", 
                    ifelse(b2 &gt; 0, "better", "worse"), " treatment outcomes.\n\n"))
        } else {
          cat(".\n\n")
        }
      }
      
      if ("X3" %in% input$predictors) {
        idx &lt;- which(rownames(coefs) == "X3")
        b3 &lt;- coefs[idx, 1]
        p3 &lt;- coefs[idx, 4]
        sig3 &lt;- ifelse(p3 &lt; 0.05, "significant", "not significant")
        
        cat(paste0("Number of sessions attended is a ", sig3, " predictor"))
        if (p3 &lt; 0.05) {
          cat(paste0(" (β = ", round(b3, 2)))
          if (p3 &lt; 0.001) {
            cat(", p &lt; .001)")
          } else {
            cat(paste0(", p = ", round(p3, 3), ")"))
          }
          
          cat(paste0(". More sessions attended is associated with ", 
                    ifelse(b3 &gt; 0, "better", "worse"), " treatment outcomes.\n\n"))
        } else {
          cat(".\n\n")
        }
      }
      
      # Compare standardized coefficients (relative importance)
      sig_preds &lt;- character(0)
      betas &lt;- numeric(0)
      
      if ("X1" %in% input$predictors &amp;&amp; coefs[which(rownames(coefs) == "X1"), 4] &lt; 0.05) {
        sig_preds &lt;- c(sig_preds, "pre-treatment severity")
        betas &lt;- c(betas, abs(coefs[which(rownames(coefs) == "X1"), 1]))
      }
      
      if ("X2" %in% input$predictors &amp;&amp; coefs[which(rownames(coefs) == "X2"), 4] &lt; 0.05) {
        sig_preds &lt;- c(sig_preds, "therapeutic alliance")
        betas &lt;- c(betas, abs(coefs[which(rownames(coefs) == "X2"), 1]))
      }
      
      if ("X3" %in% input$predictors &amp;&amp; coefs[which(rownames(coefs) == "X3"), 4] &lt; 0.05) {
        sig_preds &lt;- c(sig_preds, "number of sessions attended")
        betas &lt;- c(betas, abs(coefs[which(rownames(coefs) == "X3"), 1]))
      }
      
      if (length(sig_preds) &gt;= 2) {
        # Sort by beta weight
        idx &lt;- order(betas, decreasing = TRUE)
        sig_preds &lt;- sig_preds[idx]
        
        cat("Based on the standardized coefficients, ", sig_preds[1], 
            " appears to be the strongest predictor, followed by ", 
            paste(sig_preds[2:length(sig_preds)], collapse = ", "), ".\n")
      }
    } else {
      cat("No predictors are currently included in the model. Please select at least one predictor to see results.")
    }
  })
  
  # Coefficient plot
  output$coefficientPlot &lt;- renderPlot({
    req(simData(), fitModel())
    
    model_result &lt;- fitModel()
    model &lt;- model_result$model
    
    # Check if we have at least one predictor
    if (length(input$predictors) == 0) {
      # No predictors selected, show empty plot with message
      plot(0, 0, type = "n", axes = FALSE, xlab = "", ylab = "",
           xlim = c(0, 1), ylim = c(0, 1))
      text(0.5, 0.5, "Please select at least one predictor", cex = 1.5)
      return()
    }
    
    # Extract coefficients and confidence intervals
    coefs &lt;- summary(model)$coefficients
    coefs &lt;- coefs[-1, , drop = FALSE]  # Remove intercept
    
    # If no predictors are selected (only intercept), return empty plot
    if (nrow(coefs) == 0) {
      plot(0, 0, type = "n", axes = FALSE, xlab = "", ylab = "",
           xlim = c(0, 1), ylim = c(0, 1))
      text(0.5, 0.5, "Please select at least one predictor", cex = 1.5)
      return()
    }
    
    # Create a data frame for plotting
    coef_data &lt;- data.frame(
      predictor = rownames(coefs),
      estimate = coefs[, 1],
      se = coefs[, 2],
      lower = coefs[, 1] - 1.96 * coefs[, 2],
      upper = coefs[, 1] + 1.96 * coefs[, 2],
      p_value = coefs[, 4]
    )
    
    # Replace predictor names for better labels
    coef_data$predictor &lt;- gsub("X1", "Pre-treatment Severity (X₁)", coef_data$predictor)
    coef_data$predictor &lt;- gsub("X2", "Therapeutic Alliance (X₂)", coef_data$predictor)
    coef_data$predictor &lt;- gsub("X3", "Sessions Attended (X₃)", coef_data$predictor)
    
    # Convert to factor with specified order
    coef_data$predictor &lt;- factor(coef_data$predictor, 
                                levels = rev(c("Pre-treatment Severity (X₁)", 
                                              "Therapeutic Alliance (X₂)", 
                                              "Sessions Attended (X₃)")))
    
    # Determine significance for coloring
    coef_data$significant &lt;- coef_data$p_value &lt; 0.05
    
    # Create coefficient plot
    ggplot(coef_data, aes(x = predictor, y = estimate, color = significant)) +
      geom_point(size = 4) +
      geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2, size = 1) +
      geom_hline(yintercept = 0, linetype = "dashed") +
      labs(title = "Standardized Regression Coefficients",
           subtitle = "With 95% Confidence Intervals",
           x = "",
           y = "Standardized Coefficient (β)") +
      theme_minimal() +
      theme(
        legend.position = "none",
        plot.title = element_text(face = "bold", size = 16),
        axis.text.y = element_text(size = 12),
        axis.title = element_text(size = 14)
      ) +
      scale_color_manual(values = c("TRUE" = "#28a745", "FALSE" = "#dc3545")) +
      geom_text(aes(label = ifelse(p_value &lt; 0.001, "p &lt; .001",
                                  ifelse(p_value &lt; 0.05, 
                                        paste0("p = ", round(p_value, 3)),
                                        paste0("p = ", round(p_value, 3))))),
               hjust = -0.2, size = 4) +
      coord_flip(ylim = range(c(coef_data$lower, coef_data$upper)) * 1.2)
  })
  
  # Assumption plots
  output$assumptionPlots &lt;- renderPlot({
    req(simData(), fitModel())
    
    model_result &lt;- fitModel()
    model &lt;- model_result$model
    
    # Check if we have at least one predictor
    if (length(input$predictors) == 0) {
      # No predictors selected, show empty plot with message
      plot(0, 0, type = "n", axes = FALSE, xlab = "", ylab = "",
           xlim = c(0, 1), ylim = c(0, 1))
      text(0.5, 0.5, "Please select at least one predictor", cex = 1.5)
      return()
    }
    
    # Create a 2x2 layout with base R for diagnostic plots
    par(mfrow = c(2, 2))
    
    # Residuals vs Fitted
    plot(fitted(model), residuals(model),
         xlab = "Fitted values", ylab = "Residuals",
         main = "Residuals vs Fitted",
         pch = 19, col = "steelblue")
    abline(h = 0, lty = 2)
    
    # Normal Q-Q Plot
    qqnorm(residuals(model), pch = 19, col = "steelblue", 
           main = "Normal Q-Q Plot")
    qqline(residuals(model), col = "red")
    
    # Scale-Location Plot
    plot(fitted(model), sqrt(abs(residuals(model))),
         xlab = "Fitted values", ylab = "√|Residuals|",
         main = "Scale-Location",
         pch = 19, col = "steelblue")
    
    # Residuals vs Leverage
    plot(hatvalues(model), residuals(model),
         xlab = "Leverage", ylab = "Residuals",
         main = "Residuals vs Leverage",
         pch = 19, col = "steelblue")
    abline(h = 0, lty = 2)
  })
}

shinyApp(ui, server)</code></pre>
</div>
<p>Use this interactive application to explore how multiple predictors contribute to explaining variance in the dependent variable, including the concepts of unique and shared variance.</p>
</section>
</section>
<section id="logistic-regression" class="level2">
<h2 class="anchored" data-anchor-id="logistic-regression">4.4 Logistic Regression</h2>
<p>Logistic regression extends regression analysis to situations where the dependent variable is binary (e.g., success/failure, yes/no, present/absent).</p>
<div class="definition">
<p><strong>Logistic Regression:</strong> A regression model where the dependent variable is categorical, typically binary, and the model predicts the probability of the dependent variable taking a particular value.</p>
</div>
<section id="the-logistic-regression-model" class="level3">
<h3 class="anchored" data-anchor-id="the-logistic-regression-model">4.4.1 The Logistic Regression Model</h3>
<p>The logistic regression model predicts the probability of the outcome occurring (p) as:</p>
<p><span class="math display">\[\text{logit}(p) = \ln\left(\frac{p}{1-p}\right) = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_pX_p\]</span></p>
<p>Where:</p>
<ul>
<li>p is the probability of the outcome occurring</li>
<li>logit(p) is the log odds of the outcome</li>
<li>β₀, β₁, …, β_p are the regression coefficients</li>
</ul>
<p>The model uses the logistic function to constrain predicted values between 0 and 1 (appropriate for probabilities).</p>
</section>
<section id="when-to-use-logistic-regression" class="level3">
<h3 class="anchored" data-anchor-id="when-to-use-logistic-regression">4.4.2 When to Use Logistic Regression</h3>
<p>Use logistic regression when:</p>
<ul>
<li>Your dependent variable is binary</li>
<li>You want to predict the probability of the outcome occurring</li>
<li>You want to examine the relationship between the outcome and one or more predictors</li>
</ul>
<div class="example">
<p><strong>Clinical Example:</strong> A researcher wants to predict treatment completion (completed/dropped out) based on pre-treatment variables such as symptom severity, motivation, and demographic factors. Logistic regression can identify factors associated with higher or lower probabilities of completing treatment.</p>
</div>
</section>
<section id="interpretation-of-logistic-regression-results" class="level3">
<h3 class="anchored" data-anchor-id="interpretation-of-logistic-regression-results">4.4.3 Interpretation of Logistic Regression Results</h3>
<p>The interpretation of logistic regression coefficients is less intuitive than linear regression:</p>
<ol type="1">
<li><p><strong>Regression coefficients (β):</strong> The change in log odds for a one-unit change in the predictor</p></li>
<li><p><strong>Odds ratios (exp(β)):</strong> The multiplicative change in odds for a one-unit change in the predictor</p>
<ul>
<li>Odds ratio &gt; 1: As the predictor increases, the odds of the outcome increase</li>
<li>Odds ratio &lt; 1: As the predictor increases, the odds of the outcome decrease</li>
</ul></li>
<li><p><strong>Predicted probabilities:</strong> The estimated probability of the outcome for specific values of the predictors</p></li>
</ol>
<div class="margin-note">
<p>Odds ratios are often easier to interpret than log odds. For example, an odds ratio of 1.5 means that a one-unit increase in the predictor is associated with a 50% increase in the odds of the outcome.</p>
</div>
</section>
<section id="model-evaluation-in-logistic-regression" class="level3">
<h3 class="anchored" data-anchor-id="model-evaluation-in-logistic-regression">4.4.4 Model Evaluation in Logistic Regression</h3>
<p>Evaluating logistic regression models:</p>
<ol type="1">
<li><p><strong>Overall model fit:</strong></p>
<ul>
<li>Likelihood ratio test (chi-square test)</li>
<li>Pseudo-R² measures (e.g., Nagelkerke R²)</li>
<li>AIC and BIC</li>
</ul></li>
<li><p><strong>Classification accuracy:</strong></p>
<ul>
<li>Sensitivity (true positive rate)</li>
<li>Specificity (true negative rate)</li>
<li>Overall classification accuracy</li>
<li>ROC curve and area under the curve (AUC)</li>
</ul></li>
<li><p><strong>Individual predictors:</strong></p>
<ul>
<li>Wald tests for individual coefficients</li>
<li>Confidence intervals for odds ratios</li>
</ul></li>
</ol>
<div class="example">
<p><strong>Interpretation Example:</strong> “The logistic regression model was statistically significant, χ²(3) = 18.92, p &lt; .001, Nagelkerke R² = .24. Higher motivation was associated with greater odds of completing treatment (OR = 1.64, 95% CI [1.21, 2.22], p = .001), indicating that for each one-unit increase in motivation, the odds of completing treatment increased by 64%. Symptom severity was not significantly related to treatment completion (p = .38).”</p>
</div>
<div style="width:175%; margin-left:-75%; position:relative; overflow:visible;">
<pre class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 700

install.packages(c("shiny", "ggplot2", "dplyr", "tidyr", "pROC"))
library(shiny)
library(ggplot2)
library(dplyr)
library(tidyr)
library(pROC)

ui &lt;- fluidPage(
  titlePanel("Logistic Regression Visualization"),
  
  sidebarLayout(
    sidebarPanel(
      width = 3,
      
      h4("Dataset Parameters"),
      
      # Sample size
      sliderInput("sampleSize", "Sample Size:", 
                  min = 50, max = 500, value = 150, step = 50),
      
      hr(),
      
      h4("Predictor Effects"),
      
      # Predictor 1 (Symptom severity)
      h5("Symptom Severity"),
      sliderInput("effect1", "Effect on Log Odds (β₁):", 
                  min = -2, max = 2, value = -0.8, step = 0.1),
      
      # Predictor 2 (Motivation)
      h5("Motivation"),
      sliderInput("effect2", "Effect on Log Odds (β₂):", 
                  min = -2, max = 2, value = 1.2, step = 0.1),
      sliderInput("x1x2_cor", "Correlation with Severity:", 
                  min = -0.8, max = 0.8, value = -0.3, step = 0.1),
      
      # Intercept (baseline odds)
      h5("Baseline"),
      sliderInput("intercept", "Intercept (β₀):", 
                  min = -3, max = 3, value = -0.5, step = 0.1),
      
      actionButton("simulate", "Generate New Data", class = "btn-primary btn-block"),
      
      hr(),
      
      # Classification threshold
      h4("Classification Settings"),
      sliderInput("threshold", "Probability Threshold:", 
                  min = 0.1, max = 0.9, value = 0.5, step = 0.05)
    ),
    
    mainPanel(
      width = 9,
      tabsetPanel(
        tabPanel("Probability Curve", 
                 plotOutput("probabilityPlot", height = "500px"),
                 div(class = "well",
                     h4("Understanding the Logistic Curve"),
                     p("This plot shows how the probability of treatment completion changes as predictor values increase."),
                     p("Unlike linear regression, logistic regression models an S-shaped curve that keeps probabilities between 0 and 1."),
                     p("Points represent individual cases, colored by their actual outcome (completed/dropped out).")
                 )),
        
        tabPanel("Classification Results", 
                 plotOutput("classificationPlot", height = "350px"),
                 verbatimTextOutput("confusionMatrix"),
                 div(class = "well",
                     h4("Evaluating Classification Accuracy"),
                     p("The confusion matrix shows correct and incorrect classifications based on your chosen probability threshold."),
                     p("Sensitivity (true positive rate) is the proportion of actual completers correctly identified."),
                     p("Specificity (true negative rate) is the proportion of actual dropouts correctly identified."),
                     p("Adjusting the threshold changes the balance between sensitivity and specificity.")
                 )),
        
        tabPanel("ROC Curve", 
                 plotOutput("rocPlot", height = "500px"),
                 div(class = "well",
                     h4("Receiver Operating Characteristic (ROC) Curve"),
                     p("The ROC curve plots sensitivity vs. (1 - specificity) across all possible threshold values."),
                     p("The area under the curve (AUC) measures overall model discrimination - higher is better."),
                     p("A perfect model has AUC = 1, while a model with no predictive ability has AUC = 0.5 (diagonal line).")
                 )),
        
        tabPanel("Model Results", 
                 verbatimTextOutput("logisticSummary"),
                 plotOutput("oddsRatioPlot", height = "300px"),
                 div(class = "well",
                     h4("Interpreting Logistic Regression Results"),
                     p("The model summary shows coefficient estimates on the log-odds scale."),
                     p("Odds ratios (exp(β)) are often easier to interpret:"),
                     tags$ul(
                       tags$li("OR &gt; 1: Increased odds of completing treatment as predictor increases"),
                       tags$li("OR &lt; 1: Decreased odds of completing treatment as predictor increases"),
                       tags$li("OR = 1: No effect on odds")
                     ),
                     p("For example, an odds ratio of 1.5 means a one-unit increase in the predictor increases the odds of completion by 50%.")
                 ))
      )
    )
  )
)

server &lt;- function(input, output, session) {
  
  # Generate data based on inputs
  simData &lt;- eventReactive(c(input$simulate, input$sampleSize, input$intercept, 
                             input$effect1, input$effect2, input$x1x2_cor), {
    set.seed(sample(1:1000, 1))
    
    n &lt;- input$sampleSize
    
    # Create correlation matrix for predictors
    cor_matrix &lt;- matrix(c(
      1, input$x1x2_cor,
      input$x1x2_cor, 1
    ), nrow = 2, ncol = 2)
    
    # Generate multivariate normal predictors
    mvn_data &lt;- MASS::mvrnorm(n, mu = c(0, 0), Sigma = cor_matrix)
    
    # Convert to data frame
    data &lt;- data.frame(
      symptom_severity = mvn_data[, 1],  # Higher scores = more severe
      motivation = mvn_data[, 2]         # Higher scores = more motivated
    )
    
    # Scale predictors to have mean = 0, sd = 1
    data$symptom_severity &lt;- scale(data$symptom_severity)
    data$motivation &lt;- scale(data$motivation)
    
    # Calculate log odds based on model
    data$log_odds &lt;- input$intercept + 
                    input$effect1 * data$symptom_severity + 
                    input$effect2 * data$motivation
    
    # Convert to probability
    data$probability &lt;- 1 / (1 + exp(-data$log_odds))
    
    # Generate binary outcome (1 = completed, 0 = dropped out)
    data$completed &lt;- rbinom(n, 1, data$probability)
    data$completed_factor &lt;- factor(data$completed, 
                                  levels = c(0, 1), 
                                  labels = c("Dropped out", "Completed"))
    
    # Fit logistic regression model
    model &lt;- glm(completed ~ symptom_severity + motivation, 
                data = data, family = binomial)
    
    # Calculate ROC curve
    roc_obj &lt;- pROC::roc(data$completed, fitted(model))
    
    # Return all results
    return(list(
      data = data,
      model = model,
      roc = roc_obj
    ))
  })
  
  # Probability plot
  output$probabilityPlot &lt;- renderPlot({
    req(simData())
    
    data &lt;- simData()$data
    model &lt;- simData()$model
    
    # Create a grid for prediction curves
    severity_range &lt;- seq(min(data$symptom_severity), max(data$symptom_severity), length.out = 100)
    motivation_range &lt;- seq(min(data$motivation), max(data$motivation), length.out = 100)
    
    # For motivation effect line (varying motivation, fixing severity at mean)
    motivation_grid &lt;- data.frame(
      motivation = motivation_range,
      symptom_severity = 0  # Mean of scaled variable
    )
    motivation_grid$predicted &lt;- predict(model, newdata = motivation_grid, type = "response")
    motivation_grid$variable &lt;- "Motivation"
    
    # For severity effect line (varying severity, fixing motivation at mean)
    severity_grid &lt;- data.frame(
      motivation = 0,  # Mean of scaled variable
      symptom_severity = severity_range
    )
    severity_grid$predicted &lt;- predict(model, newdata = severity_grid, type = "response")
    severity_grid$variable &lt;- "Symptom Severity"
    
    # Combine for plotting
    grid_combined &lt;- rbind(motivation_grid, severity_grid)
    
    # Plot
    ggplot() +
      # Add points for actual data
      geom_point(data = data, 
                aes(x = symptom_severity, y = probability, color = completed_factor),
                alpha = 0.5) +
      
      # Add prediction curves
      geom_line(data = severity_grid,
               aes(x = symptom_severity, y = predicted),
               color = "#d62728", size = 1.5) +
      geom_line(data = motivation_grid,
               aes(x = motivation, y = predicted),
               color = "#2ca02c", size = 1.5) +
      
      # Add threshold line
      geom_hline(yintercept = input$threshold, linetype = "dashed") +
      annotate("text", x = max(data$symptom_severity), y = input$threshold + 0.05,
               label = paste0("Classification Threshold = ", input$threshold),
               hjust = 1) +
      
      # Labels and theme
      labs(title = "Probability of Treatment Completion",
           subtitle = "Effect of Symptom Severity and Motivation",
           x = "Predictor Value (standardized)",
           y = "Probability of Completion",
           color = "Actual Outcome") +
      theme_minimal() +
      theme(
        plot.title = element_text(face = "bold", size = 16),
        axis.title = element_text(size = 14),
        legend.position = "top"
      ) +
      scale_color_manual(values = c("Dropped out" = "#d62728", "Completed" = "#2ca02c")) +
      
      # Add text annotations for curves
      annotate("text", x = 2, y = 0.8, label = "Motivation Effect", color = "#2ca02c", size = 5) +
      annotate("text", x = -2, y = 0.2, label = "Severity Effect", color = "#d62728", size = 5) +
      
      # Set limits
      ylim(0, 1)
  })
  
  # Classification plot
  output$classificationPlot &lt;- renderPlot({
    req(simData())
    
    data &lt;- simData()$data
    model &lt;- simData()$model
    
    # Add predictions based on threshold
    data$predicted_prob &lt;- fitted(model)
    data$predicted &lt;- ifelse(data$predicted_prob &gt;= input$threshold, 1, 0)
    data$predicted_factor &lt;- factor(data$predicted, 
                                  levels = c(0, 1), 
                                  labels = c("Predicted Dropout", "Predicted Completion"))
    
    # Classification accuracy
    data$correct &lt;- data$completed == data$predicted
    
    # Confusion matrix counts
    tp &lt;- sum(data$completed == 1 &amp; data$predicted == 1)  # True positives
    tn &lt;- sum(data$completed == 0 &amp; data$predicted == 0)  # True negatives
    fp &lt;- sum(data$completed == 0 &amp; data$predicted == 1)  # False positives
    fn &lt;- sum(data$completed == 1 &amp; data$predicted == 0)  # False negatives
    
    sensitivity &lt;- tp / (tp + fn)
    specificity &lt;- tn / (tn + fp)
    accuracy &lt;- (tp + tn) / nrow(data)
    
    # Plot
    ggplot(data, aes(x = predicted_prob, fill = correct)) +
      geom_histogram(bins = 30, color = "white", alpha = 0.8) +
      geom_vline(xintercept = input$threshold, linetype = "dashed", size = 1) +
      facet_wrap(~completed_factor, ncol = 1) +
      labs(title = "Classification Results by Actual Outcome",
           subtitle = paste0("Threshold = ", input$threshold, 
                           ", Accuracy = ", round(accuracy * 100, 1), "%",
                           ", Sensitivity = ", round(sensitivity * 100, 1), "%",
                           ", Specificity = ", round(specificity * 100, 1), "%"),
           x = "Predicted Probability of Completion",
           y = "Count",
           fill = "Correct Classification") +
      theme_minimal() +
      theme(
        plot.title = element_text(face = "bold", size = 16),
        axis.title = element_text(size = 14),
        strip.text = element_text(size = 14, face = "bold"),
        legend.position = "top"
      ) +
      scale_fill_manual(values = c("TRUE" = "#2ca02c", "FALSE" = "#d62728"))
  })
  
  # Confusion matrix
  output$confusionMatrix &lt;- renderText({
    req(simData())
    
    data &lt;- simData()$data
    model &lt;- simData()$model
    
    # Add predictions based on threshold
    data$predicted_prob &lt;- fitted(model)
    data$predicted &lt;- ifelse(data$predicted_prob &gt;= input$threshold, 1, 0)
    
    # Confusion matrix counts
    tp &lt;- sum(data$completed == 1 &amp; data$predicted == 1)  # True positives
    tn &lt;- sum(data$completed == 0 &amp; data$predicted == 0)  # True negatives
    fp &lt;- sum(data$completed == 0 &amp; data$predicted == 1)  # False positives
    fn &lt;- sum(data$completed == 1 &amp; data$predicted == 0)  # False negatives
    
    # Calculate metrics
    sensitivity &lt;- tp / (tp + fn)
    specificity &lt;- tn / (tn + fp)
    ppv &lt;- tp / (tp + fp)  # Positive predictive value
    npv &lt;- tn / (tn + fn)  # Negative predictive value
    accuracy &lt;- (tp + tn) / nrow(data)
    
    # Create confusion matrix display
    paste0(
      "Confusion Matrix (Threshold = ", input$threshold, "):\n\n",
      "                 Predicted Outcome\n",
      "Actual Outcome    Dropped Out    Completed    Total\n",
      "------------------------------------------------------\n",
      "Dropped Out       ", sprintf("%-14s", tn), fp, "       ", tn + fp, "\n",
      "Completed         ", sprintf("%-14s", fn), tp, "       ", fn + tp, "\n",
      "------------------------------------------------------\n",
      "Total             ", sprintf("%-14s", tn + fn), tp + fp, "       ", nrow(data), "\n\n",
      
      "Classification Metrics:\n",
      "- Accuracy: ", round(accuracy * 100, 1), "% (overall correct classifications)\n",
      "- Sensitivity: ", round(sensitivity * 100, 1), "% (correctly identified completers)\n",
      "- Specificity: ", round(specificity * 100, 1), "% (correctly identified dropouts)\n",
      "- Positive Predictive Value: ", round(ppv * 100, 1), "% (% of predicted completers who actually completed)\n",
      "- Negative Predictive Value: ", round(npv * 100, 1), "% (% of predicted dropouts who actually dropped out)\n"
    )
  })
  
  # ROC curve
  output$rocPlot &lt;- renderPlot({
    req(simData())
    
    roc_obj &lt;- simData()$roc
    
    # Convert ROC object to data frame for ggplot
    roc_df &lt;- data.frame(
      specificity = 1 - roc_obj$specificities,
      sensitivity = roc_obj$sensitivities
    )
    
    # Get AUC
    auc_value &lt;- auc(roc_obj)
    
    # Calculate coordinates for current threshold
    current_coords &lt;- coords(roc_obj, input$threshold, "threshold")
    
    # Plot
    ggplot(roc_df, aes(x = specificity, y = sensitivity)) +
      # Add reference diagonal line
      geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray") +
      
      # Add ROC curve
      geom_line(color = "steelblue", size = 1.5) +
      
      # Add point for current threshold
      geom_point(aes(x = 1 - current_coords$specificity, y = current_coords$sensitivity), 
                color = "red", size = 4) +
      
      # Add text annotation for current threshold
      annotate("text", x = 1 - current_coords$specificity + 0.05, 
               y = current_coords$sensitivity,
               label = paste0("Threshold = ", input$threshold),
               hjust = 0) +
      
      # Labels and theme
      labs(title = "ROC Curve for Logistic Regression Model",
           subtitle = paste0("AUC = ", round(auc_value, 3)),
           x = "1 - Specificity (False Positive Rate)",
           y = "Sensitivity (True Positive Rate)") +
      theme_minimal() +
      theme(
        plot.title = element_text(face = "bold", size = 16),
        axis.title = element_text(size = 14)
      ) +
      
      # Set limits and aspect ratio
      coord_equal(xlim = c(0, 1), ylim = c(0, 1))
  })
  
  # Logistic regression summary
  output$logisticSummary &lt;- renderPrint({
    req(simData())
    
    model &lt;- simData()$model
    
    # Print model summary
    cat("## Logistic Regression Results\n\n")
    print(summary(model))
    
    # Calculate and print odds ratios
    cat("\n\nOdds Ratios (95% Confidence Intervals):\n")
    
    # Calculate odds ratios and CIs
    coefs &lt;- coef(summary(model))
    odds_ratios &lt;- exp(coefs[, 1])
    ci_lower &lt;- exp(coefs[, 1] - 1.96 * coefs[, 2])
    ci_upper &lt;- exp(coefs[, 1] + 1.96 * coefs[, 2])
    
    for (i in 2:length(odds_ratios)) {  # Skip intercept
      var_name &lt;- names(odds_ratios)[i]
      cat(paste0(var_name, ": ", round(odds_ratios[i], 3), 
                " (", round(ci_lower[i], 3), " - ", round(ci_upper[i], 3), ")\n"))
    }
    
    # Calculate model fit statistics
    null_deviance &lt;- model$null.deviance
    deviance &lt;- model$deviance
    df_null &lt;- model$df.null
    df_residual &lt;- model$df.residual
    
    # Chi-square test
    chi_sq &lt;- null_deviance - deviance
    df_chi &lt;- df_null - df_residual
    p_value &lt;- pchisq(chi_sq, df_chi, lower.tail = FALSE)
    
    # McFadden's R²
    mcfadden_r2 &lt;- 1 - (deviance / null_deviance)
    
    # Print model fit statistics
    cat("\n\nModel Fit Statistics:\n")
    cat(paste0("Chi-square: ", round(chi_sq, 2), ", df = ", df_chi, 
              ", p ", ifelse(p_value &lt; 0.001, "&lt; .001", paste0("= ", round(p_value, 3))), "\n"))
    cat(paste0("McFadden's R²: ", round(mcfadden_r2, 3), "\n"))
    
    # Clinical interpretation
    cat("\n\n## Clinical Interpretation\n\n")
    
    # Overall model
    if (p_value &lt; 0.05) {
      cat("The logistic regression model is statistically significant")
      if (p_value &lt; 0.001) {
        cat(" (p &lt; .001)")
      } else {
        cat(paste0(" (p = ", round(p_value, 3), ")"))
      }
      cat(paste0(", with McFadden's R² = ", round(mcfadden_r2, 3), 
                ", indicating that the predictors collectively account for ",
                round(mcfadden_r2 * 100, 1), "% of the variance in treatment completion.\n\n"))
    } else {
      cat(paste0("The logistic regression model is not statistically significant (p = ", 
                round(p_value, 3), ").\n\n"))
    }
    
    # Symptom severity
    p_sev &lt;- coefs[2, 4]
    or_sev &lt;- odds_ratios[2]
    
    cat("Symptom severity is")
    if (p_sev &lt; 0.05) {
      cat(" a significant predictor of treatment completion")
      if (p_sev &lt; 0.001) {
        cat(" (p &lt; .001)")
      } else {
        cat(paste0(" (p = ", round(p_sev, 3), ")"))
      }
      cat(paste0(". The odds ratio of ", round(or_sev, 2), 
                " indicates that for each one-unit increase in symptom severity, the odds of completing treatment ",
                ifelse(or_sev &gt; 1, "increase", "decrease"), " by ", 
                round(abs(1 - or_sev) * 100, 1), "%.\n\n"))
    } else {
      cat(" not a significant predictor of treatment completion.\n\n")
    }
    
    # Motivation
    p_mot &lt;- coefs[3, 4]
    or_mot &lt;- odds_ratios[3]
    
    cat("Motivation is")
    if (p_mot &lt; 0.05) {
      cat(" a significant predictor of treatment completion")
      if (p_mot &lt; 0.001) {
        cat(" (p &lt; .001)")
      } else {
        cat(paste0(" (p = ", round(p_mot, 3), ")"))
      }
      cat(paste0(". The odds ratio of ", round(or_mot, 2), 
                " indicates that for each one-unit increase in motivation, the odds of completing treatment ",
                ifelse(or_mot &gt; 1, "increase", "decrease"), " by ", 
                round(abs(1 - or_mot) * 100, 1), "%.\n\n"))
    } else {
      cat(" not a significant predictor of treatment completion.\n\n")
    }
    
    # Compare odds ratios
    if (p_sev &lt; 0.05 &amp;&amp; p_mot &lt; 0.05) {
      stronger_pred &lt;- ifelse(abs(log(or_sev)) &gt; abs(log(or_mot)), 
                             "symptom severity", "motivation")
      cat(paste0("Based on the magnitude of effects, ", stronger_pred, 
                " appears to be the stronger predictor of treatment completion."))
    }
  })
  
  # Odds ratio plot
  output$oddsRatioPlot &lt;- renderPlot({
    req(simData())
    
    model &lt;- simData()$model
    
    # Calculate odds ratios and CIs
    coefs &lt;- coef(summary(model))
    odds_ratios &lt;- exp(coefs[, 1])
    ci_lower &lt;- exp(coefs[, 1] - 1.96 * coefs[, 2])
    ci_upper &lt;- exp(coefs[, 1] + 1.96 * coefs[, 2])
    
    # Create a data frame for plotting (excluding intercept)
    or_data &lt;- data.frame(
      predictor = names(odds_ratios)[-1],  # Exclude intercept
      odds_ratio = odds_ratios[-1],
      lower_ci = ci_lower[-1],
      upper_ci = ci_upper[-1],
      p_value = coefs[-1, 4]
    )
    
    # Fix predictor names for display
    or_data$predictor &lt;- gsub("symptom_severity", "Symptom Severity", or_data$predictor)
    or_data$predictor &lt;- gsub("motivation", "Motivation", or_data$predictor)
    
    # Determine significance for coloring
    or_data$significant &lt;- or_data$p_value &lt; 0.05
    
    # Plot
    ggplot(or_data, aes(x = predictor, y = odds_ratio, color = significant)) +
      # Add reference line at OR = 1
      geom_hline(yintercept = 1, linetype = "dashed", color = "gray") +
      
      # Add point and error bars
      geom_point(size = 5) +
      geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.2, size = 1.2) +
      
      # Add text annotations for OR values
      geom_text(aes(label = paste0("OR = ", round(odds_ratio, 2))), 
               vjust = -0.8, size = 4) +
      
      # Labels and theme
      labs(title = "Odds Ratios with 95% Confidence Intervals",
           subtitle = "Values &gt; 1 indicate increased odds of treatment completion",
           x = "",
           y = "Odds Ratio (log scale)") +
      theme_minimal() +
      theme(
        legend.position = "none",
        plot.title = element_text(face = "bold", size = 16),
        axis.text.x = element_text(size = 12),
        axis.title.y = element_text(size = 14)
      ) +
      scale_color_manual(values = c("TRUE" = "#2ca02c", "FALSE" = "#dc3545")) +
      
      # Use log scale for y-axis to better show relative effects
      scale_y_log10(breaks = c(0.1, 0.2, 0.5, 1, 2, 5, 10))
  })
}

shinyApp(ui, server)</code></pre>
</div>
<p>Use this interactive application to explore how predictors affect the probability of a binary outcome and how logistic regression differs from linear regression.</p>
</section>
</section>
<section id="summary-2" class="level2">
<h2 class="anchored" data-anchor-id="summary-2">4.5 Summary</h2>
<p>Regression analysis is a versatile statistical approach for examining relationships between variables. Key points to remember:</p>
<ul>
<li>Simple linear regression examines the relationship between one independent variable and one dependent variable</li>
<li>Multiple regression extends this to multiple independent variables</li>
<li>Logistic regression handles binary dependent variables</li>
<li>Regression can be used for both prediction and explanation</li>
<li>Interpretation focuses on regression coefficients, statistical significance, and measures of model fit</li>
</ul>
<p>In the next chapter, we’ll explore mediation and moderation analysis, which builds on regression to examine more complex relationships between variables.</p>
<pre class="shinylive-r" data-engine="r"><code>#| '!! shinylive warning !!': |
#|   shinylive does not work in self-contained HTML documents.
#|   Please set `embed-resources: false` in your metadata.
#| standalone: true
#| viewerHeight: 700

library(shiny)
library(shinyjs)

ui &lt;- fluidPage(
  useShinyjs(),
  tags$head(
    tags$style(HTML("
      .quiz-container {
        max-width: 800px;
        margin: 0 auto;
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 20px;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
      }
      .question {
        margin-bottom: 30px;
        padding-bottom: 20px;
        border-bottom: 1px solid #dee2e6;
      }
      .question-title {
        font-weight: bold;
        margin-bottom: 15px;
        color: #212529;
      }
      .feedback {
        margin-top: 15px;
        padding: 15px;
        border-radius: 5px;
      }
      .correct {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
      }
      .incorrect {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
      }
      .panel-heading {
        background-color: #6c757d;
        color: white;
        padding: 10px 15px;
        border-radius: 5px 5px 0 0;
      }
      .panel-body {
        background-color: white;
        padding: 15px;
        border: 1px solid #dee2e6;
        border-top: none;
        border-radius: 0 0 5px 5px;
      }
      .result-container {
        margin-top: 20px;
        text-align: center;
      }
      .btn-submit-answer {
        margin-top: 10px;
      }
      .explanation {
        font-style: italic;
        margin-top: 10px;
      }
    "))
  ),
  
  div(class = "container-fluid",
      div(class = "row",
          div(class = "col-md-12",
              div(class = "quiz-container",
                  
                  # Quiz header
                  div(class = "panel-heading",
                      h2("Chapter 4 Quiz: Relationships Between Variables", style = "margin-top: 0;")
                  ),
                  
                  div(class = "panel-body",
                      p("Test your understanding of regression analysis. For each question, select the best answer and click 'Submit' to see feedback."),
                      
                      # Question 1
                      div(class = "question", id = "q1_container",
                          div(class = "question-title", "Question 1: Simple Linear Regression"),
                          p("A researcher wants to examine whether the number of therapy sessions predicts reduction in anxiety symptoms. What type of analysis is most appropriate?"),
                          
                          radioButtons("q1", NULL, 
                                     choices = c(
                                       "Simple linear regression" = "correct",
                                       "Chi-square test" = "incorrect1",
                                       "One-way ANOVA" = "incorrect2",
                                       "Independent samples t-test" = "incorrect3"
                                     )),
                          actionButton("check1", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback1")
                      ),
                      
                      # Question 2
                      div(class = "question", id = "q2_container",
                          div(class = "question-title", "Question 2: Interpreting Regression Coefficients"),
                          p("In a simple linear regression predicting depression scores from social support, the model is: Depression = 25 - 0.8 × Social Support. How would you interpret the coefficient -0.8?"),
                          
                          radioButtons("q2", NULL, 
                                     choices = c(
                                       "For each one-unit increase in social support, depression scores decrease by 0.8 points on average." = "correct",
                                       "For each one-unit increase in depression, social support decreases by 0.8 points on average." = "incorrect1",
                                       "Depression and social support have a weak negative correlation of -0.8." = "incorrect2",
                                       "80% of the variation in depression scores is explained by social support." = "incorrect3"
                                     )),
                          actionButton("check2", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback2")
                      ),
                      
                      # Question 3
                      div(class = "question", id = "q3_container",
                          div(class = "question-title", "Question 3: Multiple Regression"),
                          p("A multiple regression analysis predicting therapy outcomes includes pre-treatment severity, therapeutic alliance, and motivation as predictors, with R² = 0.42. What does this value tell us?"),
                          
                          radioButtons("q3", NULL, 
                                     choices = c(
                                       "The three predictors collectively explain 42% of the variance in therapy outcomes." = "correct",
                                       "The three predictors are 42% accurate in predicting therapy outcomes." = "incorrect1",
                                       "There is a 42% chance that the regression model is correctly specified." = "incorrect2", 
                                       "The correlation between the predictors and therapy outcomes is 0.42." = "incorrect3"
                                     )),
                          actionButton("check3", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback3")
                      ),
                      
                      # Question 4
                      div(class = "question", id = "q4_container",
                          div(class = "question-title", "Question 4: Assumptions of Regression"),
                          p("Which of the following is NOT an assumption of simple linear regression?"),
                          
                          radioButtons("q4", NULL, 
                                     choices = c(
                                       "The predictor and outcome variables are normally distributed." = "correct",
                                       "The relationship between variables is linear." = "incorrect1",
                                       "Observations are independent of each other." = "incorrect2",
                                       "The variance of residuals is consistent across all values of the predictor (homoscedasticity)." = "incorrect3"
                                     )),
                          actionButton("check4", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback4")
                      ),
                      
                      # Question 5
                      div(class = "question", id = "q5_container",
                          div(class = "question-title", "Question 5: Logistic Regression"),
                          p("In a logistic regression predicting treatment completion (yes/no), the odds ratio for motivation is 1.75. What does this mean?"),
                          
                          radioButtons("q5", NULL, 
                                     choices = c(
                                       "For each one-unit increase in motivation, the odds of completing treatment increase by 75%." = "correct",
                                       "Clients who complete treatment are 1.75 times more motivated than those who don't." = "incorrect1",
                                       "There is a 75% probability that motivated clients will complete treatment." = "incorrect2",
                                       "The correlation between motivation and treatment completion is 0.75." = "incorrect3"
                                     )),
                          actionButton("check5", "Submit Answer", class = "btn-primary btn-submit-answer"),
                          htmlOutput("feedback5")
                      ),
                      
                      # Score display
                      div(id = "score_section", class = "result-container",
                          actionButton("calculate_score", "Calculate My Score", class = "btn-success btn-lg"),
                          htmlOutput("final_score")
                      )
                  )
              )
          )
      )
  )
)

server &lt;- function(input, output, session) {
  
  # Initialize score tracking
  score &lt;- reactiveVal(0)
  answered &lt;- reactiveVal(rep(FALSE, 5))
  
  # Question 1 feedback
  observeEvent(input$check1, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[1] &lt;- TRUE
    answered(current_answered)
    
    # Check if correct and update score
    is_correct &lt;- input$q1 == "correct"
    if(is_correct) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback1 &lt;- renderUI({
      if(is_correct) {
        div(class = "feedback correct",
            h4("Correct!"),
            p(class = "explanation", "Simple linear regression is the appropriate analysis when examining the relationship between one continuous predictor variable (number of therapy sessions) and one continuous outcome variable (reduction in anxiety symptoms). It would allow the researcher to determine whether more sessions predict greater symptom reduction and quantify this relationship.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "When examining the relationship between two continuous variables, simple linear regression is the appropriate choice. Chi-square tests are for categorical variables, ANOVA compares means across three or more groups, and t-tests compare means between two groups. None of these would address the research question about the relationship between therapy sessions and anxiety reduction.")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check1")
  })
  
  # Question 2 feedback
  observeEvent(input$check2, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[2] &lt;- TRUE
    answered(current_answered)
    
    # Check if correct and update score
    is_correct &lt;- input$q2 == "correct"
    if(is_correct) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback2 &lt;- renderUI({
      if(is_correct) {
        div(class = "feedback correct",
            h4("Correct!"),
            p(class = "explanation", "In regression, the coefficient represents the change in the outcome variable associated with a one-unit change in the predictor variable. The negative sign indicates an inverse relationship: as social support increases, depression scores decrease. Specifically, each additional point on the social support measure is associated with a 0.8-point decrease in depression scores, on average.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "The regression coefficient (-0.8) in the equation Depression = 25 - 0.8 × Social Support specifically indicates how much the outcome variable (Depression) changes for each one-unit increase in the predictor (Social Support). It doesn't indicate the correlation between variables, the percentage of variance explained (that would be R²), or the reverse relationship. In this case, the negative coefficient means that higher social support is associated with lower depression scores.")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check2")
  })
  
  # Question 3 feedback
  observeEvent(input$check3, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[3] &lt;- TRUE
    answered(current_answered)
    
    # Check if correct and update score
    is_correct &lt;- input$q3 == "correct"
    if(is_correct) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback3 &lt;- renderUI({
      if(is_correct) {
        div(class = "feedback correct",
            h4("Correct!"),
            p(class = "explanation", "R² (coefficient of determination) represents the proportion of variance in the outcome variable that is explained by the predictor variables in the regression model. In this case, R² = 0.42 means that 42% of the variability in therapy outcomes can be explained by the three predictors collectively (pre-treatment severity, therapeutic alliance, and motivation). The remaining 58% of variance is due to factors not included in the model or random variation.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "R² specifically represents the proportion of variance in the outcome variable explained by the predictors in the model. It is not a measure of accuracy, probability of correct specification, or correlation. The value 0.42 means that 42% of the variability in therapy outcomes is accounted for by the three predictors together, while 58% is due to other factors not included in the model.")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check3")
  })
  
  # Question 4 feedback
  observeEvent(input$check4, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[4] &lt;- TRUE
    answered(current_answered)
    
    # Check if correct and update score
    is_correct &lt;- input$q4 == "correct"
    if(is_correct) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback4 &lt;- renderUI({
      if(is_correct) {
        div(class = "feedback correct",
            h4("Correct!"),
            p(class = "explanation", "Linear regression does NOT assume that the predictor and outcome variables themselves are normally distributed. Rather, it assumes that the residuals (errors) follow a normal distribution. The other assumptions listed—linearity, independence of observations, and homoscedasticity (constant variance of residuals)—are indeed key assumptions of simple linear regression.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "Linear regression does not require that the predictor or outcome variables themselves follow a normal distribution—only that the residuals (errors) are normally distributed. The other options all represent true assumptions of linear regression: the relationship between variables should be linear, observations should be independent of each other, and the variance of residuals should be consistent across all values of the predictor (homoscedasticity).")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check4")
  })
  
  # Question 5 feedback
  observeEvent(input$check5, {
    # Update answered status
    current_answered &lt;- answered()
    current_answered[5] &lt;- TRUE
    answered(current_answered)
    
    # Check if correct and update score
    is_correct &lt;- input$q5 == "correct"
    if(is_correct) {
      score(score() + 1)
    }
    
    # Generate feedback
    output$feedback5 &lt;- renderUI({
      if(is_correct) {
        div(class = "feedback correct",
            h4("Correct!"),
            p(class = "explanation", "In logistic regression, the odds ratio represents the multiplicative change in odds associated with a one-unit change in the predictor. An odds ratio of 1.75 for motivation means that for each one-unit increase in motivation, the odds of completing treatment are multiplied by 1.75, which represents a 75% increase in odds. This is calculated as (1.75 - 1) × 100% = 75%. Odds ratios greater than 1 indicate that higher values of the predictor are associated with higher odds of the outcome occurring.")
        )
      } else {
        div(class = "feedback incorrect",
            h4("Not quite right."),
            p(class = "explanation", "An odds ratio of 1.75 specifically means that for each one-unit increase in motivation, the odds of completing treatment increase by 75%. It does not directly compare motivation levels between completers and non-completers, indicate probability of completion, or represent a correlation coefficient. In logistic regression, odds ratios are the standard way to interpret the strength and direction of relationships between predictors and the binary outcome.")
        )
      }
    })
    
    # Disable the button after clicking
    disable("check5")
  })
  
  # Calculate and display final score
  observeEvent(input$calculate_score, {
    # Check if all questions have been answered
    if(!all(answered())) {
      output$final_score &lt;- renderUI({
        div(class = "alert alert-warning",
            h4("Please answer all questions first!"),
            p("Make sure you've submitted an answer for each question before calculating your score.")
        )
      })
      return()
    }
    
    # Calculate percentage
    total &lt;- 5
    current_score &lt;- score()
    percentage &lt;- round((current_score / total) * 100)
    
    # Generate feedback based on score
    feedback &lt;- if(percentage &gt;= 80) {
      "Excellent work! You have a strong understanding of regression analysis and its applications in clinical psychology."
    } else if(percentage &gt;= 60) {
      "Good job! You understand many key concepts about regression, but might want to review some areas to strengthen your understanding."
    } else {
      "You might benefit from reviewing this chapter again to strengthen your understanding of regression concepts."
    }
    
    # Display score and feedback
    output$final_score &lt;- renderUI({
      div(class = "well well-lg",
          h3(paste0("Your Score: ", current_score, "/", total, " (", percentage, "%)")),
          p(feedback),
          if(percentage &lt; 100) {
            p("Review the questions you missed and the explanations provided to deepen your understanding.")
          } else {
            p("Perfect score! You're well-prepared to move on to the next chapter on mediation and moderation analysis.")
          }
      )
    })
    
    # Disable the button after clicking
    disable("calculate_score")
  })
}

shinyApp(ui, server)</code></pre>
<hr>
</section>
</section>
<section id="mediation-and-moderation-analysis" class="level1 unnumbered">
<h1 class="unnumbered">5. Mediation and Moderation Analysis</h1>
<div class="key-concepts">
<p><strong>Key Concepts:</strong></p>
<ul>
<li>Mediation analysis for examining indirect effects through intervening variables</li>
<li>Moderation analysis for examining how relationships depend on other variables</li>
<li>Steps for testing mediation and moderation</li>
<li>Bootstrapping for confidence intervals in mediation</li>
<li>Simple slopes analysis for interpreting moderating effects</li>
<li>Conditional process models combining mediation and moderation</li>
<li>Theoretical and practical considerations in mediation and moderation analysis</li>
</ul>
</div>
<section id="introduction-to-mediation-and-moderation" class="level2">
<h2 class="anchored" data-anchor-id="introduction-to-mediation-and-moderation">5.1 Introduction to Mediation and Moderation</h2>
<p>Mediation and moderation analyses allow researchers to move beyond simple relationships to explore more complex explanatory models. These approaches are particularly valuable in clinical psychology, where understanding mechanisms of change and contextual factors is crucial.</p>
<div class="margin-note">
<p>Mediation and moderation answer different kinds of questions: mediation addresses “how” or “through what process,” while moderation addresses “when” or “for whom.”</p>
</div>
</section>
<section id="mediation-analysis" class="level2">
<h2 class="anchored" data-anchor-id="mediation-analysis">5.2 Mediation Analysis</h2>
<p>Mediation analysis examines the process or mechanism through which one variable affects another via an intervening variable.</p>
<div class="definition">
<p><strong>Mediation:</strong> A process where the effect of an independent variable (X) on a dependent variable (Y) occurs through an intervening variable (M), called a mediator.</p>
</div>
<section id="the-mediation-model" class="level3">
<h3 class="anchored" data-anchor-id="the-mediation-model">5.2.1 The Mediation Model</h3>
<p>A simple mediation model involves three variables:</p>
<ul>
<li>Independent variable (X)</li>
<li>Dependent variable (Y)</li>
<li>Mediator (M)</li>
</ul>
<p>The model examines three key paths:</p>
<ul>
<li><strong>a path:</strong> The effect of X on M</li>
<li><strong>b path:</strong> The effect of M on Y, controlling for X</li>
<li><strong>c path:</strong> The total effect of X on Y</li>
<li><strong>c’ path:</strong> The direct effect of X on Y, controlling for M</li>
</ul>
<p>The <strong>indirect effect</strong> (the mediated effect) is the product of the a and b paths (a × b).</p>
<div class="example">
<p><strong>Clinical Example:</strong> A researcher examines whether the effect of cognitive-behavioral therapy (X) on depression reduction (Y) is mediated by changes in negative thinking patterns (M). The mediation model tests whether therapy reduces negative thinking (a path), whether reduced negative thinking leads to reduced depression (b path), and whether the effect of therapy on depression operates through this mechanism.</p>
</div>
</section>
<section id="testing-mediation" class="level3">
<h3 class="anchored" data-anchor-id="testing-mediation">5.2.2 Testing Mediation</h3>
<p>Several approaches exist for testing mediation:</p>
<ol type="1">
<li><p><strong>Baron and Kenny’s causal steps approach:</strong></p>
<ul>
<li>Step 1: Show that X significantly predicts Y (c path)</li>
<li>Step 2: Show that X significantly predicts M (a path)</li>
<li>Step 3: Show that M significantly predicts Y, controlling for X (b path)</li>
<li>Step 4: Show that the effect of X on Y is reduced when controlling for M (c’ path compared to c path)</li>
</ul></li>
<li><p><strong>Bootstrapping approach (recommended):</strong></p>
<ul>
<li>Estimate the indirect effect (a × b)</li>
<li>Generate a bootstrap confidence interval for the indirect effect</li>
<li>If the confidence interval does not include zero, there is evidence of mediation</li>
</ul></li>
</ol>
<div class="margin-note">
<p>The bootstrapping approach is generally preferred because it doesn’t assume normality of the sampling distribution of the indirect effect and has higher power than the causal steps approach.</p>
</div>
</section>
<section id="types-of-mediation" class="level3">
<h3 class="anchored" data-anchor-id="types-of-mediation">5.2.3 Types of Mediation</h3>
<p>Different patterns of results can occur in mediation analysis:</p>
<ol type="1">
<li><p><strong>Complete (full) mediation:</strong> The direct effect (c’) becomes non-significant when the mediator is included, suggesting that the mediator fully explains the relationship between X and Y.</p></li>
<li><p><strong>Partial mediation:</strong> The direct effect (c’) remains significant but is reduced when the mediator is included, suggesting that the mediator partially explains the relationship.</p></li>
<li><p><strong>Indirect-only mediation:</strong> X has no significant total effect on Y, but there is a significant indirect effect through M. (Note: Historically, a significant total effect was considered necessary, but modern approaches recognize that mediation can occur without a significant total effect.)</p></li>
</ol>
<div class="margin-note">
<p>Complete vs.&nbsp;partial mediation is not a dichotomy but a continuum. Most psychological processes involve multiple mediators.</p>
</div>
</section>
<section id="statistical-power-and-sample-size" class="level3">
<h3 class="anchored" data-anchor-id="statistical-power-and-sample-size">5.2.4 Statistical Power and Sample Size</h3>
<p>Mediation analysis typically requires larger sample sizes than simple regression or t-tests:</p>
<ul>
<li>The a and b paths both need to be detected</li>
<li>Power depends on the relative sizes of the a and b effects</li>
<li>Sample size requirements increase for smaller expected effects</li>
</ul>
<div class="margin-note">
<p>As a rough guideline, samples of at least 100-150 are often recommended for detecting medium-sized mediation effects.</p>
</div>
</section>
<section id="causal-inference-in-mediation" class="level3">
<h3 class="anchored" data-anchor-id="causal-inference-in-mediation">5.2.5 Causal Inference in Mediation</h3>
<p>Mediation implies a causal process, but correlation-based mediation analysis has limitations for causal inference:</p>
<ul>
<li>Temporal precedence needs to be established (X before M before Y)</li>
<li>Unmeasured confounders can bias estimates</li>
<li>Alternative models (e.g., reverse causation) need to be ruled out</li>
</ul>
<p>Stronger causal inference can be supported by:</p>
<ul>
<li>Experimental manipulation of X</li>
<li>Experimental manipulation of M (to test the b path)</li>
<li>Longitudinal designs with appropriate measurement timing</li>
</ul>
<div class="example">
<p><strong>Causal Inference Example:</strong> To strengthen causal inference in the therapy example, a researcher could randomly assign participants to CBT vs.&nbsp;control (manipulating X), measure negative thinking patterns at multiple time points during treatment (establishing temporal precedence of changes in M before changes in Y), and potentially manipulate negative thinking directly in a separate study (to test the b path).</p>
</div>
<p>[INTERACTIVE APPLICATION 11: Mediation Analysis Visualization]</p>
<p>Use this interactive application to explore how different values of the a, b, and c’ paths affect the total effect and the proportion mediated.</p>
</section>
</section>
<section id="moderation-analysis" class="level2">
<h2 class="anchored" data-anchor-id="moderation-analysis">5.3 Moderation Analysis</h2>
<p>Moderation analysis examines how the relationship between two variables depends on a third variable.</p>
<div class="definition">
<p><strong>Moderation:</strong> A process where the relationship between an independent variable (X) and a dependent variable (Y) changes as a function of a third variable (Z), called a moderator.</p>
</div>
<div class="margin-note">
<p>Moderators address questions about when or for whom a relationship holds or is strongest. They help identify boundary conditions for effects.</p>
</div>
<section id="the-moderation-model" class="level3">
<h3 class="anchored" data-anchor-id="the-moderation-model">5.3.1 The Moderation Model</h3>
<p>A moderation model tests whether the effect of X on Y depends on Z. This is represented as an interaction effect in a regression model:</p>
<p>Y = β₀ + β₁X + β₂Z + β₃(X × Z) + ε</p>
<p>Where:</p>
<ul>
<li>β₁ is the effect of X when Z = 0</li>
<li>β₂ is the effect of Z when X = 0</li>
<li>β₃ is the interaction effect, representing how the effect of X on Y changes as Z changes</li>
</ul>
<div class="example">
<p><strong>Clinical Example:</strong> A researcher examines whether the effectiveness of exposure therapy (X) on reducing anxiety (Y) depends on the client’s level of distress tolerance (Z). The moderation model tests whether the effect of exposure therapy is stronger for clients with higher distress tolerance (a positive interaction).</p>
</div>
</section>
<section id="testing-moderation" class="level3">
<h3 class="anchored" data-anchor-id="testing-moderation">5.3.2 Testing Moderation</h3>
<p>Testing moderation involves these steps:</p>
<ol type="1">
<li>Create an interaction term by multiplying X and Z</li>
<li>Run a regression analysis with X, Z, and the X × Z interaction as predictors</li>
<li>Examine the significance of the interaction term (β₃)</li>
<li>If significant, probe the interaction to understand its nature</li>
</ol>
<div class="margin-note">
<p>It’s generally recommended to center continuous predictors (subtract the mean) before creating interaction terms to reduce multicollinearity and make the main effects more interpretable.</p>
</div>
</section>
<section id="probing-and-interpreting-interactions" class="level3">
<h3 class="anchored" data-anchor-id="probing-and-interpreting-interactions">5.3.3 Probing and Interpreting Interactions</h3>
<p>If a significant interaction is found, there are several ways to probe and interpret it:</p>
<ol type="1">
<li><p><strong>Simple slopes analysis:</strong> Examine the effect of X on Y at different values of Z (typically at the mean and 0B1 1 SD)</p></li>
<li><p><strong>Johnson-Neyman technique:</strong> Identify the region(s) of Z where the effect of X on Y is significant</p></li>
<li><p><strong>Interaction plots:</strong> Graph the relationship between X and Y at different levels of Z to visualize the moderation effect</p></li>
</ol>
<div class="example">
<p><strong>Interpretation Example:</strong> “The interaction between exposure therapy and distress tolerance was significant (β = 0.32, p = .01). Simple slopes analysis revealed that exposure therapy was effective for clients with high distress tolerance (β = 0.45, p &lt; .001) but not for those with low distress tolerance (β = 0.09, p = .42). This suggests that distress tolerance may be an important prerequisite for benefiting from exposure therapy.”</p>
</div>
</section>
<section id="types-of-moderators" class="level3">
<h3 class="anchored" data-anchor-id="types-of-moderators">5.3.4 Types of Moderators</h3>
<p>In clinical psychology, several types of variables might serve as moderators:</p>
<ol type="1">
<li><strong>Client characteristics:</strong> Demographic variables (age, gender), personality traits, comorbidities</li>
<li><strong>Therapist characteristics:</strong> Experience, therapeutic style, cultural background</li>
<li><strong>Treatment variables:</strong> Dose, delivery format, setting</li>
<li><strong>Contextual factors:</strong> Social support, life stressors, cultural context</li>
</ol>
<p>Examining moderators can help refine clinical practices by identifying which interventions work best for which clients under which circumstances.</p>
<p>[INTERACTIVE APPLICATION 12: Moderation Analysis Visualization]</p>
<p>Use this interactive application to explore how different interaction patterns affect the relationship between the independent and dependent variables at different levels of the moderator.</p>
</section>
</section>
<section id="conditional-process-models" class="level2">
<h2 class="anchored" data-anchor-id="conditional-process-models">5.4 Conditional Process Models</h2>
<p>Conditional process models (also known as moderated mediation or mediated moderation) combine mediation and moderation to examine more complex theoretical processes.</p>
<div class="definition">
<p><strong>Conditional Process Model:</strong> A model that combines mediation and moderation, examining how indirect effects may be conditional on the value of a moderator.</p>
</div>
<section id="examples-of-conditional-process-models" class="level3">
<h3 class="anchored" data-anchor-id="examples-of-conditional-process-models">5.4.1 Examples of Conditional Process Models</h3>
<p>Several types of conditional process models are possible:</p>
<ol type="1">
<li><p><strong>Moderated mediation:</strong> The indirect effect (a × b) varies depending on the level of a moderator. The moderator could affect:</p>
<ul>
<li>The a path (X → M)</li>
<li>The b path (M → Y)</li>
<li>Both paths</li>
</ul></li>
<li><p><strong>Mediated moderation:</strong> A significant interaction effect (moderation) is mediated by an intervening variable.</p></li>
</ol>
<div class="example">
<p><strong>Clinical Example (Moderated Mediation):</strong> A researcher examines whether the effectiveness of CBT (X) on reducing depression (Y) through changing negative thinking patterns (M) depends on the client’s level of homework compliance (Z). The model tests whether the indirect effect of CBT on depression through negative thinking is stronger for clients who complete more homework assignments.</p>
</div>
</section>
<section id="testing-conditional-process-models" class="level3">
<h3 class="anchored" data-anchor-id="testing-conditional-process-models">5.4.2 Testing Conditional Process Models</h3>
<p>Testing conditional process models involves:</p>
<ol type="1">
<li>Specifying the theoretical model and which paths are moderated</li>
<li>Estimating the model using regression or structural equation modeling</li>
<li>Testing the conditional indirect effect at different values of the moderator</li>
<li>Constructing bootstrap confidence intervals for the conditional indirect effects</li>
</ol>
<div class="margin-note">
<p>Hayes’ PROCESS macro for SPSS and other statistical software provides templates for various conditional process models and simplifies the analysis.</p>
</div>
</section>
<section id="index-of-moderated-mediation" class="level3">
<h3 class="anchored" data-anchor-id="index-of-moderated-mediation">5.4.3 Index of Moderated Mediation</h3>
<p>The index of moderated mediation is a single value that quantifies the association between the moderator and the indirect effect. If the confidence interval for this index does not include zero, there is evidence that the indirect effect is moderated.</p>
<div class="example">
<p><strong>Interpretation Example:</strong> “The index of moderated mediation was significant (index = 0.15, 95% CI [0.04, 0.29]), indicating that the indirect effect of CBT on depression through negative thinking was moderated by homework compliance. The indirect effect was significant for clients with high compliance (effect = 0.28, 95% CI [0.12, 0.47]) but not for those with low compliance (effect = 0.05, 95% CI [-0.08, 0.18]).”</p>
</div>
<p>[INTERACTIVE APPLICATION 13: Conditional Process Model Visualization]</p>
<p>Use this interactive application to explore conditional process models and understand how the indirect effect can depend on the level of a moderator.</p>
</section>
</section>
<section id="practical-considerations" class="level2">
<h2 class="anchored" data-anchor-id="practical-considerations">5.5 Practical Considerations</h2>
<section id="sample-size-and-power" class="level3">
<h3 class="anchored" data-anchor-id="sample-size-and-power">5.5.1 Sample Size and Power</h3>
<p>Mediation, moderation, and conditional process models require larger sample sizes than simpler analyses:</p>
<ul>
<li>Interactions (moderation) are typically lower in power than main effects</li>
<li>Indirect effects (mediation) involve the product of two effects</li>
<li>Conditional process models combine both challenges</li>
</ul>
<div class="margin-note">
<p>Power analysis software or Monte Carlo simulations can help determine appropriate sample sizes for these analyses.</p>
</div>
</section>
<section id="measurement-quality" class="level3">
<h3 class="anchored" data-anchor-id="measurement-quality">5.5.2 Measurement Quality</h3>
<p>The quality of measurement is particularly important for mediation and moderation analyses:</p>
<ul>
<li>Unreliable measures can substantially reduce power</li>
<li>Measurement timing is crucial for mediation (X should precede M, which should precede Y)</li>
<li>The conceptual meaning of moderator variables should be clear for interpretation</li>
</ul>
</section>
<section id="theory-driven-vs.-exploratory-analysis" class="level3">
<h3 class="anchored" data-anchor-id="theory-driven-vs.-exploratory-analysis">5.5.3 Theory-Driven vs.&nbsp;Exploratory Analysis</h3>
<p>Mediation and moderation analyses should ideally be theory-driven:</p>
<ul>
<li>Hypotheses should be based on theoretical frameworks or prior research</li>
<li>Exploratory analyses should be clearly labeled as such</li>
<li>Multiple testing increases the risk of Type I errors</li>
</ul>
</section>
<section id="reporting-results" class="level3">
<h3 class="anchored" data-anchor-id="reporting-results">5.5.4 Reporting Results</h3>
<p>When reporting mediation and moderation analyses, include:</p>
<ul>
<li>Theoretical rationale for the model</li>
<li>Detailed description of the analysis approach</li>
<li>All relevant path coefficients and their significance</li>
<li>Confidence intervals for indirect effects</li>
<li>Visual representations (path diagrams, interaction plots)</li>
</ul>
</section>
</section>
<section id="summary-3" class="level2">
<h2 class="anchored" data-anchor-id="summary-3">5.6 Summary</h2>
<p>Mediation and moderation analyses allow researchers to move beyond simple relationships to examine more complex processes. Key points to remember:</p>
<ul>
<li>Mediation examines how one variable affects another through an intervening variable</li>
<li>Moderation examines how the relationship between two variables depends on a third variable</li>
<li>Bootstrapping is the preferred approach for testing indirect effects in mediation</li>
<li>Simple slopes analysis helps interpret significant interactions in moderation</li>
<li>Conditional process models combine mediation and moderation</li>
<li>These analyses require careful theoretical grounding and adequate sample sizes</li>
</ul>
<div class="practice">
<p><strong>Practice Questions:</strong></p>
<ol type="1">
<li><p>A researcher hypothesizes that mindfulness training reduces anxiety by increasing emotion regulation. What type of model is this, and what statistical approach would be appropriate to test it?</p></li>
<li><p>Explain the difference between moderation and mediation. How do they address different types of research questions?</p></li>
<li><p>A study finds that the effect of a trauma intervention on PTSD symptoms is significant for adults but not for adolescents. What type of analysis would formally test this pattern?</p></li>
<li><p>Why is bootstrapping preferred over the traditional causal steps approach for testing mediation?</p></li>
</ol>
</div>
<hr>
</section>
</section>
<section id="practical-considerations-1" class="level1 unnumbered">
<h1 class="unnumbered">6. Practical Considerations</h1>
<div class="key-concepts">
<p><strong>Key Concepts:</strong></p>
<ul>
<li>Statistical power and sample size planning</li>
<li>Missing data: mechanisms and handling strategies</li>
<li>Effect size interpretation in clinical contexts</li>
<li>Reporting results in APA format</li>
<li>Common misinterpretations of statistical tests</li>
<li>Balancing statistical and clinical significance</li>
</ul>
</div>
<section id="statistical-power-and-sample-size-planning" class="level2">
<h2 class="anchored" data-anchor-id="statistical-power-and-sample-size-planning">6.1 Statistical Power and Sample Size Planning</h2>
<p>Statistical power is the probability of detecting an effect when it truly exists. Adequate power is crucial for drawing valid conclusions from research.</p>
<div class="definition">
<p><strong>Statistical Power:</strong> The probability that a statistical test will correctly reject the null hypothesis when the alternative hypothesis is true.</p>
</div>
<div class="margin-note">
<p>The conventional target for statistical power is 0.80, meaning an 80% chance of detecting an effect if it exists.</p>
</div>
<section id="factors-affecting-statistical-power" class="level3">
<h3 class="anchored" data-anchor-id="factors-affecting-statistical-power">6.1.1 Factors Affecting Statistical Power</h3>
<p>Several factors influence statistical power:</p>
<ol type="1">
<li><strong>Sample size:</strong> Larger samples increase power</li>
<li><strong>Effect size:</strong> Larger effects are easier to detect</li>
<li><strong>Significance level (3B1):</strong> Less stringent significance levels increase power</li>
<li><strong>Research design:</strong> Within-subjects designs typically have higher power than between-subjects designs</li>
<li><strong>Measurement reliability:</strong> More reliable measures increase power</li>
<li><strong>Analysis method:</strong> Some statistical approaches have higher power than others</li>
</ol>
</section>
<section id="a-priori-power-analysis" class="level3">
<h3 class="anchored" data-anchor-id="a-priori-power-analysis">6.1.2 A Priori Power Analysis</h3>
<p>A priori power analysis involves determining the necessary sample size before conducting a study:</p>
<ol type="1">
<li>Specify the statistical test to be used</li>
<li>Determine the desired power (typically 0.80)</li>
<li>Set the significance level (typically 3B1 = 0.05)</li>
<li>Estimate the expected effect size based on prior research or theoretical considerations</li>
<li>Calculate the required sample size</li>
</ol>
<div class="margin-note">
<p>Effect size estimates for power analysis can be based on previous studies, meta-analyses, or meaningful clinical differences when other information is unavailable.</p>
</div>
</section>
<section id="effect-size-conventions-and-considerations" class="level3">
<h3 class="anchored" data-anchor-id="effect-size-conventions-and-considerations">6.1.3 Effect Size Conventions and Considerations</h3>
<p>Cohen’s conventions for effect sizes are widely used but should be considered flexible guidelines:</p>
<ul>
<li>Small effect: d ≈ 0.2, r ≈ 0.1, f0B2 ≈ 0.02</li>
<li>Medium effect: d ≈ 0.5, r ≈ 0.3, f0B2 ≈ 0.15</li>
<li>Large effect: d ≈ 0.8, r ≈ 0.5, f0B2 ≈ 0.35</li>
</ul>
<p>In clinical research, consider these factors when estimating effect sizes:</p>
<ul>
<li>Previous studies with similar populations and interventions</li>
<li>Meta-analytic estimates for similar interventions</li>
<li>Minimally clinically important differences (MCIDs)</li>
<li>Practical constraints on feasible sample sizes</li>
</ul>
<div class="example">
<p><strong>Clinical Example:</strong> A researcher is planning a study comparing a new therapy to treatment as usual for anxiety. Based on previous studies, they expect a medium effect size (d = 0.50). An a priori power analysis indicates that they need 64 participants per group (total N = 128) to achieve 80% power with 3B1 = 0.05 for a two-tailed independent samples t-test.</p>
</div>
<p>[INTERACTIVE APPLICATION 14: Power Analysis Visualization]</p>
<p>Use this interactive application to explore how sample size, effect size, and significance level affect statistical power for different statistical tests.</p>
</section>
</section>
<section id="missing-data" class="level2">
<h2 class="anchored" data-anchor-id="missing-data">6.2 Missing Data</h2>
<p>Missing data is a common challenge in clinical research and can bias results if not handled appropriately.</p>
<section id="missing-data-mechanisms" class="level3">
<h3 class="anchored" data-anchor-id="missing-data-mechanisms">6.2.1 Missing Data Mechanisms</h3>
<p>There are three main mechanisms of missing data:</p>
<div class="definition">
<p><strong>Missing Completely at Random (MCAR):</strong> The probability of missing data is unrelated to any measured or unmeasured variables.</p>
<p><strong>Missing at Random (MAR):</strong> The probability of missing data depends on observed variables but not on unobserved variables.</p>
<p><strong>Missing Not at Random (MNAR):</strong> The probability of missing data depends on unobserved variables, including the value that would have been observed.</p>
</div>
<div class="margin-note">
<p>The mechanism of missing data determines which handling strategies are appropriate. MNAR is the most problematic because it can introduce systematic bias that cannot be corrected through most standard approaches.</p>
</div>
</section>
<section id="missing-data-handling-strategies" class="level3">
<h3 class="anchored" data-anchor-id="missing-data-handling-strategies">6.2.2 Missing Data Handling Strategies</h3>
<p>Several approaches exist for handling missing data:</p>
<ol type="1">
<li><p><strong>Deletion methods:</strong></p>
<ul>
<li><strong>Listwise deletion:</strong> Exclude cases with any missing data</li>
<li><strong>Pairwise deletion:</strong> Use all available data for each analysis</li>
</ul></li>
<li><p><strong>Single imputation methods:</strong></p>
<ul>
<li><strong>Mean imputation:</strong> Replace missing values with the mean</li>
<li><strong>Regression imputation:</strong> Predict missing values based on other variables</li>
<li><strong>Last observation carried forward (LOCF):</strong> Use the last available value (for longitudinal data)</li>
</ul></li>
<li><p><strong>Modern methods (preferred):</strong></p>
<ul>
<li><strong>Multiple imputation:</strong> Create multiple datasets with imputed values, analyze each, and pool results</li>
<li><strong>Maximum likelihood estimation:</strong> Estimate parameters directly from available data without imputing missing values</li>
</ul></li>
</ol>
<div class="margin-note">
<p>Modern methods (multiple imputation and maximum likelihood) are generally preferred because they make use of all available information and yield less biased estimates under MAR conditions.</p>
</div>
</section>
<section id="recommendations-for-handling-missing-data" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-for-handling-missing-data">6.2.3 Recommendations for Handling Missing Data</h3>
<p>Best practices for handling missing data include:</p>
<ol type="1">
<li>Plan for missing data during study design</li>
<li>Document the extent of missing data and explore patterns</li>
<li>Consider potential mechanisms for missingness</li>
<li>Use modern missing data methods when possible</li>
<li>Conduct sensitivity analyses with different missing data approaches</li>
<li>Report missing data details and handling methods</li>
</ol>
<div class="example">
<p><strong>Clinical Example:</strong> In a longitudinal treatment study, dropout rates are higher for participants with more severe baseline symptoms. This suggests a MAR pattern (missingness related to observed variables). The researcher uses multiple imputation based on baseline symptoms and other observed variables to create 20 imputed datasets, analyzes each, and pools the results to obtain unbiased estimates.</p>
</div>
</section>
</section>
<section id="effect-size-interpretation-in-clinical-contexts" class="level2">
<h2 class="anchored" data-anchor-id="effect-size-interpretation-in-clinical-contexts">6.3 Effect Size Interpretation in Clinical Contexts</h2>
<p>Statistical significance tells us whether an effect is likely due to chance, but effect sizes tell us about the magnitude or importance of the effect.</p>
<section id="beyond-cohens-conventions" class="level3">
<h3 class="anchored" data-anchor-id="beyond-cohens-conventions">6.3.1 Beyond Cohen’s Conventions</h3>
<p>While Cohen’s conventions (small, medium, large) provide a starting point, effect size interpretation in clinical contexts should consider:</p>
<ol type="1">
<li><p><strong>Comparison to similar interventions:</strong> How does the effect size compare to other interventions for the same condition?</p></li>
<li><p><strong>Cost and resources:</strong> Smaller effects may be meaningful if the intervention is low-cost, brief, or has few side effects.</p></li>
<li><p><strong>Severity of the condition:</strong> For severe or treatment-resistant conditions, smaller effects may be important.</p></li>
<li><p><strong>Individual-level changes:</strong> Group-level effect sizes may mask meaningful individual responses.</p></li>
<li><p><strong>Maintenance of effects:</strong> Smaller immediate effects that persist may be more valuable than larger effects that fade quickly.</p></li>
</ol>
</section>
<section id="clinical-significance" class="level3">
<h3 class="anchored" data-anchor-id="clinical-significance">6.3.2 Clinical Significance</h3>
<p>Clinical significance refers to whether an intervention produces meaningful change in clients’ lives, regardless of statistical significance.</p>
<div class="definition">
<p><strong>Clinical Significance:</strong> The practical importance of an effect, intervention, or treatment outcome, especially as it relates to meaningful change in functioning, quality of life, or symptom reduction.</p>
</div>
<p>Approaches to assessing clinical significance include:</p>
<ol type="1">
<li><p><strong>Comparison to normative data:</strong> Do post-treatment scores fall within the normal range?</p></li>
<li><p><strong>Reliable Change Index (RCI):</strong> Does the change exceed what would be expected due to measurement error?</p></li>
<li><p><strong>Minimally Clinically Important Difference (MCID):</strong> Does the change exceed a threshold considered meaningful to patients?</p></li>
<li><p><strong>Functional outcomes:</strong> Does the change lead to improvements in daily functioning, quality of life, or other important domains?</p></li>
</ol>
<div class="example">
<p><strong>Clinical Example:</strong> A study of a brief anxiety intervention finds a statistically significant but small effect size (d = 0.30) compared to a waitlist control. However, 40% of treated participants no longer meet diagnostic criteria for an anxiety disorder (compared to 15% of controls), and treated participants report significant improvements in work and social functioning. Despite the modest effect size, these outcomes suggest clinical significance.</p>
</div>
</section>
</section>
<section id="reporting-results-in-apa-format" class="level2">
<h2 class="anchored" data-anchor-id="reporting-results-in-apa-format">6.4 Reporting Results in APA Format</h2>
<p>Clear, consistent reporting of statistical results helps readers understand and evaluate research findings. The American Psychological Association (APA) provides guidelines for reporting statistics.</p>
<section id="general-reporting-guidelines" class="level3">
<h3 class="anchored" data-anchor-id="general-reporting-guidelines">6.4.1 General Reporting Guidelines</h3>
<p>Key elements to include when reporting results:</p>
<ol type="1">
<li><strong>Test type and purpose:</strong> Clearly state what test was conducted and why</li>
<li><strong>Test statistic, degrees of freedom, p-value:</strong> Report the complete test result</li>
<li><strong>Effect size:</strong> Include an appropriate effect size measure</li>
<li><strong>Confidence intervals:</strong> Provide confidence intervals when possible</li>
<li><strong>Descriptive statistics:</strong> Report relevant means, standard deviations, etc.</li>
<li><strong>Direction of effect:</strong> Clearly describe the direction or pattern of results</li>
</ol>
</section>
<section id="apa-formatting-for-common-tests" class="level3">
<h3 class="anchored" data-anchor-id="apa-formatting-for-common-tests">6.4.2 APA Formatting for Common Tests</h3>
<p><strong>t-test:</strong></p>
<pre><code>Participants in the treatment group (M = 15.2, SD = 4.3) reported significantly lower anxiety than those in the control group (M = 19.8, SD = 4.5), t(58) = 3.94, p &lt; .001, d = 1.02, 95% CI [2.25, 6.95].</code></pre>
<p><strong>ANOVA:</strong></p>
<pre><code>A significant main effect of treatment type was found, F(2, 87) = 7.56, p = .001, η\U00B2 = .15. Post-hoc tests (Tukey's HSD) revealed that CBT resulted in significantly lower depression scores than supportive therapy (p = .003) or the waitlist control (p &lt; .001), which did not differ significantly from each other (p = .38).</code></pre>
<p><strong>Correlation:</strong></p>
<pre><code>Therapeutic alliance was significantly positively correlated with symptom reduction, r(48) = .42, p = .003, 95% CI [.16, .63].</code></pre>
<p><strong>Regression:</strong></p>
<pre><code>The multiple regression model with three predictors explained 38% of the variance in treatment outcomes, R\U00B2 = .38, F(3, 96) = 19.57, p &lt; .001. As shown in Table 1, both therapeutic alliance (β = .45, p &lt; .001) and homework compliance (β = .32, p = .002) were significant predictors, while treatment duration was not (β = .11, p = .18).</code></pre>
</section>
<section id="tables-and-figures" class="level3">
<h3 class="anchored" data-anchor-id="tables-and-figures">6.4.3 Tables and Figures</h3>
<p>Tables and figures can effectively present complex statistical information:</p>
<ol type="1">
<li><p><strong>Tables:</strong> Useful for presenting multiple statistical results in a structured format (e.g., means and standard deviations by group, regression coefficients)</p></li>
<li><p><strong>Figures:</strong> Effective for visualizing patterns, relationships, and interactions (e.g., bar graphs for group comparisons, scatterplots for correlations, line graphs for interactions)</p></li>
</ol>
<div class="margin-note">
<p>APA has specific formatting requirements for tables and figures, including numbering, titles, notes, and layout. Consult the APA Publication Manual for detailed guidelines.</p>
</div>
</section>
</section>
<section id="common-misinterpretations-and-pitfalls" class="level2">
<h2 class="anchored" data-anchor-id="common-misinterpretations-and-pitfalls">6.5 Common Misinterpretations and Pitfalls</h2>
<p>Several common misinterpretations and pitfalls in statistical analysis can lead to invalid conclusions.</p>
<section id="misinterpreting-p-values" class="level3">
<h3 class="anchored" data-anchor-id="misinterpreting-p-values">6.5.1 Misinterpreting p-values</h3>
<p>Common misconceptions about p-values include:</p>
<ol type="1">
<li><p><strong>p-value as the probability the null hypothesis is true:</strong> The p-value is the probability of obtaining the observed results (or more extreme) if the null hypothesis is true, not the probability that the null hypothesis is true.</p></li>
<li><p><strong>p &lt; .05 as “proof” of an effect:</strong> Statistical significance does not prove that an effect exists or that it is meaningful.</p></li>
<li><p><strong>p &gt; .05 as “proof” of no effect:</strong> Non-significant results do not prove the null hypothesis; they often reflect insufficient power.</p></li>
<li><p><strong>p-value as indicating the size of an effect:</strong> A smaller p-value does not necessarily indicate a larger or more important effect.</p></li>
</ol>
</section>
<section id="multiple-comparisons-problem" class="level3">
<h3 class="anchored" data-anchor-id="multiple-comparisons-problem">6.5.2 Multiple Comparisons Problem</h3>
<p>The more statistical tests you conduct, the more likely you are to find significant results by chance alone.</p>
<div class="margin-note">
<p>At 3B1 = .05, conducting 20 independent tests would be expected to yield one statistically significant result by chance alone.</p>
</div>
<p>Approaches to address the multiple comparisons problem:</p>
<ol type="1">
<li><strong>Bonferroni correction:</strong> Divide the significance level by the number of tests</li>
<li><strong>False Discovery Rate (FDR) approaches:</strong> Control the proportion of false positives</li>
<li><strong>Planned comparisons:</strong> Specify comparisons in advance based on theory</li>
<li><strong>Omnibus tests:</strong> Use ANOVA or similar tests before examining specific comparisons</li>
</ol>
</section>
<section id="confusing-correlation-with-causation" class="level3">
<h3 class="anchored" data-anchor-id="confusing-correlation-with-causation">6.5.3 Confusing Correlation with Causation</h3>
<p>Correlation does not imply causation. A statistical relationship between variables does not necessarily indicate that one causes the other.</p>
<p>Potential alternative explanations for correlations:</p>
<ol type="1">
<li><strong>Reverse causation:</strong> The presumed effect may cause the presumed cause</li>
<li><strong>Third variables:</strong> Unmeasured variables may cause both the observed variables</li>
<li><strong>Selection bias:</strong> The way participants were selected may create artificial relationships</li>
<li><strong>Chance:</strong> Random variation can produce apparent relationships</li>
</ol>
</section>
<section id="overreliance-on-significance-testing" class="level3">
<h3 class="anchored" data-anchor-id="overreliance-on-significance-testing">6.5.4 Overreliance on Significance Testing</h3>
<p>An overemphasis on significance testing can lead to:</p>
<ol type="1">
<li><strong>Publication bias:</strong> Significant results are more likely to be published</li>
<li><strong>p-hacking:</strong> Analyzing data multiple ways until significant results emerge</li>
<li><strong>HARKing (Hypothesizing After Results are Known):</strong> Presenting post-hoc hypotheses as if they were a priori</li>
<li><strong>Neglecting effect sizes and confidence intervals:</strong> Focusing on p-values at the expense of other important information</li>
</ol>
</section>
<section id="recommendations-for-avoiding-pitfalls" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-for-avoiding-pitfalls">6.5.5 Recommendations for Avoiding Pitfalls</h3>
<p>Best practices to avoid these pitfalls include:</p>
<ol type="1">
<li><strong>Preregistration:</strong> Specify hypotheses, sample size, and analyses in advance</li>
<li><strong>Focus on effect sizes and confidence intervals:</strong> Report and interpret these alongside p-values</li>
<li><strong>Consider practical/clinical significance:</strong> Evaluate whether effects are meaningful, not just statistically significant</li>
<li><strong>Be transparent about analyses:</strong> Report all analyses conducted, including “failed” tests</li>
<li><strong>Consider replications:</strong> Treat initial findings as provisional until replicated</li>
</ol>
</section>
</section>
<section id="summary-4" class="level2">
<h2 class="anchored" data-anchor-id="summary-4">6.6 Summary</h2>
<p>Practical considerations in statistical analysis are crucial for conducting valid, interpretable, and meaningful research. Key points to remember:</p>
<ul>
<li>Plan for adequate statistical power through a priori sample size calculations</li>
<li>Use appropriate methods to handle missing data</li>
<li>Interpret effect sizes in the context of clinical significance</li>
<li>Follow APA guidelines for clear and complete reporting of results</li>
<li>Be aware of common misinterpretations and pitfalls in statistical analysis</li>
</ul>
<p>By attending to these practical considerations, researchers can enhance the validity and usefulness of their findings, contributing to a more robust evidence base for clinical psychology.</p>
<div class="practice">
<p><strong>Practice Questions:</strong></p>
<ol type="1">
<li><p>A researcher is planning a study comparing two therapies and expects a small-to-medium effect size (d = 0.4). How many participants would they need per group to achieve 80% power?</p></li>
<li><p>In a longitudinal study, participants with higher baseline anxiety are more likely to drop out. What type of missing data pattern is this, and what approach to handling missing data would be appropriate?</p></li>
<li><p>A study finds a statistically significant difference between treatments (p = .02) but a small effect size (d = 0.25). How would you evaluate the clinical significance of this finding?</p></li>
<li><p>What are the key elements that should be included when reporting the results of a multiple regression analysis in APA format?</p></li>
</ol>
</div>
</section>
<section id="references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="references">References</h2>
<p>American Psychological Association. (2020). Publication manual of the American Psychological Association (7th ed.). https://doi.org/10.1037/0000165-000</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Lawrence Erlbaum Associates.</p>
<p>Field, A. (2017). Discovering statistics using IBM SPSS Statistics (5th ed.). SAGE Publications.</p>
<p>Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach (2nd ed.). The Guilford Press.</p>
<p>Kazdin, A. E. (2017). Research design in clinical psychology (5th ed.). Pearson.</p>
<p>MacKinnon, D. P. (2008). Introduction to statistical mediation analysis. Lawrence Erlbaum Associates.</p>
<p>Maxwell, S. E., &amp; Delaney, H. D. (2004). Designing experiments and analyzing data: A model comparison perspective (2nd ed.). Psychology Press.</p>
<p>Thompson, B. (2007). Effect sizes, confidence intervals, and confidence intervals for effect sizes. Psychology in the Schools, 44(5), 423-432. https://doi.org/10.1002/pits.20234</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>